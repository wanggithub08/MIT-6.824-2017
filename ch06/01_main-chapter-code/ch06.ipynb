{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
      "metadata": {
        "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
      "metadata": {
        "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
      },
      "source": [
        "# Chapter 6: Finetuning for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
        "outputId": "2117495b-5d3e-45c6-dad6-43f7f1e87fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "numpy version: 2.0.2\n",
            "tiktoken version: 0.9.0\n",
            "torch version: 2.6.0+cu124\n",
            "tensorflow version: 2.18.0\n",
            "pandas version: 2.2.2\n",
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",  # Plotting library\n",
        "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
        "        \"tiktoken\",    # Tokenizer\n",
        "        \"torch\",       # Deep learning library\n",
        "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
        "        \"pandas\"       # Dataset loading\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")\n",
        "print(version(\"torch\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
      "metadata": {
        "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
      "metadata": {
        "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
      },
      "source": [
        "## 6.1 Different categories of finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
      "metadata": {
        "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
      },
      "source": [
        "- No code in this section"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
      "metadata": {
        "id": "ac45579d-d485-47dc-829e-43be7f4db57b"
      },
      "source": [
        "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
        "- Instruction-finetuning, depicted below, is the topic of the next chapter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
      "metadata": {
        "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
      "metadata": {
        "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd"
      },
      "source": [
        "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
        "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
        "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
        "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
      "metadata": {
        "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
      "metadata": {
        "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
      },
      "source": [
        "## 6.2 Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
      "metadata": {
        "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
      "metadata": {
        "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
      },
      "source": [
        "- This section prepares the dataset we use for classification finetuning\n",
        "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
        "- First, we download and unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
        "outputId": "78c1da22-76cd-4762-ad61-613483d5db99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "try:\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
        "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
        "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
      "metadata": {
        "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
      },
      "source": [
        "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1185
        },
        "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
        "outputId": "77b1f73f-98a5-4df1-db80-9f543a8b5185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3e03ae4-dd90-47b6-9070-f95cd0623aaf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3e03ae4-dd90-47b6-9070-f95cd0623aaf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3e03ae4-dd90-47b6-9070-f95cd0623aaf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3e03ae4-dd90-47b6-9070-f95cd0623aaf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68e66127-36ab-45a3-bf56-b05a4e740f92\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68e66127-36ab-45a3-bf56-b05a4e740f92')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68e66127-36ab-45a3-bf56-b05a4e740f92 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fbc44348-c3f0-4bc4-9e27-8e799153b30b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbc44348-c3f0-4bc4-9e27-8e799153b30b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<google.colab._quickchart_helpers.SectionTitle at 0x7ae717cc8e90>"
            ],
            "text/html": [
              "<h4 class=\"colab-quickchart-section-title\">Distributions</h4>\n",
              "<style>\n",
              "  .colab-quickchart-section-title {\n",
              "      clear: both;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "from matplotlib import pyplot as plt\n",
              "_df_0['index'].plot(kind='hist', bins=20, title='index')\n",
              "plt.gca().spines[['top', 'right',]].set_visible(False)"
            ],
            "text/html": [
              "      <div class=\"colab-quickchart-chart-with-code\" id=\"chart-d0c9b7b2-9daf-4e03-a232-25324583303e\">\n",
              "        <img style=\"width: 180px;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAi4AAAGrCAYAAADn3xwpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\n",
              "bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\n",
              "YQAAD2EBqD+naQAAHkZJREFUeJzt3X+QVfV9//HXyuIm/gAMBEGXhRB+pKnIqoVSTILWsVHTCBGd\n",
              "jNYIqSnEtmMdnEaZpBOrGYipNbHpZETboVVmKDSQtA3VqtVIbI2Av0jMqBDc7Gr54WABxyrCer5/\n",
              "ONmvq4he2Mvygcdj5o7c87n38r5nLs5zzp69p6GqqioAAAU4orcHAAB4v4QLAFAM4QIAFEO4AADF\n",
              "EC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAtwQJx77rm54YYb9vn5n/jEJ3Ldddf13EBAkRp7ewDg\n",
              "8HDXXXf19gjAIcARFwCgGMIFOCDOOOOMfO1rX0uSNDQ05Lvf/W5OP/30HHPMMRk3blweeuihrsfu\n",
              "3r07X/nKVzJkyJB8+MMfzty5c9/xei+88EIuueSSnHjiiRk8eHAuvvjivPjii0mSH//4xzn66KOz\n",
              "evXqJElVVfnMZz6Tz372s3FdWSibcAF6xd/93d/lH//xH7Nt27acddZZ+YM/+IOutW9961tZunRp\n",
              "7r///jz//PNpbGzMI4880rW+c+fOnHXWWTnhhBPy7LPPZsOGDWlsbMwll1yS5M1Iuu6663LhhRdm\n",
              "69atueGGG/L000/nzjvvTENDwwF/r0DPES5Ar7j66qszatSoNDY25o/+6I/S3t6ezZs3J0kWLlyY\n",
              "q6++Oh//+MfT1NSU6667Lscdd1zXc1esWJGXX345f/VXf5Wjjz46xxxzTL75zW/mvvvuy/PPP58k\n",
              "+fM///NMmDAhZ511Vr71rW9l2bJlGTBgQG+8VaAHOTkX6BUnnHBC15+PPvroJMnLL7+c448/Ps8/\n",
              "/3w+8pGPdK336dMnLS0tXffXrVuXzZs3d4uZJGlqakp7e3uam5uTJHPmzMnpp5+eiy++OK2trXV8\n",
              "N8CBIlyAg05zc3Pa2tq67nd2dqajo6Pr/pAhQzJ8+PD88pe/fNfX2L59e2bMmJHLL788S5cuzb/9\n",
              "27/ls5/9bD3HBg4APyoCDjozZszIX//1X+fpp5/Ozp07c/311+ell17qWr/ggguya9eu/MVf/EW2\n",
              "b9+eJNmyZUuWLFmS5M2TcWfMmJGxY8fm9ttvz4IFC3LZZZdlw4YNvfJ+gJ4jXICDzjXXXJMLLrgg\n",
              "U6ZMSXNzc15//fX89m//dtf6sccem4cffjjt7e0ZN25c+vXrl8mTJ2flypVJkhtvvDFr167tOhn3\n",
              "4osvzqWXXprp06fn1Vdf7a23BfSAhsrvBgIAhXDEBQAohnABAIohXACAYggXAKAYwgUAKIZwAQCK\n",
              "IVwAgGIccuFyyy239PYIAECdHHLh8qtf/aq3RwAA6uSQCxcA4NAlXACAYggXAKAYwgUAKIZwAQCK\n",
              "IVwAgGIIFwCgGMIFACiGcAEAiiFcAIBiCBcAoBjCBQAohnABAIohXACAYggXAKAYjb09QElGXLui\n",
              "t0eoWds3P1OX163nvqjXzEn95jZzd/6t/H8l/lspcebEv5UDpZ774/1wxAUAKEZDVVVVbw/Rk+bM\n",
              "mZObb765Lq9dYhkDQE9yxAUA4H0SLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAA\n",
              "xRAuAEAxhAsAUAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAA\n",
              "xRAuAEAxhAsAUAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQjLqFy2uvvZZp\n",
              "06ZlzJgxGT9+fM4+++ysX78+SXLGGWfkIx/5SFpbW9Pa2ppvf/vbXc/bsmVLzjnnnIwePTonnXRS\n",
              "Vq5cWa8RAYDCNNbzxWfNmpVzzz03DQ0N+du//dt86Utfyo9//OMkybe//e1MmzbtHc+59tprM2nS\n",
              "pNx9991ZvXp1Pve5z+W5555L37596zkqAFCAuh1x+cAHPpDzzjsvDQ0NSZJJkyalra3tPZ+3dOnS\n",
              "fPnLX06STJgwISeccEIefPDBPT52586d2bFjR7dbZ2dnj70HAODgcsDOcbnlllsyderUrvvXXntt\n",
              "xo0bl89//vPZsGFDkmTr1q3ZtWtXhgwZ0vW4ESNGpL29fY+vOX/+/PTv37/bbdWqVfV9IwBArzkg\n",
              "4TJv3rysX78+8+fPT5Lceeedefrpp7N27dp88pOfzO///u/v0+vOnTs327dv73abOHFiT44OABxE\n",
              "6h4uN910U5YvX5677rorRx11VJJk2LBhSZKGhob86Z/+aTZs2JCtW7dm4MCBaWxszKZNm7qe39bW\n",
              "lpaWlj2+dlNTU/r169ft1qdPn3q/JQCgl9Q1XG6++eYsXrw49957bwYMGJAk2b17dzZv3tz1mGXL\n",
              "luX444/PwIEDkyQXXXRRbr311iTJ6tWr88ILL2TKlCn1HBMAKETdfqvo+eefz9VXX52RI0fmzDPP\n",
              "TPLmEZL7778/n/nMZ7Jz584cccQRGTRoUP71X/+163k33nhjvvCFL2T06NE58sgjs2jRIr9RBAAk\n",
              "qWO4NDc3p6qqPa6tWbPmXZ93/PHH55577qnXWABAwXxzLgBQDOECABRDuAAAxRAuAEAxhAsAUAzh\n",
              "AgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsAUAzh\n",
              "AgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsAUAzh\n",
              "AgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsAUAzh\n",
              "AgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsAUAzh\n",
              "AgAUo27h8tprr2XatGkZM2ZMxo8fn7PPPjvr169PkmzZsiXnnHNORo8enZNOOikrV67set7e1gCA\n",
              "w1tdj7jMmjUrzzzzTJ588slMnTo1X/rSl5Ik1157bSZNmpR169Zl4cKFueSSS7Jr1673XAMADm91\n",
              "C5cPfOADOe+889LQ0JAkmTRpUtra2pIkS5cuzZe//OUkyYQJE3LCCSfkwQcffM+1t9u5c2d27NjR\n",
              "7dbZ2VmvtwQA9LIDdo7LLbfckqlTp2br1q3ZtWtXhgwZ0rU2YsSItLe373VtT+bPn5/+/ft3u61a\n",
              "taru7wUA6B0HJFzmzZuX9evXZ/78+T36unPnzs327du73SZOnNijfwcAcPBorPdfcNNNN2X58uW5\n",
              "7777ctRRR+Woo45KY2NjNm3a1HVkpa2tLS0tLRk4cOC7ru1JU1NTmpqaum3r06dPfd8QANBr6nrE\n",
              "5eabb87ixYtz7733ZsCAAV3bL7rootx6661JktWrV+eFF17IlClT3nMNADi81e2Iy/PPP5+rr746\n",
              "I0eOzJlnnpnkzSMkjzzySG688cZ84QtfyOjRo3PkkUdm0aJF6du3b5LsdQ0AOLzVLVyam5tTVdUe\n",
              "144//vjcc889Na8BAIc335wLABRDuAAAxRAuAEAxhAsAUAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIA\n",
              "FEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsAUAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIA\n",
              "FEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsAUAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIA\n",
              "FEO4AADFEC4AQDGECwBQjJrD5T/+4z/qMQcAwHuqOVyuv/76jB07Nrfcckt27NhRj5kAAPao5nD5\n",
              "r//6r/zTP/1Tfv7zn2fMmDH54z/+4/ziF7+ox2wAAN3s0zkup5xySm6//fbcfffd+dGPfpSTTz45\n",
              "Z599dn72s5/19HwAAF32KVzuu+++TJ06NRdccEH+5E/+JJs2bcrs2bPzuc99rqfnAwDo0ljrE37j\n",
              "N34jgwYNypVXXpkLLrggffr0SZJceOGF+fu///seHxAA4NdqDpdFixbltNNO2+PaXXfdtd8DAQC8\n",
              "m5p/VPToo4/mpZde6rq/devW3H777T06FADAntQcLt/73vfyoQ99qOv+wIED873vfa9HhwIA2JOa\n",
              "w6Wqqnds6+zs7JFhAAD2puZwGTp0aJYuXdp1f8mSJRk6dGiPDgUAsCc1n5z7ne98J1OnTs1XvvKV\n",
              "JMlRRx2Vf/mXf+nxwQAA3q7mcPnYxz6WX/ziF3nmmWeSJGPHju36lWgAgHqqOVySpKGhIQMGDMju\n",
              "3bvzwgsvJElaWlp6dDAAgLerOVz+4R/+IVdeeWX69u2bI4548xSZhoaGbNmypceHAwB4q5rD5YYb\n",
              "bsjq1aszduzYeswDAPCuav6tokGDBokWAKBX1Bwu06ZNy3e+851s2bIlO3bs6LoBANRbzeHy1a9+\n",
              "NXPmzMmQIUNy3HHHZcCAATnuuOP2+Ngrr7wyI0aMSENDQ5544omu7SNGjMjYsWPT2tqa1tbWLFmy\n",
              "pGtt3bp1mTx5csaMGZMJEybkqaeeqv1dAQCHpJrD5Y033ui6dXZ2dv13Ty688MI89NBDGT58+DvW\n",
              "lixZkieeeCJPPPFEPv/5z3dtnz17dmbNmpVnn30211xzTWbOnFnriADAIarmcEnevNDinXfemSTZ\n",
              "tm1bNm7cuMfHfepTn0pzc/P7ft0tW7ZkzZo1ufTSS5Mk06dPT0dHR9avX7/Hx+/cubPbj6t27Njh\n",
              "8gMAcAjbp4ss/uEf/mGuu+66JG9eHfqSSy6p+S++7LLLMm7cuFx++eV58cUXkyQdHR0ZOnRoGhvf\n",
              "/GWnhoaGtLS0pL29fY+vMX/+/PTv37/bbdWqVTXPAgCUoeZwue222/LTn/40/fr1S5J89KMf7QqP\n",
              "92vlypVZu3ZtHnvssQwaNCgzZsyodYwkydy5c7N9+/Zut4kTJ+7TawEAB7+av8elqakpH/zgB7u/\n",
              "SGNtL/Prb9nt27dvrrrqqowZMyZJMmzYsGzcuDG7d+9OY2NjqqpKe3v7u34rb1NTU5qamrptc/kB\n",
              "ADh01XzE5cMf/nCeffbZNDQ0JHnzm3Rr+br/V155Jdu2beu6v3jx4pxyyilJksGDB+fUU0/NokWL\n",
              "kiTLli1Lc3NzRo0aVeuYAMAhaJ+uDn3xxRfn6aefzrBhw9KvX7/86Ec/2uNjZ8+enRUrVmTTpk35\n",
              "9Kc/nWOPPTb33HNPpk+fns7OzlRVlZEjR+aOO+7oes6CBQsyc+bMzJs3L/369cvChQv3/d0BAIeU\n",
              "msNl1KhReeSRR/LMM8+kqqq9Xh16wYIFe9z++OOPv+vrjx07Ng8//HCtYwEAh4Gaw+XXv+Fz9NFH\n",
              "J4mrQwMAB0zN4XLaaaeloaEhVVXltddey//93/9l4MCBrg4NANRdzeHy9l99Xr58eZ588skeGwgA\n",
              "4N3s0zfnvtUFF1yQFStW9MQsAAB7VfMRl7deCbqzszOPPPKIq0MDAAdEzeEyYMCArnNc+vTpk9Gj\n",
              "R+dv/uZv6jEbAEA3NYfLG2+8UY85AADe036f4wIAcKDUfMTliCOO6Pq6/7eqqioNDQ3p7OzskcEA\n",
              "AN6u5nC5/vrr8+qrr+aKK65Iktx666354Ac/mKuuuqqnZwMA6KbmcPnBD36QRx99tOv+N77xjZx2\n",
              "2mn56le/2qODAQC8Xc3nuLz88svdviV3y5Ytefnll3t0KACAPan5iMvVV1+d8ePH57zzzkuS3H33\n",
              "3bnuuut6ei4AgHeoOVxmz56d008/PQ888ECSZM6cOfnN3/zNHh8MAODtag6XJBk4cGDGjRuXM844\n",
              "I7t3787rr7+eI488sqdnAwDopuZzXL7//e9n0qRJ+eIXv5gkeeqppzJt2rSengsA4B1qDpf58+fn\n",
              "sccey4ABA5Ik48ePz69+9auengsA4B1qDpc+ffpk4MCB3bb5MREAcCDUHC7HHntsNm/e3PXtuf/5\n",
              "n/+ZD33oQz0+GADA29V8cu6NN96Yc889Nxs2bMgnPvGJPPfcc1mxYkU9ZgMA6KamcHnjjTfS2dmZ\n",
              "Bx54IP/93/+dqqoyefLkrvNdAADqqaZwOeKIIzJr1qw8+eSTOffcc+s1EwDAHtV8jsvo0aOzfv36\n",
              "eswCALBXNZ/j8tJLL6W1tTWTJ0/OMccc07V9+fLlPToYAMDbve9wmTVrVm677bbMmDEj559/fo47\n",
              "7rh6zgUA8A7vO1zWrFmTJJkxY0ZOPfXUPPbYY3UbCgBgT2o+xyVJqqrq6TkAAN7T+z7i8uqrr+Zn\n",
              "P/tZqqrKa6+91vXnXzv55JPrMiAAwK/VFC7nn39+1/23/rmhoSEbNmzo2ckAAN7mfYdLW1tbHccA\n",
              "AHhv+3SOCwBAbxAuAEAxhAsAUAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQ\n",
              "DOECABRDuAAAxRAuAEAxhAsAUAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQ\n",
              "DOECABSjruFy5ZVXZsSIEWloaMgTTzzRtX3dunWZPHlyxowZkwkTJuSpp556X2sAwOGtruFy4YUX\n",
              "5qGHHsrw4cO7bZ89e3ZmzZqVZ599Ntdcc01mzpz5vtYAgMNbXcPlU5/6VJqbm7tt27JlS9asWZNL\n",
              "L700STJ9+vR0dHRk/fr1e13bk507d2bHjh3dbp2dnfV8SwBALzrg57h0dHRk6NChaWxsTJI0NDSk\n",
              "paUl7e3te13bk/nz56d///7dbqtWrTpg7wUAOLCKPjl37ty52b59e7fbxIkTe3ssAKBOGg/0Xzhs\n",
              "2LBs3Lgxu3fvTmNjY6qqSnt7e1paWtKvX793XduTpqamNDU1ddvWp0+fA/E2AIBecMCPuAwePDin\n",
              "nnpqFi1alCRZtmxZmpubM2rUqL2uAQDU9YjL7Nmzs2LFimzatCmf/vSnc+yxx2b9+vVZsGBBZs6c\n",
              "mXnz5qVfv35ZuHBh13P2tgYAHN7qGi4LFizY4/axY8fm4YcfrnkNADi8FX1yLgBweBEuAEAxhAsA\n",
              "UAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsA\n",
              "UAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsA\n",
              "UAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsA\n",
              "UAzhAgAUQ7gAAMUQLgBAMYQLAFAM4QIAFEO4AADFEC4AQDGECwBQDOECABRDuAAAxRAuAEAxhAsA\n",
              "UAzhAgAUQ7gAAMUQLgBAMXotXEaMGJGxY8emtbU1ra2tWbJkSZJk3bp1mTx5csaMGZMJEybkqaee\n",
              "6q0RAYCDTGNv/uVLlixJa2trt22zZ8/OrFmzMnPmzHz/+9/PzJkzs3r16t4ZEAA4qBxUPyrasmVL\n",
              "1qxZk0svvTRJMn369HR0dGT9+vV7fPzOnTuzY8eObrfOzs4DOTIAcAD1arhcdtllGTduXC6//PK8\n",
              "+OKL6ejoyNChQ9PY+OaBoIaGhrS0tKS9vX2Pz58/f3769+/f7bZq1aoD+RYAgAOo18Jl5cqVWbt2\n",
              "bR577LEMGjQoM2bMqPk15s6dm+3bt3e7TZw4sQ7TAgAHg147x6WlpSVJ0rdv31x11VUZM2ZMhg0b\n",
              "lo0bN2b37t1pbGxMVVVpb2/veuzbNTU1pampqdu2Pn361H12AKB39MoRl1deeSXbtm3rur948eKc\n",
              "csopGTx4cE499dQsWrQoSbJs2bI0Nzdn1KhRvTEmAHCQ6ZUjLps3b8706dPT2dmZqqoycuTI3HHH\n",
              "HUmSBQsWZObMmZk3b1769euXhQsX9saIAMBBqFfCZeTIkXn88cf3uDZ27Ng8/PDDB3giAKAEB9Wv\n",
              "QwMA7I1wAQCKIVwAgGIIFwCgGMIFACiGcAEAiiFcAIBiCBcAoBjCBQAohnABAIohXACAYggXAKAY\n",
              "wgUAKIZwAQCKIVwAgGIIFwCgGMIFACiGcAEAiiFcAIBiCBcAoBjCBQAohnABAIohXACAYggXAKAY\n",
              "wgUAKIZwAQCKIVwAgGIIFwCgGMIFACiGcAEAiiFcAIBiCBcAoBjCBQAohnABAIohXACAYggXAKAY\n",
              "wgUAKIZwAQCKIVwAgGIIFwCgGMIFACiGcAEAiiFcAIBiCBcAoBjCBQAohnABAIohXACAYggXAKAY\n",
              "wgUAKIZwAQCKIVwAgGIIFwCgGMIFACiGcAEAinFQhsu6desyefLkjBkzJhMmTMhTTz3V2yMBAAeB\n",
              "gzJcZs+enVmzZuXZZ5/NNddck5kzZ/b2SADAQeCgC5ctW7ZkzZo1ufTSS5Mk06dPT0dHR9avX/+O\n",
              "x+7cuTM7duzoduvs7DzQIwMAB0hjbw/wdh0dHRk6dGgaG98craGhIS0tLWlvb8+oUaO6PXb+/Pn5\n",
              "y7/8y27bPvaxj2XOnDk9PldnZ2eGrlqViRMnpk+fPj3++oeDzs7OrLIP94t9uP/sw/1nH+6f0vff\n",
              "nDn/WZfXHT58eP7sz/7sPR/XUFVVVZcJ9tGjjz6aSy65JM8880zXtokTJ+ab3/xmfvd3f7fbY3fu\n",
              "3JmdO3d229bU1JSmpqYen2vHjh3p379/tm/fnn79+vX46x8O7MP9Zx/uP/tw/9mH+8f+2z8H3RGX\n",
              "YcOGZePGjdm9e3caGxtTVVXa29vT0tLyjsfWK1IAgIPTQXeOy+DBg3Pqqadm0aJFSZJly5alubn5\n",
              "HT8mAgAOPwfdEZckWbBgQWbOnJl58+alX79+WbhwYW+PBAAcBA7KcBk7dmwefvjh3h6jm6ampnz9\n",
              "61/3o6n9YB/uP/tw/9mH+88+3D/23/456E7OBQB4NwfdOS4AAO9GuAAAxRAuAEAxhAsAUAzh8j64\n",
              "WvWeXXnllRkxYkQaGhryxBNPdG3f2/7a17VD0WuvvZZp06ZlzJgxGT9+fM4+++yua3Jt2bIl55xz\n",
              "TkaPHp2TTjopK1eu7Hrevq4dqn7v934vJ598clpbW/PJT34yjz/+eBKfw32xcOHCNDQ05Ic//GES\n",
              "n8NajBgxImPHjk1ra2taW1uzZMmSJD6HdVHxns4888xq4cKFVVVV1T//8z9Xv/Vbv9W7Ax0kHnzw\n",
              "waqjo6MaPnx49fjjj3dt39v+2te1Q9Grr75arVixonrjjTeqqqqq7373u9WUKVOqqqqqL37xi9XX\n",
              "v/71qqqqatWqVdWJJ55Yvf766/u1dqj63//9364/L1++vDr55JOrqvI5rNVzzz1X/c7v/E41adKk\n",
              "6gc/+EFVVT6HtXj7/wd/zeew5wmX97B58+bq2GOPrXbt2lVVVVW98cYb1fHHH1+tW7eulyc7eLz1\n",
              "H+ze9te+rh0uVq9eXQ0fPryqqqo6+uijq40bN3atTZgwobr33nv3a+1wsHDhwmr8+PE+hzXq7Oys\n",
              "zjrrrGrNmjXVlClTusLF5/D921O4+BzWx0H5BXQHk1quVs3e91f//v33ae1w2c+33HJLpk6dmq1b\n",
              "t2bXrl0ZMmRI19qIESPS3t6+z2uHussuuywPPPBAkuTf//3ffQ5rdPPNN+f000/Paaed1rXN57B2\n",
              "l112Waqq6rowsM9hfTjHBQ4C8+bNy/r16zN//vzeHqVId9xxRzo6OvKNb3wj11xzTW+PU5Sf//zn\n",
              "WbZsWb72ta/19ihFW7lyZdauXZvHHnssgwYNyowZM3p7pEOWcHkPb71adZK9Xq2ave+vfV071N10\n",
              "001Zvnx57rrrrhx11FEZOHBgGhsbs2nTpq7HtLW1paWlZZ/XDhczZszIAw88kObmZp/D9+knP/lJ\n",
              "2traMnr06IwYMSI//elPM2vWrCxdutTnsAa/fn99+/bNVVddlZ/85Cf+f1gnwuU9uFp1bfa2v/Z1\n",
              "7VB28803Z/Hixbn33nszYMCAru0XXXRRbr311iTJ6tWr88ILL2TKlCn7tXYo2rZtW/7nf/6n6/4P\n",
              "f/jDDBw40OewBldccUU2btyYtra2tLW1ZdKkSbnttttyxRVX+By+T6+88kq2bdvWdX/x4sU55ZRT\n",
              "fA7rpZfOrSnK008/XU2aNKkaPXp0ddppp1Vr167t7ZEOCrNmzapOPPHEqk+fPtXgwYOrj370o1VV\n",
              "7X1/7evaoaijo6NKUo0cObIaP358NX78+GrixIlVVVXVpk2bqrPPPrsaNWpU9fGPf7y6//77u563\n",
              "r2uHora2tmrChAnVSSedVJ188snVWWed1XWCpM/hvnnrybk+h+/PL3/5y6q1tbUaN25cddJJJ1Xn\n",
              "n39+9dxzz1VV5XNYDy6yCAAUw4+KAIBiCBcAoBjCBQAohnABAIohXACAYggXAKAYwgUAKIZwAQCK\n",
              "IVwAgGIIFwCgGP8Pu+51wea6tbMAAAAASUVORK5CYII=\n",
              "\">\n",
              "      </div>\n",
              "      <script type=\"text/javascript\">\n",
              "        (() => {\n",
              "          const chartElement = document.getElementById(\"chart-d0c9b7b2-9daf-4e03-a232-25324583303e\");\n",
              "          async function getCodeForChartHandler(event) {\n",
              "            const chartCodeResponse =  await google.colab.kernel.invokeFunction(\n",
              "                'getCodeForChart', [\"chart-d0c9b7b2-9daf-4e03-a232-25324583303e\"], {});\n",
              "            const responseJson = chartCodeResponse.data['application/json'];\n",
              "            await google.colab.notebook.addCell(responseJson.code, 'code');\n",
              "          }\n",
              "          chartElement.onclick = getCodeForChartHandler;\n",
              "        })();\n",
              "      </script>\n",
              "      <style>\n",
              "        .colab-quickchart-chart-with-code  {\n",
              "            display: block;\n",
              "            float: left;\n",
              "            border: 1px solid transparent;\n",
              "        }\n",
              "\n",
              "        .colab-quickchart-chart-with-code:hover {\n",
              "            cursor: pointer;\n",
              "            border: 1px solid #aaa;\n",
              "        }\n",
              "      </style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<google.colab._quickchart_helpers.SectionTitle at 0x7ae70fe41dd0>"
            ],
            "text/html": [
              "<h4 class=\"colab-quickchart-section-title\">Categorical distributions</h4>\n",
              "<style>\n",
              "  .colab-quickchart-section-title {\n",
              "      clear: both;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "from matplotlib import pyplot as plt\n",
              "import seaborn as sns\n",
              "_df_1.groupby('Label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
              "plt.gca().spines[['top', 'right',]].set_visible(False)"
            ],
            "text/html": [
              "      <div class=\"colab-quickchart-chart-with-code\" id=\"chart-c8b8cdb8-4da1-4fe7-8b39-1816ec62331b\">\n",
              "        <img style=\"width: 180px;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAj8AAAGZCAYAAABmAVBZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\n",
              "bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\n",
              "YQAAD2EBqD+naQAAE6NJREFUeJzt3X+s1XX9wPHX+V7woilgmIjC5So/TLhyMbiAtiIDyX/S2irQ\n",
              "CrKaS+fAb6sxqs3aSmhjLLM559agcgM1ja0ftNECcS1+qUSIP7Bx41rcRORHOSAu9/39o3kn3xAB\n",
              "77kHeD0e29nuOZ97z3md8+G9+9znftinUkopAQCQxP/UegAAgJ4kfgCAVMQPAJCK+AEAUhE/AEAq\n",
              "4gcASEX8AACpiB8AIBXxAwCkkjZ+7rvvvlqPAADUQNr4+etf/1rrEQCAGkgbPwBATuIHAEhF/AAA\n",
              "qYgfACAV8QMApCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK\n",
              "+AEAUhE/AEAq4gcASEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgf\n",
              "ACAV8QMApCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEA\n",
              "UhE/AEAq4gcASEX8AACpiB8AIJVKKaXUeohauG10Jea1aL/jGbnkSK1HAIBu57c/AJCK+AEAUhE/\n",
              "AEAq4gcASEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgfACAV8QMA\n",
              "pCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq\n",
              "4gcASEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+\n",
              "AIBUxA8AkIr4AQBSET8AQCpVi58DBw7E9OnTY9SoUdHc3BzTpk2L1atXR1NTU8ycOTOamppi3Lhx\n",
              "sWnTpoiIaG9vj+uvvz7GjRsXo0ePjrvuuis6OzsjImLJkiUxderUuOWWW2LUqFFx3XXXxdatW+OT\n",
              "n/xkXHXVVTFt2rT417/+Va23AgCcRaoWP7/97W9j7969sXXr1vjTn/4Uy5Yti4iI5557LmbNmhVb\n",
              "tmyJuXPnxowZM6KUEv37949f/vKX8fTTT8fmzZujtbU1Hn300a7n27BhQ3z/+9+PrVu3xrBhw+Lj\n",
              "H/94PPjgg/H888/HOeecEz/5yU/edpZDhw7F/v37j7od6azWOwcATmdVi5/m5uZ4/vnn484774xH\n",
              "HnkkevfuHRERjY2NMWXKlIiI+MxnPhPt7e3R1tYWnZ2dMXfu3Ghubo5rrrkmNm7c2HVUKCLi2muv\n",
              "jYaGhoiIGD9+fLS0tMTAgQMjIqKlpSW2bdv2trPMnz8/+vXrd9Rt82tVeuMAwGmtavFzxRVXxNat\n",
              "W+PGG2+MP/zhD9HU1BR79uz5r++rVCpRqVRi0aJF8eqrr8a6deti8+bNceutt8bBgwe7vq9Pnz5d\n",
              "X9fV1f3X/Y6OjredZd68ebFv376jbmMu6qY3CgCcUaoWP6+88kpUKpW46aabYuHChVFKiba2tmht\n",
              "bY1Vq1ZFRMTPf/7zGDhwYAwePDj27NkTl1xySfTp0yfa29vjscce67ZZ6uvro2/fvkfd6pzqDQAp\n",
              "9arWE//5z3+OefPmRSklOjo64vOf/3yMGTMmRo8eHUuWLInZs2fHOeecE0uXLo1KpRJz5syJT33q\n",
              "UzF69Oi49NJLY+rUqdUaDQBIrFJKKT31YqtXr4677777qHN5auW20ZWY1+Lwz/GMXHKk1iMAQLfz\n",
              "2x8ASKVH4+cjH/nIaXHUBwDIy5EfACAV8QMApCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmI\n",
              "HwAgFfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq4gcASEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgB\n",
              "AFIRPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAg\n",
              "FfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq4gcASKVXrQeolQs/9r8xctGiWo8BAPQwR34AgFTEDwCQ\n",
              "ivgBAFIRPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmI\n",
              "HwAgFfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq4gcASEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgB\n",
              "AFIRPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+AIBUxA8AkEqvE/3G/fv3H3d737593/UwAADVdsLx\n",
              "079//6hUKlFK6XrszfuVSiWOHDlSlQEBALrTCcdPZ2dnNecAAOgRp3TOz9NPPx0/+9nPIiJi7969\n",
              "sXPnzm4dCgCgWk46fh544IH44he/GN/+9rcjImL37t1x6623dvdcAABVcdLx89BDD8XatWu7TnAe\n",
              "NmxY7Nq1q9sHAwCohpOOn/r6+jj33HOPeqxXrxM+dQgAoKZOOn7e9773xUsvvRSVSiUiIpYsWRIN\n",
              "DQ3dPhgAQDWc9CGbH/zgB3HLLbfECy+8EEOGDIm+ffvGr371q2rMBgDQ7U46foYPHx7r1q2LF198\n",
              "MUopceWVV0ZdXV01ZgMA6HandLLO+vXr43e/+11UKpWYOnVqTJw4sbvnAgCoipM+52fhwoUxffr0\n",
              "2L17d7z22msxffr0WLRoUTVmAwDodpXy1utVnICRI0fGH//4xxgwYEBERLz++usxadKkeOmll6oy\n",
              "YLV89atfFW0AkNBJH/np27dvV/hERLz3ve91UVMA4Ixxwuf8bN68OSIiPvrRj8YXvvCF+NKXvhQR\n",
              "//mv7lOnTq3OdAAA3eyE4+fmm28+6v6TTz7Z9XWlUokFCxZ031QAAFVywvGzffv2as4BANAjTvm6\n",
              "FIcOHYpDhw513XfeDwBwJjjpE57Xrl0bV111VZx33nlx4YUXdt0AAM4EJ33kZ86cObFkyZL4yle+\n",
              "EmvWrIkf/vCH0adPn2rMBgDQ7U76yM/hw4dj4sSJ0dHRERdccEF885vfjGXLllVjNgCAbnfS8dO7\n",
              "d++IiBgwYEA888wzsWvXrti1a1e3DwYAUA0nHT8zZsyI3bt3xze+8Y2YPHlyDBkyJL785S9XYzYA\n",
              "gG530pe3eKvDhw/HgQMHoqmpKXbs2NGdc1Wdy1sAQE6n/F/dI/7zJ7DevXvHu+gnAIAeddJ/9jqW\n",
              "SqXSHU8DAFB1J31tr2M5fPhwtwwDAFBtp3xtr7c699xzu2UYAIBqc20vACCVbjnnBwDgTCF+AIBU\n",
              "xA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq4gcASEX8\n",
              "AACpiB8AIBXxAwCkIn4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+AIBUxA8A\n",
              "kIr4AQBSET8AQCqVUkqp9RC1cP7HWqL/jCm1HgMAziqv3Lag1iO8I0d+AIBUxA8AkIr4AQBSET8A\n",
              "QCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq4gcASEX8AACpiB8AIBXxAwCk\n",
              "In4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+AIBUxA8AkIr4AQBSET8AQCri\n",
              "BwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq4gcASEX8AACpiB8AIBXxAwCkIn4A\n",
              "gFR6PH4qlUrs3bu3p18WACAiHPkBAJKpSfw88MADMWHChLj88stj8eLFXY9/7Wtfi5aWlhg7dmx8\n",
              "+MMfjhdffLFrW6VSie9973sxceLEaGxsjOXLl8f8+fNj/PjxMWLEiFi9enUN3gkAcKapSfzU19fH\n",
              "+vXrY8WKFTF79uzo6OiIiIi5c+fGhg0bYtOmTXHnnXfGnDlzjvq5888/P9atWxc//vGP43Of+1wM\n",
              "GjQoNm7cGPfee298/etff9vXO3ToUOzfv/+oWxwpVX2PAMDpqVctXvSzn/1sRES8//3vj169ekV7\n",
              "e3sMHjw4Vq5cGffff3/885//jM7Oznj99deP+rnp06dHRMT48ePjjTfeiBkzZkRExIQJE2Lbtm1v\n",
              "+3rz58+P73znO0c91vuKS7vzLQEAZ4iaHPnp06dP19d1dXXR0dERO3bsiLvuuisefvjh2LJlSyxb\n",
              "tiwOHjx4zJ+rq6v7r/tvHj06lnnz5sW+ffuOup1z+aDuflsAwBmgJkd+jmXfvn3Ru3fvGDRoUJRS\n",
              "4kc/+lG3PXd9fX3U19cf/WBdpdueHwA4c5w2/9vr6quvjhkzZsTo0aOjpaUlGhoaaj0SAHAWqpRS\n",
              "Up75e/7HWqL/jCm1HgMAziqv3Lag1iO8o9PmyA8AQE8QPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+\n",
              "AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEAUhE/AEAq4gcA\n",
              "SEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgfACAV8QMApCJ+AIBU\n",
              "xA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEAUulV6wFq5fbRH4pF\n",
              "ty2o9RgAQA9z5AcASEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgf\n",
              "ACAV8QMApCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVMQPAJCK+AEA\n",
              "UhE/AEAq4gcASEX8AACpiB8AIBXxAwCkIn4AgFTEDwCQivgBAFIRPwBAKuIHAEhF/AAAqYgfACAV\n",
              "8QMApCJ+AIBUxA8AkIr4AQBSET8AQCriBwBIRfwAAKmIHwAgFfEDAKQifgCAVHrVeoBaOHToUKxY\n",
              "sSKOHDkSdXV1tR4nrSNHjsT69etjwoQJ9kON2AenB/vh9GA/nB7eaT8MHTo05syZ865eo1JKKe/q\n",
              "Gc5A+/fvj379+sW+ffuib9++tR4nLfuh9uyD04P9cHqwH04PPbEf/NkLAEhF/AAAqYgfACCVlPFT\n",
              "X18f99xzT9TX19d6lNTsh9qzD04P9sPpwX44PfTEfkh5wjMAkFfKIz8AQF7iBwBIRfwAAKmki59t\n",
              "27bFddddFyNHjoyWlpZ47rnnaj3SWWP27NnR2NgYlUolNm3a1PX48T7zU93GsR08eDA+8YlPxMiR\n",
              "I6O5uTluuOGGePnllyMi4tVXX40bb7wxRowYEU1NTbFmzZqunzvVbby9adOmxZgxY2Ls2LHxoQ99\n",
              "KJ599tmIsB5qZfHixVGpVGL58uURYT30tMbGxrjyyitj7NixMXbs2HjkkUcioobroSRz/fXXl8WL\n",
              "F5dSSnnsscfK+PHjazvQWeTJJ58sbW1tZejQoeXZZ5/tevx4n/mpbuPYDhw4UH7961+Xzs7OUkop\n",
              "999/f5k8eXIppZTbbrut3HPPPaWUUtavX18uu+yy8u9///tdbePt7dmzp+vrJ554oowZM6aUYj3U\n",
              "wvbt28u1115bJk2aVH7xi1+UUqyHnvb/fy+8qVbrIVX8/OMf/ygXXHBBOXz4cCmllM7OzjJw4MCy\n",
              "bdu2Gk92dnnrP/Ljfeanuo0Tt2HDhjJ06NBSSinvec97ys6dO7u2tbS0lJUrV76rbZyYxYsXl+bm\n",
              "ZuuhBo4cOVKmTJlSNm7cWCZPntwVP9ZDzzpW/NRyPaS6sGlbW1sMGjQoevX6z9uuVCrR0NAQO3bs\n",
              "iOHDh9d4urPT8T7zfv36ndI2++rE3XfffXHzzTfH7t274/Dhw3HJJZd0bWtsbIwdO3ac8jbe2cyZ\n",
              "M2PVqlUREfGb3/zGeqiBRYsWxQc/+MEYN25c12PWQ23MnDkzSikxYcKEWLBgQU3XQ7pzfiCLe++9\n",
              "N15++eWYP39+rUdJ66c//Wm0tbXFd7/73Zg7d26tx0lny5Yt8fjjj8e3vvWtWo+S3po1a2Lz5s3x\n",
              "zDPPxEUXXRSzZs2q6Typ4mfIkCGxc+fO6OjoiIiIUkrs2LEjGhoaajzZ2et4n/mpbuOdLVy4MJ54\n",
              "4olYsWJFnHfeeTFgwIDo1atXtLe3d31Pa2trNDQ0nPI2TtysWbNi1apVMXjwYOuhBz311FPR2toa\n",
              "I0aMiMbGxli7dm3cfvvt8eijj1oPPezNz6h3795x9913x1NPPVXT3w+p4ufiiy+OD3zgA/Hwww9H\n",
              "RMTjjz8egwcPdti4io73mZ/qNo5v0aJFsXTp0li5cmX079+/6/FPf/rT8eCDD0ZExIYNG+Jvf/tb\n",
              "TJ48+V1t49j27t0bf//737vuL1++PAYMGGA99LA77rgjdu7cGa2trdHa2hqTJk2Khx56KO644w7r\n",
              "oQe98cYbsXfv3q77S5cujWuuuaa26+FdnL90RnrhhRfKpEmTyogRI8q4cePK5s2baz3SWeP2228v\n",
              "l112WamrqysXX3xxGTZsWCnl+J/5qW7j2Nra2kpElCuuuKI0NzeX5ubmMmHChFJKKe3t7eWGG24o\n",
              "w4cPL6NGjSq///3vu37uVLdxbK2traWlpaU0NTWVMWPGlClTpnSd7Gk91M5bT3i2HnrOX/7ylzJ2\n",
              "7Nhy9dVXl6ampnLTTTeV7du3l1Jqtx5c2wsASCXVn70AAMQPAJCK+AEAUhE/AEAq4gcASEX8AACp\n",
              "iB8AIBXxAwCkIn4AgFTEDwCQivgBAFL5P7QkPfZ+RLjqAAAAAElFTkSuQmCC\n",
              "\">\n",
              "      </div>\n",
              "      <script type=\"text/javascript\">\n",
              "        (() => {\n",
              "          const chartElement = document.getElementById(\"chart-c8b8cdb8-4da1-4fe7-8b39-1816ec62331b\");\n",
              "          async function getCodeForChartHandler(event) {\n",
              "            const chartCodeResponse =  await google.colab.kernel.invokeFunction(\n",
              "                'getCodeForChart', [\"chart-c8b8cdb8-4da1-4fe7-8b39-1816ec62331b\"], {});\n",
              "            const responseJson = chartCodeResponse.data['application/json'];\n",
              "            await google.colab.notebook.addCell(responseJson.code, 'code');\n",
              "          }\n",
              "          chartElement.onclick = getCodeForChartHandler;\n",
              "        })();\n",
              "      </script>\n",
              "      <style>\n",
              "        .colab-quickchart-chart-with-code  {\n",
              "            display: block;\n",
              "            float: left;\n",
              "            border: 1px solid transparent;\n",
              "        }\n",
              "\n",
              "        .colab-quickchart-chart-with-code:hover {\n",
              "            cursor: pointer;\n",
              "            border: 1px solid #aaa;\n",
              "        }\n",
              "      </style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<google.colab._quickchart_helpers.SectionTitle at 0x7ae70f88abd0>"
            ],
            "text/html": [
              "<h4 class=\"colab-quickchart-section-title\">Time series</h4>\n",
              "<style>\n",
              "  .colab-quickchart-section-title {\n",
              "      clear: both;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "from matplotlib import pyplot as plt\n",
              "import seaborn as sns\n",
              "def _plot_series(series, series_name, series_index=0):\n",
              "  palette = list(sns.palettes.mpl_palette('Dark2'))\n",
              "  counted = (series['index']\n",
              "                .value_counts()\n",
              "              .reset_index(name='counts')\n",
              "              .rename({'index': 'index'}, axis=1)\n",
              "              .sort_values('index', ascending=True))\n",
              "  xs = counted['index']\n",
              "  ys = counted['counts']\n",
              "  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])\n",
              "\n",
              "fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')\n",
              "df_sorted = _df_2.sort_values('index', ascending=True)\n",
              "for i, (series_name, series) in enumerate(df_sorted.groupby('Label')):\n",
              "  _plot_series(series, series_name, i)\n",
              "  fig.legend(title='Label', bbox_to_anchor=(1, 1), loc='upper left')\n",
              "sns.despine(fig=fig, ax=ax)\n",
              "plt.xlabel('index')\n",
              "_ = plt.ylabel('count()')"
            ],
            "text/html": [
              "      <div class=\"colab-quickchart-chart-with-code\" id=\"chart-8f429ac6-cc9b-4621-843f-88c7fab4dc19\">\n",
              "        <img style=\"width: 180px;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABEMAAAITCAYAAADsAtIvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\n",
              "bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\n",
              "YQAAD2EBqD+naQAALGNJREFUeJzt3Xu01XWd//HX5hw45oXLKIJ2PBwR0BQRb4xKSaYlNUma5mil\n",
              "Ul7IyaXFlGbFpFOjWYaZ0ww6OZY5Y2NqLrpMazVqhpdCUyRFS4wToOKluJhyOYfz/f3R6vw6eQM8\n",
              "hw18Ho+19lpnf7/fvfd723d9Yz3X9/vdtaqqqgAAAAAUok+9BwAAAADYmMQQAAAAoChiCAAAAFAU\n",
              "MQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAomzxMeTyyy+v9wgAAADAJqSx3gP0tt/9\n",
              "7nf1HgEAAAB6XGdnZ1avXp01a9bUe5SNrrGxMQ0NDS9Z3rdv35dd/pLX98ZQAAAAQO954YUX0tbW\n",
              "lo6OjtRqtXqPUxcNDQ3p06f7BS+1Wi3Nzc3ZdtttX/W1YggAAABsRjo6OjJ//vxstdVW2WmnndLU\n",
              "1FRcEOno6EhnZ2e3715VVZ599tksXrw4I0eOfNUzRMQQAAAA2Iy88MILqdVq2XnnnbPddtvVe5y6\n",
              "+PMlQk1NTd3ODhk8eHDa2trS3t7+qjFki7+BKgAAAGyJ1uXeGKVZ1zNkxBAAAACgKGIIAAAAFGzu\n",
              "3Ll58cUXkyStra2ZM2dOj27/Z/fdd186OjqS/OkMjmXLlm3oyK+bGAIAAAAUxQ1UAQAAgG6WLFmS\n",
              "P/zhD6mqKt/61rdy6623Zu3atenbt2/OPvvsDBo0qOtGpVdddVV+8YtfZPny5fnwhz+c973vfWlv\n",
              "b09bW1suu+yyLFu2LKtXr87EiRMzduzYen+1JGIIAAAA8Fe23377DB06NEly5pln5uSTT87o0aPz\n",
              "85//PCeeeGJuu+22vOlNb0rfvn2zaNGi/PSnP82qVasyZsyYHHzwwTn00ENz8skn53Of+1ze9ra3\n",
              "pVarZZ999skxxxyTgw8+uM7fTgwBAAAA/sqLL76Yp556KmvXrs1dd92VGTNmZM2aNWlsbExbW1u2\n",
              "2Wabrl9uOemkk/L8889n0KBBOeyww3LTTTfl+eefz0MPPZRPfvKTaWxsTGNjY1588cU88sgjYggA\n",
              "AACwaens7Mzjjz+e3XffPX379s3f/u3f5utf/3o+8IEP5MUXX8yAAQOyevXql31trVbLkCFDsttu\n",
              "u2X77bfPo48+2rXuvvvu22Quk3EDVQAAAKBLVVWpqir9+vXLqlWrsmbNmq5LZq644ookyR/+8Ieu\n",
              "7f/rv/4r/fv3z4svvpjbb789+++/f3bffff0798/V111VdcvyCxatKjb6+rJmSEAAABQuN/85jep\n",
              "1WpZs2ZN3vGOd6Rfv37p7OxMrVbLxz72sUyePDk77bRTTjzxxCRJY2Nj5s2bl/b29jQ3N2fChAlZ\n",
              "vnx5zjrrrIwcOTK//vWvM3369HzpS1/KFVdckc7OzjQ1NeV73/tenb/pn9SqqqrqPURvmjp1aqZP\n",
              "n17vMQAAAKBHLF++PL/73e8yYsSIbL311vUepy46OzuzevXqNDU1pU+f/3/Ry6pVq7JgwYLsuuuu\n",
              "2WqrrV7x9S6TAQAAAIoihgAAAABFEUMAAACAooghAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAeN1q\n",
              "tVqee+65eo+xTsQQAAAAoChiCAAAAGzGOjs78/zqVb366OzsXKdZvvKVr2TMmDF54xvfmK997Wtd\n",
              "y6dMmZLRo0dnjz32yAEHHJC5c+d2ravVavnUpz7V9brrrrsun/70pzN69OgMGzYsP/rRj3r8v1lj\n",
              "j78jAAAAsNG80L4mb/rvC3r1Mx55/wXZrmmr19yuqakpc+fOzZw5czJ+/PiceeaZ6du3bz73uc9l\n",
              "5513TpJ84xvfyEc/+tHMmjWr63Xbbrtt5s6dm5kzZ+aEE07IJZdckoceeijXXHNNzj333LzrXe/q\n",
              "0e8jhgAAAAA94tRTT02SjB07Ng0NDVm0aFGGDx+e73//+/n3f//3vPDCC+ns7Mzy5cu7ve6UU05J\n",
              "kowfPz4rV67sep/x48fn7LPP7vE5xRAAAADYjG3Tt18eef8Fvf4Z6+INb3hD198NDQ1pb2/PY489\n",
              "lnPPPTf33HNP9txzz/ziF7/IEUcc8bKva2z8U6bYeuutu56vXbu2J75CN2IIAAAAbMb69OmzTpew\n",
              "1MvSpUvT2NiYXXbZJZ2dnfnqV79a75HcQBUAAADoPePGjct73vOe7LHHHhkzZkx22WWXeo/kzBAA\n",
              "AADg9auqqtvzpUuXdv39n//5n93WfelLX3rZ1w0YMKDb8+HDh+fFF1/s6VGdGQIAAACURQwBAAAA\n",
              "iiKGAAAAAEURQwAAAGAz9Nf36GDduYEqAAAAbEb69u2bJOno6EhHR0f69CnvPIf29vYkSa1W26DX\n",
              "iyEAAACwGenTp08aGxtTq9W6okCJ+vXrJ4YAAABAKWq1Wvr27ZumpqZ6j1IXtVptg0NIIoYAAADA\n",
              "ZqlWqxV5iUxPEEMAAABgM1ZVVao1L/bqZ9T6bf26zsTY1IghAAAAsBmr1ryY+VP69+pnjLhyRWpN\n",
              "27zqNitXrszkyZPzq1/9Kn379s2QIUPy6U9/OmeddVb222+/3H///WlqasrVV1+dsWPHZsmSJTnx\n",
              "xBOzYsWKrFq1Kocddli+9rWvpU+fPvnmN7+Z6667LoMHD86DDz6YgQMH5hvf+EY+85nP5NFHH80u\n",
              "u+ySm2++Odtuu+0GfR/n0wAAAACv249//OMsW7Ys8+bNy4MPPpjvfOc7SZKHH344p5xySh566KGc\n",
              "d955OeGEE1JVVQYOHJjvf//7+eUvf5m5c+emra0tN9xwQ9f73Xvvvbnkkksyb9687LbbbjnqqKMy\n",
              "Y8aMPPLII+nXr1++9a1vbfCszgwBAACAzVit39YZceWKXv+M17LPPvvkkUceyT/8wz9kwoQJede7\n",
              "3pUkaW1tzeGHH54kOf7443PGGWdk0aJF2WGHHXLeeeflzjvvTFVVeeaZZzJ69OiccMIJSZKDDz44\n",
              "LS0tSZIDDjgg7e3tGTJkSJLkwAMPzGOPPbbB38eZIQAAALAZq9Vq6dO0Ta8+1uV+IcOHD8+8efMy\n",
              "ceLE3HXXXRk9enSWLl36svPWarVMnz49zzzzTH7xi19k7ty5ef/7359Vq1Z1bbfVVlt1/d3Q0PCS\n",
              "5x0dHRv830wMAQAAAF63xYsXp1arZdKkSbn00ktTVVUWLVqUtra23H777UmSG2+8MUOGDElzc3OW\n",
              "Ll2aoUOHZquttsqSJUvy3e9+d6PN6jIZAAAA4HX71a9+lfPPPz9VVaWjoyMnnXRSxowZk7322ivf\n",
              "/OY3c/bZZ6dfv365/vrrU6vVcs455+S4447LXnvtlZ133jlHHHHERpu1VlVVtdE+rQ6mTp2a6dOn\n",
              "13sMAAAA6BGrVq3KggULsuuuu3a7dGRT9NOf/jQf+9jHMmfOnI3yeev638ZlMgAAAEBRxBAAAACg\n",
              "V7z1rW/daGeFrA8xBAAAACiKGAIAAACboc7OznqPsMlZ19ui+jUZAAAA2Iz069cvffr0yZNPPpnB\n",
              "gwenX79+qdVq9R6r7qqqyrPPPptarZa+ffu+6rZiCAAAAGxG+vTpk1133TVPPfVUnnzyyXqPs0mp\n",
              "1Wppbm5OQ0PDq24nhgAAAMBmpl+/fmlpaUlHR0fWrl1b73E2GX379n3NEJKIIQAAALBZ+vPlIK91\n",
              "SQgv5QaqAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAA\n",
              "gKL0agw5++yz09ramlqtljlz5rzidldffXVGjhyZ3XbbLaeffnra29u7ra+qKm9729sycODA3hwX\n",
              "AAAAKECvxpDjjjsud955Z4YNG/aK2yxYsCDTpk3LrFmzMn/+/Dz99NO56qqrum1z2WWXZbfdduvN\n",
              "UQEAAIBC9GoMOfTQQ9Pc3Pyq29x4442ZNGlShg4dmlqtlo985CO5/vrru9Y//PDDueWWW/KpT33q\n",
              "NT9v9erVWbFiRbfH2rVrX/f3AAAAALYcdb9nyMKFC7udOdLa2pqFCxcmSdrb23P66afnyiuvTEND\n",
              "w2u+18UXX5wBAwZ0e8yePbvXZgcAAAA2P3WPIa/mwgsvzHvf+9686U1vWqftzz///CxfvrzbY9y4\n",
              "cb08JQAAALA5aaz3AC0tLXn88ce7nre1taWlpSVJcscdd2ThwoX513/913R0dGTFihVpbW3Nvffe\n",
              "m8GDB7/kvZqamtLU1NRt2bqcUQIAAACUo+5nhhx77LGZOXNmlixZkqqqMmPGjJxwwglJklmzZuV3\n",
              "v/td2tracuedd6Z///5pa2t72RACAAAAsC56NYZMmTIlzc3NWbx4cY488siMGDEiSXLaaadl5syZ\n",
              "SZLhw4fnwgsvzPjx4zNixIgMHjw4U6ZM6c2xAAAAgILVqqqq6j1Eb5o6dWqmT59e7zEAAACATUTd\n",
              "L5MBAAAA2JjEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKI\n",
              "IQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEA\n",
              "AABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAooghAAAA\n",
              "QFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKIIQAAAEBR\n",
              "xBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEAAABAUcQQ\n",
              "AAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAooghAAAAQFHEEAAA\n",
              "AKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKIIQAAAEBRxBAAAACg\n",
              "KGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEAAABAUcQQAAAAoChi\n",
              "CAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAooghAAAAQFHEEAAAAKAoYggA\n",
              "AABQFDEEAAAAKIoYAgAAABRFDAEAAACK0qsx5Oyzz05ra2tqtVrmzJnzittdffXVGTlyZHbbbbec\n",
              "fvrpaW9vT5LcdtttGTduXPbcc8/stddeOffcc9PZ2dmbIwMAAABbuF6NIccdd1zuvPPODBs27BW3\n",
              "WbBgQaZNm5ZZs2Zl/vz5efrpp3PVVVclSQYNGpTvfOc7mTdvXn75y1/m7rvvzrXXXtubIwMAAABb\n",
              "uF6NIYceemiam5tfdZsbb7wxkyZNytChQ1Or1fKRj3wk119/fZJk3333zfDhw5MkW221VcaOHZu2\n",
              "trZXfK/Vq1dnxYoV3R5r167tse8DAAAAbP7qfs+QhQsXdjtzpLW1NQsXLnzJdkuWLMmNN96Yd7/7\n",
              "3a/4XhdffHEGDBjQ7TF79uxemRsAAADYPNU9hqyLFStW5Kijjsq5556bAw444BW3O//887N8+fJu\n",
              "j3Hjxm3ESQEAAIBNXWO9B2hpacnjjz/e9bytrS0tLS1dz59//vlMnDgx73nPezJ16tRXfa+mpqY0\n",
              "NTV1W9bQ0NCzAwMAAACbtbqfGXLsscdm5syZWbJkSaqqyowZM3LCCSckSf74xz9m4sSJmThxYj77\n",
              "2c/WeVIAAABgS9CrMWTKlClpbm7O4sWLc+SRR2bEiBFJktNOOy0zZ85MkgwfPjwXXnhhxo8fnxEj\n",
              "RmTw4MGZMmVKkuTyyy/P7Nmzc/PNN2fs2LEZO3Zs/uVf/qU3RwYAAAC2cLWqqqp6D9Gbpk6dmunT\n",
              "p9d7DAAAAGATUffLZAAAAAA2JjEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKIIQAA\n",
              "AEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEAAABA\n",
              "UcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAooghAAAAQFHE\n",
              "EAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKIIQAAAEBRxBAA\n",
              "AACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEAAABAUcQQAAAA\n",
              "oChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAooghAAAAQFHEEAAAAKAo\n",
              "YggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKIIQAAAEBRxBAAAACgKGII\n",
              "AAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEAAABAUcQQAAAAoCiNG/Ki\n",
              "efPmZfHixXnDG96QvffeOwMHDuzhsQAAAAB6xzrHkOeffz6XXnpp/uM//iNbb711hgwZklWrVuXx\n",
              "xx/PuHHjct555+Xwww/vzVkBAAAAXrd1jiGHHXZYTj755DzwwAMZMmRI1/LOzs7MmjUrM2bMyPz5\n",
              "8zNlypReGRQAAACgJ6xzDLnrrrvS1NT0kuV9+vTJhAkTMmHChKxevbpHhwMAAADoaet8A9WXCyEb\n",
              "sg0AAABAPa1zDHn3u9+du++++2XXLVu2LF/5yldy5ZVX9thgAAAAAL1hnS+Tueiii3L++edn3rx5\n",
              "OfDAA7tuoProo4/miSeeyEc/+tF8+MMf7s1ZAQAAAF63dY4hY8aMyQ9/+MMsWrQod9xxRxYvXpyt\n",
              "t946H/jAB/LmN785jY0b9Cu9AAAAABvVeheMpUuX5oMf/GC3ZXPnzs2YMWN6bCgAAACA3rLO9wz5\n",
              "s8mTJ6/TMgAAAIBN0TqfGfLMM89kyZIlWblyZX71q1+lqqokyfLly/PCCy/02oAAAAAAPWmdY8j1\n",
              "11+fr371q3nyySczadKkruUDBgzIueee2yvDAQAAAPS0dY4h55xzTs4555x8/vOfz7Rp03pzJgAA\n",
              "AIBes943UJ02bVo6OzuzZMmSdHR0dC1vaWnp0cEAAAAAesN630D1W9/6VgYOHJi99947+++/f/bf\n",
              "f/8ccMABL7vt2WefndbW1tRqtcyZM+cV3/Pqq6/OyJEjs9tuu+X0009Pe3v7Oq0DAAAAWF/rHUP+\n",
              "+Z//Offee29+//vf59lnn82zzz6bZ5555mW3Pe6443LnnXdm2LBhr/h+CxYsyLRp0zJr1qzMnz8/\n",
              "Tz/9dK666qrXXAcAAACwIdb7Mpkddtghu++++zpte+ihh77mNjfeeGMmTZqUoUOHJkk+8pGP5KKL\n",
              "LspHP/rRV123JVnZvibfefhn9R4DAABgi7XTwKGZ2Dq63mOwiVjvGHL00Ufnq1/9at7//vdnq622\n",
              "6lrev3//DRpg4cKF3c4caW1tzcKFC19z3ctZvXp1Vq9e3W3Z2rVrN2iujWnlyuUZ/9Uj6z0GAADA\n",
              "Fuui910hhtBlvS+T+cxnPpOpU6dm6NChGTRoUAYOHJhBgwb1xmzr7eKLL86AAQO6PWbPnl3vsV5T\n",
              "3z4N9R4BAABgi/a3Q1vrPQKbkPU+M6Szs7NHB2hpacnjjz/e9bytra3rl2lebd3LOf/88zN16tRu\n",
              "yzaHnwHedptBGXHlinqPAQAAsMUa2W/reo/AJmS9Y0hPO/bYY/PmN785F1xwQYYMGZIZM2bkhBNO\n",
              "eM11L6epqSlNTU3dljU0bPpnXdRqtdSatqn3GAAAAFCE9b5Mpk+fPmloaHjJ4+VMmTIlzc3NWbx4\n",
              "cY488siMGDEiSXLaaadl5syZSZLhw4fnwgsvzPjx4zNixIgMHjw4U6ZMec11AAAAABuiVlVVtT4v\n",
              "eOGFF7r+XrlyZa699tqsXbs2n/zkJ3t8uJ4wderUTJ8+vd5jAAAAAJuI9T4zZJtttul67LDDDpk6\n",
              "dWpuvPHG3pgNAAAAoMetdwz5a48++miee+65npgFAAAAoNet9w1UBw0alFqtliTp6OhIklxxxRU9\n",
              "OxUAAABAL1nvGDJnzpz//+LGxgwdOnSz+MUWAAAAgGQDYsiwYcPy4osvdkWRQYMGZeut/V4zAAAA\n",
              "sHlY7xhy991359hjj83QoUOTJE8//XRuuummHHzwwT0+HAAAAEBPW+8Y8udfjxk/fnySP8WRj3/8\n",
              "4/n5z3/e48MBAAAA9LT1/jWZlStXdoWQJDnkkEOyatWqHh0KAAAAoLesdwzZdttt83//939dz2+9\n",
              "9dZss802PToUAAAAQG9Z78tkvva1r+W9731v1y/IdHZ25uabb+7xwQAAAAB6w3rHkCeffDL33Xdf\n",
              "nn766STJkCFDMnv27B4fDAAAAKA3rPdlMtOmTcvgwYMzevTojB49OjvssEOmTZvWG7MBAAAA9Lj1\n",
              "jiF/rVarZe3atT0xCwAAAECvW+8Yst122+Xuu+/uen7XXXdlu+2269GhAAAAAHrLet8z5Etf+lKO\n",
              "OeaY7LHHHkmSxx57LN/73vd6fDAAAACA3rDeMeTggw/OI488knvuuSdJcsghh2TgwIE9PRcAAABA\n",
              "r1jvGJIkgwYNyrve9a6engUAAACg173uG6gCAAAAbE7EEAAAAKAoYggAAABQFDEEAAAAKIoYAgAA\n",
              "ABRFDAEAAACKIoYAAAAARRFDAAAAgKKIIQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAU\n",
              "RQwBAAAAiiKGAAAAAEURQwAAAICiiCEAAABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUM\n",
              "AQAAAIoihgAAAABFEUMAAACAooghAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEA\n",
              "AACKIoYAAAAARRFDAAAAgKKIIQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAA\n",
              "iiKGAAAAAEURQwAAAICiiCEAAABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoi\n",
              "hgAAAABFEUMAAACAooghAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYA\n",
              "AAAARRFDAAAAgKKIIQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAitKrMeSx\n",
              "xx7LIYccklGjRuXAAw/Mww8//JJtOjs784lPfCKjR4/OHnvskVNPPTVr1qzpWn/JJZdkzz33zNix\n",
              "Y3PQQQdl9uzZvTkyAAAAsIXr1RgyZcqUnHHGGfnNb36T8847L5MnT37JNldffXXuv//+3H///Xnk\n",
              "kUfSp0+fXH755UmSOXPm5N/+7d8ye/bszJkzJ2eddVbOOuus3hwZAAAA2ML1Wgx55plnct999+WD\n",
              "H/xgkuTYY4/NokWLMn/+/G7bPfjggzniiCPSr1+/1Gq1vPOd78y3v/3tJEmtVkt7e3teeOGFJMmy\n",
              "ZcvS3Nz8ip+5evXqrFixottj7dq1vfQNAQAAgM1Rr8WQRYsWZaeddkpjY2OSP4WNlpaWLFy4sNt2\n",
              "+++/f2bOnJkVK1akvb09N9xwQ9ra2pIk++yzTz7+8Y9n1113TXNzcy677LJcccUVr/iZF198cQYM\n",
              "GNDt4bIaAAAA4C/V/QaqkydPzsSJEzNhwoRMmDAho0aN6gooCxYsyM0335z58+dn8eLF+fjHP56/\n",
              "//u/f8X3Ov/887N8+fJuj3Hjxm2srwIAAABsBnothuyyyy556qmn0tHRkSSpqioLFy5MS0tLt+1q\n",
              "tVouuOCCPPDAA7n77ruz5557Zq+99kqS3HTTTdl7772z8847J0k+9KEP5a677up2g9W/1NTUlP79\n",
              "+3d7NDQ09NZXBAAAADZDvRZDdtxxx+y333657rrrkvwpbDQ3N2fEiBHdtlu1alWWLl2aJHnuuefy\n",
              "xS9+Meeee26SZPjw4bnrrrvyxz/+MUnygx/8IKNGjUq/fv16a2wAAABgC9fYm29+5ZVXZvLkybno\n",
              "oovSv3//XHPNNUmS0047LZMmTcqkSZOyfPnyvPWtb02fPn3S2dmZc845J0cddVSS5Jhjjsm9996b\n",
              "Aw44IE1NTdlmm23y3//93705MgAAALCFq1VVVdV7iN40derUTJ8+vd5jAAAAAJuIut9AFQAAAGBj\n",
              "EkMAAACAooghAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFD\n",
              "AAAAgKKIIQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAA\n",
              "AICiiCEAAABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACA\n",
              "ooghAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKI\n",
              "IQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEA\n",
              "AABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAooghAAAA\n",
              "QFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKIIQAAAEBR\n",
              "xBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEAAABAUcQQ\n",
              "AAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACAooghAAAAQFHEEAAA\n",
              "AKAoYggAAABQFDEEAAAAKEqvxpDHHnsshxxySEaNGpUDDzwwDz/88Eu26ezszCc+8YmMHj06e+yx\n",
              "R0499dSsWbOma/3ChQtz1FFHZffdd8+ee+6ZK664ojdHBgAAALZwvRpDpkyZkjPOOCO/+c1vct55\n",
              "52Xy5Mkv2ebqq6/O/fffn/vvvz+PPPJI+vTpk8svvzxJUlVVjjnmmJx88sn59a9/nXnz5uX444/v\n",
              "zZEBAACALVyvxZBnnnkm9913Xz74wQ8mSY499tgsWrQo8+fP77bdgw8+mCOOOCL9+vVLrVbLO9/5\n",
              "znz7299Oktx6661pamrK+973vq7thwwZ8oqfuXr16qxYsaLbY+3atb3w7QAAAIDNVa/FkEWLFmWn\n",
              "nXZKY2NjkqRWq6WlpSULFy7stt3++++fmTNnZsWKFWlvb88NN9yQtra2JMm8efMyePDgnHDCCdl3\n",
              "331zzDHH5Le//e0rfubFF1+cAQMGdHvMnj27t74iAAAAsBmq+w1UJ0+enIkTJ2bChAmZMGFCRo0a\n",
              "1RVQOjo6ctttt2XatGl54IEHcuSRR77qZTLnn39+li9f3u0xbty4jfVVAAAAgM1Ar8WQXXbZJU89\n",
              "9VQ6OjqS/On+HwsXLkxLS0u37Wq1Wi644II88MADufvuu7Pnnntmr732SpK0tLRk33337Xp+0kkn\n",
              "5f777097e/vLfmZTU1P69+/f7dHQ0NBbXxEAAADYDPVaDNlxxx2z33775brrrkuS3HTTTWlubs6I\n",
              "ESO6bbdq1aosXbo0SfLcc8/li1/8Ys4999wkyTvf+c4sXrw4TzzxRJLkRz/6Ud70pjelb9++vTU2\n",
              "AAAAsIVr7M03v/LKKzN58uRcdNFF6d+/f6655pokyWmnnZZJkyZl0qRJWb58ed761remT58+6ezs\n",
              "zDnnnJOjjjoqSbLNNttkxowZ+bu/+7tUVZUBAwbkO9/5Tm+ODAAAAGzhalVVVfUeojdNnTo106dP\n",
              "r/cYAAAAwCai7jdQBQAAANiYxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAA\n",
              "AEURQwAAAICiiCEAAABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABF\n",
              "EUMAAACAooghAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFD\n",
              "AAAAgKKIIQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAA\n",
              "AICiiCEAAABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFEUMAQAAAIoihgAAAABFEUMAAACA\n",
              "ooghAAAAQFHEEAAAAKAoYggAAABQFDEEAAAAKIoYAgAAABRFDAEAAACKIoYAAAAARRFDAAAAgKKI\n",
              "IQAAAEBRxBAAAACgKGIIAAAAUBQxBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEA\n",
              "AABAUcQQAAAAoChiCAAAAFAUMQQAAAAoSq2qqqreQ/Sm9773vWltba33GK9p7dq1mT17dsaNG5eG\n",
              "hoZ6j8MWyn7GxmJfY2Own7Ex2M/YWOxr/KVhw4blnHPOqfcYW7QtPoZsLlasWJEBAwZk+fLl6d+/\n",
              "f73HYQtlP2Njsa+xMdjP2BjsZ2ws9jXYuFwmAwAAABRFDAEAAACKIoYAAAAARRFDNhFNTU353Oc+\n",
              "l6ampnqPwhbMfsbGYl9jY7CfsTHYz9hY7GuwcbmBKgAAAFAUZ4YAAAAARRFDAAAAgKKIIQAAAEBR\n",
              "xJBNwGOPPZZDDjkko0aNyoEHHpiHH3643iOxmTj77LPT2tqaWq2WOXPmdC1/tX1qQ9dRrlWrVuXo\n",
              "o4/OqFGjss8+++Ttb3975s+fnyR55plnMnHixIwcOTKjR4/Oz372s67Xbeg6yvaOd7wjY8aMydix\n",
              "Y/OWt7wlDzzwQBLHNXrHNddck1qtlltuuSWJYxo9q7W1NbvvvnvGjh2bsWPH5n/+53+SOJ7BJqOi\n",
              "7g477LDqmmuuqaqqqr773e9WBxxwQH0HYrNxxx13VIsWLaqGDRtWPfDAA13LX22f2tB1lGvlypXV\n",
              "D3/4w6qzs7Oqqqq64oorqgkTJlRVVVUf+tCHqs997nNVVVXV7Nmzqze+8Y3VmjVrXtc6yrZ06dKu\n",
              "v2+++eZqzJgxVVU5rtHzFixYUB188MHVQQcdVH3ve9+rqsoxjZ711/8++zPHM9g0iCF19vTTT1fb\n",
              "bbdd1d7eXlVVVXV2dlZDhgypHnvssTpPxubkL//P9tX2qQ1dB3/p3nvvrYYNG1ZVVVVts8021VNP\n",
              "PdW17sADD6x+8pOfvK518GfXXHNNtc8++ziu0ePWrl1bHX744dV9991XTZgwoSuGOKbRk14uhjie\n",
              "waajsd5nppRu0aJF2WmnndLY+Kf/KWq1WlpaWrJw4cKMGDGiztOxOXq1fWrAgAEbtM6+yF+6/PLL\n",
              "8573vCe///3v097enqFDh3ata21tzcKFCzd4HSTJySefnNtvvz1J8qMf/chxjR43ffr0jB8/Pvvv\n",
              "v3/XMsc0esPJJ5+cqqoybty4fPGLX3Q8g02Ie4YAsM4uuuiizJ8/PxdffHG9R2ELdu2112bRokX5\n",
              "whe+kPPOO6/e47CFeeihh3LTTTfls5/9bL1HYQv3s5/9LHPnzs3999+fHXbYIaecckq9RwL+ghhS\n",
              "Z7vsskueeuqpdHR0JEmqqsrChQvT0tJS58nYXL3aPrWh6yBJLr300tx888353//932y99dbZfvvt\n",
              "09jYmCVLlnRt09bWlpaWlg1eB3/plFNOye23357m5mbHNXrMrFmz0tbWlpEjR6a1tTU///nPc8YZ\n",
              "Z+SGG25wTKNH/Xkf6Nu3bz72sY9l1qxZ/p0GmxAxpM523HHH7LfffrnuuuuSJDfddFOam5ud7sYG\n",
              "e7V9akPXwfTp03P99dfnJz/5SQYOHNi1/H3ve19mzJiRJLn33nvzxBNPZMKECa9rHeVatmxZnnzy\n",
              "ya7nt9xyS7bffnvHNXrUmWeemaeeeiptbW1pa2vLQQcdlKuuuipnnnmmYxo95oUXXsiyZcu6nl9/\n",
              "/fXZd999Hc9gU1Kne5XwFx599NHqoIMOqkaOHFntv//+1dy5c+s9EpuJM844o3rjG99YNTQ0VDvu\n",
              "uGO12267VVX16vvUhq6jXIsWLaqSVMOHD6/22Wefap999qnGjRtXVVVVLVmypHr7299ejRgxotpz\n",
              "zz2r2267ret1G7qOcrW1tVUHHnhgNXr06GrMmDHV4Ycf3nXzQcc1estf3kDVMY2e8vjjj1djx46t\n",
              "9t5772r06NHVpEmTqgULFlRV5XgGm4paVVVVvYMMAAAAwMbiMhkAAACgKGIIAAAAUBQxBAAAACiK\n",
              "GAIAhRs7dmyef/759X7dcccdl29+85s9PxAAQC9rrPcAAEB9zZkzp94jAABsVM4MAYDC1Wq1LFu2\n",
              "LEnS2tqaf/qnf8rBBx+cXXfdNV/4whe6tnv00UdzyCGHZK+99srRRx+dFStWdK17/vnnc/rpp2fc\n",
              "uHEZM2ZMzjjjjKxZsya//vWv09zcnN/+9rdJkksvvTQTJ05MZ2fnRv2OAAB/SQwBALpZtmxZ7rnn\n",
              "ntx777358pe/nCeeeCJJctJJJ+XUU0/Nww8/nM9//vO54447ul7zj//4j3nLW96S2bNn58EHH0xn\n",
              "Z2cuv/zy7L777vnyl7+c448/Pj/96U/z9a9/Pd/+9rfTp49/ggAA9eMyGQCgm/e///1Jkh122CHD\n",
              "hw/PggULst1222XOnDmZPHlykmTvvffOm9/85q7X3HLLLbnnnnsyffr0JMnKlSvT0NCQJDnxxBNz\n",
              "++2358gjj8ytt96awYMHb9wvBADwV8QQAKCbrbbaquvvhoaGdHR0vOx2tVqt6++qqnLTTTdl1KhR\n",
              "L9muo6MjDz30UP7mb/6m6ywTAIB6co4qAPCa+vfvn3333TfXXnttkuThhx/OnXfe2bX+6KOPziWX\n",
              "XNIVTpYuXZr58+cnST71qU9l9913z6xZs/KJT3yiazkAQL2IIQDAOrn22mtz1VVXZfTo0fnsZz+b\n",
              "Qw89tGvdZZddlje84Q0ZO3ZsxowZk8MPPzxtbW35wQ9+kB//+Mf5+te/nhEjRmT69Ok5/vjjs2rV\n",
              "qjp+EwCgdLWqqqp6DwEAAACwsTgzBAAAACiKGAIAAAAURQwBAAAAiiKGAAAAAEURQwAAAICiiCEA\n",
              "AABAUcQQAAAAoChiCAAAAFAUMQQAAAAoihgCAAAAFOX/AeQmwBwR7IOZAAAAAElFTkSuQmCC\n",
              "\">\n",
              "      </div>\n",
              "      <script type=\"text/javascript\">\n",
              "        (() => {\n",
              "          const chartElement = document.getElementById(\"chart-8f429ac6-cc9b-4621-843f-88c7fab4dc19\");\n",
              "          async function getCodeForChartHandler(event) {\n",
              "            const chartCodeResponse =  await google.colab.kernel.invokeFunction(\n",
              "                'getCodeForChart', [\"chart-8f429ac6-cc9b-4621-843f-88c7fab4dc19\"], {});\n",
              "            const responseJson = chartCodeResponse.data['application/json'];\n",
              "            await google.colab.notebook.addCell(responseJson.code, 'code');\n",
              "          }\n",
              "          chartElement.onclick = getCodeForChartHandler;\n",
              "        })();\n",
              "      </script>\n",
              "      <style>\n",
              "        .colab-quickchart-chart-with-code  {\n",
              "            display: block;\n",
              "            float: left;\n",
              "            border: 1px solid transparent;\n",
              "        }\n",
              "\n",
              "        .colab-quickchart-chart-with-code:hover {\n",
              "            cursor: pointer;\n",
              "            border: 1px solid #aaa;\n",
              "        }\n",
              "      </style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<google.colab._quickchart_helpers.SectionTitle at 0x7ae70f8b4dd0>"
            ],
            "text/html": [
              "<h4 class=\"colab-quickchart-section-title\">Values</h4>\n",
              "<style>\n",
              "  .colab-quickchart-section-title {\n",
              "      clear: both;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "from matplotlib import pyplot as plt\n",
              "_df_3['index'].plot(kind='line', figsize=(8, 4), title='index')\n",
              "plt.gca().spines[['top', 'right']].set_visible(False)"
            ],
            "text/html": [
              "      <div class=\"colab-quickchart-chart-with-code\" id=\"chart-de91acf3-fa74-4d02-a2ab-ddbbe7fc24c6\">\n",
              "        <img style=\"width: 180px;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqUAAAFuCAYAAAC4H2HYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\n",
              "bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\n",
              "YQAAD2EBqD+naQAAN8xJREFUeJzt3Xt0VPW9//9X7kAgCQQCgZDrTFDkEsFguBlgol/bHo93v1Ur\n",
              "xKooioQvfk+t61dX62lXqT0evgRQEG1Ri3pEUXqs1qO5cAkiBEERFJjJhVxICCQkBEJuk/37Y+IA\n",
              "LaUkIdkzyfOxVtYy+5NJ3nvGnTzXZzLExzAMQwAAAICJfM0eAAAAACBKAQAAYDqiFAAAAKYjSgEA\n",
              "AGA6ohQAAACmI0oBAABgOqIUAAAApiNKAQAAYDqiFAAAAKYjSgHgCvrBD36gX//6152+/YwZM/Sr\n",
              "X/3qyg0EAF7C3+wBAKA3+etf/2r2CADgldgpBQAAgOmIUgC4gmbNmqVf/OIXkiQfHx+tXLlS06dP\n",
              "18CBAzV+/Hjl5eW5P7a1tVU/+9nPNGLECA0bNkzPPPPM332+8vJy3XfffRo1apQiIiJ077336vjx\n",
              "45KkzZs3Kzg4WPn5+ZIkwzD0ox/9SLfccosMw+iBswWAK4coBYBu9Oqrr+r1119XbW2tbDab7r//\n",
              "fvfa73//e23YsEE5OTkqKyuTv7+/du7c6V5vamqSzWbTyJEjdfjwYRUWFsrf31/33XefJFcA/+pX\n",
              "v9Jdd92l6upq/frXv9bBgwf1pz/9ST4+Pj1+rgDQFUQpAHSjp556ShaLRf7+/nrkkUdUUlKiY8eO\n",
              "SZLWrVunp556SmPHjlVQUJB+9atfafDgwe7bfvTRR6qvr9d//Md/KDg4WAMHDtTvfvc7ZWVlqays\n",
              "TJL0b//2b0pOTpbNZtPvf/97bdy4UWFhYWacKgB0CS90AoBuNHLkSPd/BwcHS5Lq6+s1fPhwlZWV\n",
              "KS4uzr3u5+en6Oho9/t2u13Hjh27IFQlKSgoSCUlJYqKipIkLVmyRNOnT9e9996rpKSkbjwbAOg+\n",
              "RCkAmCQqKkrFxcXu951Op0pLS93vjxgxQjExMSooKPiHn6Ourk7z5s3TQw89pA0bNujDDz/ULbfc\n",
              "0p1jA0C34Ol7ADDJvHnz9J//+Z86ePCgmpqa9O///u+qqalxr99xxx1qaWnRs88+q7q6OklSVVWV\n",
              "3nnnHUmuFzbNmzdPY8aM0SuvvKKXX35Zc+fOVWFhoSnnAwBdQZQCgEmefvpp3XHHHUpNTVVUVJSa\n",
              "m5t1/fXXu9cHDRqkHTt2qKSkROPHj1dISIimTZumrVu3SpKef/557du3z/3CpnvvvVc/+clPdOed\n",
              "d+rs2bNmnRYAdIqPwb8bAgAAAJOxUwoAAADTEaUAAAAwHVEKAAAA0xGlAAAAMB1RCgAAANMRpQAA\n",
              "ADAdUQoAAADTeX2UZmZmmj0CAAAAusjro/TIkSNmjwAAAIAu8vooBQAAgPcjSgEAAGA6ohQAAACm\n",
              "I0oBAABgOqIUAAAApiNKAQAAYDqiFAAAAKYjSgEAAGA6ohQAAACmI0oBAABgOqIUAACgDzEMQ63O\n",
              "NrPH+DtEKQAAQB9gGIY+PVCpW1bl6bXPi80e5+/4mz0AAAAAuk9bm6FPvz2mFdl2fVtxSpJ0urFV\n",
              "P50eJ19fH5OnO4coBQAA6IVcMVqp5Vl2HayslyQFB/opfXqsHpoR71FBKhGlAAAAvUpbm6FPDlRq\n",
              "Rfa5GB0Y5K/0abF6aEacBgcHmjzhxRGlAAAAvUBbm6GP91doZbZDh465YnRQkL8enB6rn86IU9gA\n",
              "z4zR7xGlAAAAXszZZujjbyq0Itsue9VpSdKgfv766fQ4/XR6nEIHBJg84eUhSgEAALyQs83QX/Yd\n",
              "1cochxztMRrSz18/nRGnB6fHKbS/d8To94hSAAAAL+JsM/Th10e1MseuguNnJLli9OGZ8UqfHquQ\n",
              "ft4Vo98jSgEAALxAq7NNH+47qpXZDhWecMVoaP8APTwjTvO8OEa/R5QCAAB4sFZnm/781VGtynWo\n",
              "qD1GwwYE6JGZ8Zo7NUaDvDxGv0eUAgAAeKBWZ5s+2FuuF3MdKq5ukCQNHhCgR26I19ypsRoY1Lsy\n",
              "rnedDQAAgJdraY/RVTkOldS4YnRIcKB7ZzS4l8Xo93rnWQEAAHiZFmeb3t9TplW5DpXWnJUkhQcH\n",
              "av4N8fpJSu+N0e/17rMDAADwcM2t52K07KQrRocODNSjNyTo/pRoDQjsG7nWN84SAADAwzS3tum9\n",
              "L8v0Yq5D5bXfx2iQHkuN1/3Xx6h/oJ/JE/YsohQAAKAHNbU69e7uMq3eXOCO0WGDgvRYaoLumxLd\n",
              "52L0e0QpAABAD2hqdWrD7jKtznXoaF2jJCliUJAWzErQvVOi1S+gb8bo94hSAACAbtTY4tSG3aVa\n",
              "vblAFe0xOjwkSAtSE/RjYtSNKAUAAOgGjS1O/deuEq3eUqBjp5okSSNC+unx2Qm657rRxOjfIEoB\n",
              "AACuoMYWp97eVaI158VoZGg/PT7bonuui1KQPzF6MUQpAADAFdDY4tSbO10xerzeFaMj22P0bmL0\n",
              "nyJKAQAAuuBss1Nv7jyiNVsKdeK0K0ZHhfXXE7MtumtylAL9fU2e0DsQpQAAAJ3Q0NyqN78o0ctb\n",
              "C3TidLMkKWpwfy2cbdEdk4jRjiJKAQAAOqChuVV/2nFEa7cWqvqMK0ZHDzkXowF+xGhnEKUAAACX\n",
              "4UxTq97YcUSvbCtUTXuMxoQP0BOzLbr92lHEaBcRpQAAAJdwuqlVb+wo1itbC3WyoUWSK0afnGPV\n",
              "bUkj5U+MXhEdvhdjY2M1ZswYJSUlKSkpSe+8844kyW63a9q0aUpMTFRycrIOHDjgvk1n1wAAAMxS\n",
              "39iiF3MdmvF8jn7/ySGdbGhR3NBg/efdE5W9JFV3TY4iSK+gTu2UvvPOO0pKSrrg2KOPPqr58+cr\n",
              "PT1d7733ntLT05Wfn9+lNQAAgJ5W39ii17YX69W8ItWdde2Mxg8N1pM2i26ZwM5od/ExDMPoyA1i\n",
              "Y2O1adOmC6K0qqpKFotFNTU18vf3l2EYioyMVF5enkJCQjq1ZrFYLmueJUuWaNmyZR06aQAAgL91\n",
              "qj1G/3B+jA4LVobNqn+ZMFJ+vj4mT9i7dWqndO7cuTIMQ1OmTNHvfvc7lZaWKjIyUv7+rk/n4+Oj\n",
              "6OholZSUKDQ0tFNrF4vSpqYmNTU1XXDM6XR25hQAAAAkSXVnW7Rue5H+mFekU42tkiRLxEA9OcdC\n",
              "jPagDu8/b926Vfv27dOePXs0dOhQzZs3rzvmuqilS5cqNDT0grddu3b12NcHAAC9R11Di5Z9dlgz\n",
              "ns/R8iy7TjW2yhoxUCvvvVb/s/gG3Zo0iiDtQR1++v58FRUVSkxMVEFBQY88fX+xndJnn31WmZmZ\n",
              "nT0FAADQx9Q2NOuPeUVat71Y9U2undHE4QOVYUvUD8aNkC8haooO7ZSeOXNGtbW17vfffvttXXvt\n",
              "tYqIiNCkSZO0fv16SdLGjRsVFRUli8XS6bWLCQoKUkhIyAVvfn78HVkAAPDPnTzTrBf+55BmPJ+r\n",
              "FTkO1Te16qoRg/TS/ZP0ScYN+tGESILURB3aKS0sLNSdd94pp9MpwzAUHx+vzMxMxcbG6tChQ0pP\n",
              "T1d1dbVCQkK0bt06jR8/XpI6vXY5eKETAAC4lJozzXp1W6Fe/7xYZ5pdr0W5OjJEGTaLbhrLzqin\n",
              "6NLT956AKAUAABdTc6ZZr2wr1BvnxejYyBBlpFl149XDiVEPw190AgAAvUr16Sat3VaoP+04oob2\n",
              "GL1mZIgybFbdOHa4fHyIUU9ElAIAgF7hxOkmrd3qitGzLa4YHT8qVBk2q2xXRxCjHo4oBQAAXu14\n",
              "fZPWbi3Q+i9K3DE6ISpUi9Osmj2GGPUWRCkAAPBKVfWNenlLod7ceUSNLW2SpImjw7TYZtWsMcOI\n",
              "US9DlAIAAK9SdapRq7cU6K2dJWpqdcXotdFhyrBZlZpIjHorohQAAHiFY6catXpzgd7edS5GJ0WH\n",
              "aXFaomZahxKjXo4oBQAAHq2yrlGrNzv0dn6pmttj9LqYwcpIs2qGhRjtLYhSAADgkY7WntXqzQV6\n",
              "J79UzU5XjE6JHaKMNKumJYQTo70MUQoAADzK0dqzemmzQxvyy87FaNwQLU6zamo8MdpbEaUAAMAj\n",
              "lJ1s0EubC/Tu7lK1OF1/cDIlfogybImamhBu8nTobkQpAAAwVWmNK0bf+/JcjE6ND1dGmlUp8cRo\n",
              "X0GUAgAAU5TWNOjFXIfe+7JMrW2uGJ1uCVeGLVFT4oaYPB16GlEKAAB6VEl1g1bl2vX+nnJ3jM60\n",
              "DlWGzarrYonRvoooBQAAPeJI9RmtynHo/b3lcp4Xo4vTrJocQ4z2dUQpAADoVsUnzmhljkObvjoX\n",
              "o6mJw7TIZtXkmMEmTwdPQZQCAIBuUXj8tFa1x2h7i2r2GFeMXhtNjOJCRCkAALiiCtpj9M/nxeic\n",
              "qyK0yGZV0ugwU2eD5yJKAQDAFeGoOq2VOXZ9+PVRd4ymXe2K0QlRYabOBs9HlAIAgC6xH6vXihyH\n",
              "/rLvqIz2GL1x7HBl2KwaNyrU3OHgNYhSAADQKYeP1WtFtl0ffVPhjtGbxg7XImIUnUCUAgCADjlU\n",
              "6YrRj/efi9GbrxmhJ20WXTOSGEXnEKUAAOCyfFdxSiuy7frr/kr3sR+OH6En51h1dWSIiZOhNyBK\n",
              "AQDAJX171BWjnxxwxaiPj/TDcZF60mbRVSOIUVwZRCkAALio/eV1WpFt16ffHpPkitEfjY/UIptV\n",
              "icMHmTwdehuiFAAAXGB/eZ2WZ9mV9d25GL1lwkg9OcciKzGKbkKUAgAASdI3ZXXKzD6srO+qJEm+\n",
              "PtItE10xaokgRtG9iFIAAPq4r0trlZltV87BczF6a9IoLZxjUcKwgSZPh76CKAUAoI/aW3JSmdl2\n",
              "bT50XJIrRm+7dpQWzrYonhhFDyNKAQDoY/aUnFRmll1bDrti1M/XR7e174zGDQ02eTr0VUQpAAB9\n",
              "xJdHarQ8y65t9hOSXDF6x7Wj9MRsi2KJUZiMKAUAoJfLL65RZpZdeQ5XjPr7+ujOSVF6YrZF0eED\n",
              "TJ4OcCFKAQDopXYV1Sgz+7C2O6oluWL0rsmuGB09hBiFZyFKAQDoZb4orFZmll07Cl0xGuDno7sm\n",
              "j9bjsxKIUXgsohQAgF5iR0G1lmcd1s6iGkmuGL3nutFaMCtBUYOJUXg2ohQAAC9mGIYrRrPt2tUe\n",
              "o4F+vronOUoLZlk0Kqy/yRMCl4coBQDACxmGoc/bd0bzi09KcsXoj6eM1mOpCRpJjMLLEKUAAHgR\n",
              "wzCU5zihzCy7dh9pj1F/X92bPFqPzUpQZCgxCu9ElAIA4AUMw9BW+wllZh3WnpJaSa4YvW9KtBbM\n",
              "StDwkH7mDgh0EVEKAIAHMwxDWw4f1/Isu74qrZUkBfn76r7ro/VYKjGK3oMoBQDAAxmGoc2Hjmt5\n",
              "tl1ft8dovwBf3X99jB69IV4RxCh6GaIUAAAPYhiGcg5WKTPbrn1ldZJcMfpASozm35CgYYOCTJ4Q\n",
              "6B6+nb3hunXr5OPjo02bNkmSqqqqdPPNN8tqtWrcuHHaunWr+2M7uwYAQF9hGIayvj2mf121XQ+9\n",
              "vlv7yurUP8BP82+I17afzdH/96OxBCl6tU7tlBYXF+uVV15RSkqK+9jPf/5zpaSk6JNPPlF+fr5u\n",
              "v/12FRUVKSAgoNNrAAD0doZh6LNvj2lFjl37y09JkgYE+umBqTF6ZGa8hg4kRNE3dDhK29ra9PDD\n",
              "D2vlypV66qmn3Mc3bNggh8MhSUpOTtbIkSO1ZcsWpaWldXoNAIDeqq3N0KffHtOKbLu+rXDFaHCg\n",
              "n+ZOi9UjM+M1JDjQ5AmBntXhKF22bJmmT5+uyZMnu49VV1erpaVFI0aMcB+LjY1VSUlJp9cupqmp\n",
              "SU1NTRccczqdHT0FAABM44rRSi3PsutgZb0kV4zOmxarh4lR9GEditL9+/dr48aNpv3e59KlS/Xc\n",
              "c89dcOz8XyEAAMBTtbUZ+uRApVZkn4vRgUH+Sp8Wq4dmxGkwMYo+rkNRum3bNhUXF8tqtUqSKisr\n",
              "NX/+fD333HPy9/dXZWWle9ezuLhY0dHRCg8P79TaxTzzzDNasmTJBceeffbZjp0xAAA9qK3N0Mf7\n",
              "K7Qy26FDx1wxOijIXw9Oj9VPZ8QpbAAxCkgdfPX9ggULVFFRoeLiYhUXFyslJUVr167VggULdPfd\n",
              "d2vNmjWSpPz8fJWXlys1NVWSOr32t4KCghQSEnLBm5+fX+fOHACAbuRsM/Th10f1v5Zv1cK39urQ\n",
              "sXoN6uevRTar8p6eoyU3jSFIgfNcsX+n9Pnnn9cDDzwgq9WqwMBArV+/3v0K+s6uAQDgbZxthv6y\n",
              "76hW5jjkqDotSQrp56+fzojTg9PjFNqfn3HAxfgYhmGYPURXLFmyRMuWLTN7DABAH/f9zujKHLsK\n",
              "jp+R5IrRh2fGK316rEL6EaPApfAXnQAA6IJWZ5s+3HdUK7MdKjzhitHQ/gF6eEac5hGjwGUjSgEA\n",
              "6IRWZ5v+/NVRrcp1qKg9RsMGBOiRmfGaOzVGg4hRoEOIUgAAOqDV2aYP9pbrxVyHiqsbJEmDBwTo\n",
              "kRviNXdqrAYG8aMV6AyuHAAALkNLe4yuynGopMYVo0OCA907o8HEKNAlXEEAAFxCi7NN7+8p06pc\n",
              "h0przkqSwoMDNf+GeP0khRgFrhSuJAAALqK5tU0b95TpxVyHyk66YnTowEA9ekOC7k+J1oBAfoQC\n",
              "VxJXFAAA52lubdN7X7pitLz2+xgN0mOp8br/+hj1D+SPtgDdgSgFAEBSU6tT7+4u0+rNBe4YHTYo\n",
              "SI+lJui+KdHEKNDNiFIAQJ/W1OrUhvxSrd5coKN1jZKkiEFBWjArQfdOiVa/AGIU6AlEKQCgT2ps\n",
              "cWrD7lK9lFugylOuGB0eEqQFqQn6MTEK9DiiFADQpzS2OPVfu0q0ekuBjp1qkiSNCOmnx2cn6J7r\n",
              "RhOjgEmIUgBAn9DY4tRbO0u0ZkuBqupdMRoZ2k+Pz7bonuuiFORPjAJmIkoBAL1aY4tTb7bH6PH2\n",
              "GB3ZHqN3E6OAxyBKAQC90tlmp97ceURrthTqxGlXjI4K668nZlt01+QoBfr7mjwhgPMRpQCAXqWh\n",
              "uVXrvziitVsLdeJ0syQparArRu+cRIwCnoooBQD0Cg3NrfrTDleMVp9xxejoIf21cLZFd0yKUoAf\n",
              "MQp4MqIUAODVzjS16o0dR/TKtkLVtMdo9JABWjjHotuvHUWMAl6CKAUAeKXTTa16/fNivbqtUCcb\n",
              "WiRJMeEDtHC2RbcRo4DXIUoBAF6lvrHFvTNa2x6jcUODtXC2RbcmjZQ/MQp4JaIUAOAV6htb9Nr2\n",
              "Yr2aV6S6s64YjR8arCdtFt0ygRgFvB1RCgDwaKcaW7Qur1h/yCvUqcZWSVL8sGAtmmPVLRNHys/X\n",
              "x+QJAVwJRCkAwCPVnW3Ruu1F+mNekTtGLRED9eQci/5lAjEK9DZEKQDAo9Q1tOgP24u0bnuR6ttj\n",
              "1BoxUItsVv1wfCQxCvRSRCkAwCPUNjTrj3lFWre9WPVNrhhNHN4eo+Mi5UuMAr0aUQoAMNXJM836\n",
              "Q16RXvu8WKfbY/SqEYO0yGbVzdeMIEaBPoIoBQCYouZMs17dVqjXPy/WmWanJFeMLk6z6qaxxCjQ\n",
              "1xClAIAeVXOmWa9sK9Qb58Xo2MgQLbJZddPY4cQo0EcRpQCAHlF9uklrtxXqTzuOqKE9Rq8ZGaIM\n",
              "m1U3jh0uHx9iFOjLiFIAQLc6cbpJa7e6YvRsiytGx40K0WJbomxXRxCjACQRpQCAbnK8vklrtxZo\n",
              "/Rcl7hidEBWqDJtVc64iRgFciCgFAFxRVfWNenlLod7ceUSNLW2SpImjw7TYZtWsMcOIUQAXRZQC\n",
              "AK6IqlONWr2lQG/tLFFTqytGk0aHaXGaVamJxCiASyNKAQBdcuxUo1ZvLtDbu87F6KToMGWkJeoG\n",
              "61BiFMBlIUoBAJ1SWdeo1Zsdeju/VM3tMXpdzGBlpFk1w0KMAugYohQA0CFHa89q9eYCvZNfqman\n",
              "K0aTYwdrcVqipiWEE6MAOoUoBQBclvLas1q92aEN+WXuGJ0SN0SLbVZNJUYBdBFRCgC4pLKTDXpp\n",
              "c4He3V2qFqchSUqJH6IMW6KmJoSbPB2A3oIoBQBcVGmNK0bf+/JcjE6ND1dGmlUp8cQogCuLKAUA\n",
              "XKC0pkEv5jr03pdlam1zxeh0S7gybImaEjfE5OkA9FZEKQBAklRS3aBVuXa9v6fcHaMzrUOVYbPq\n",
              "ulhiFED3IkoBoI87Un1Gq3Icen9vuZznxejiNKsmxxCjAHoGUQoAfVTRCVeMbvrqXIymJg7TIptV\n",
              "k2MGmzwdgL7Gt6M3uOmmmzRhwgQlJSVp5syZ2rt3ryTJbrdr2rRpSkxMVHJysg4cOOC+TWfXAABX\n",
              "XuHx01ryzley/edmbdxTJmeboVljhumDx6fp9Z9OIUgBmKLDO6UbNmxQWFiYJOmDDz5Qenq6vv76\n",
              "az366KOaP3++0tPT9d577yk9PV35+fmS1Ok1AMCVU3D8tFblOPTnr8rVvjGqOVdFaJHNqqTRYabO\n",
              "BgA+hmEYnb3xa6+9puXLl+vTTz+VxWJRTU2N/P39ZRiGIiMjlZeXp5CQkE6tWSyWv/t6TU1Nampq\n",
              "uuDYs88+q8zMzM6eAgD0eo6qeq3McejDr4+6YzTtaleMTogKM3U2APhep36ndO7cucrNzZUkffzx\n",
              "xyotLVVkZKT8/V2fzsfHR9HR0SopKVFoaGin1i4WpUuXLtVzzz13wbGUlJTOnAIA9Hr2Y/VakePQ\n",
              "X/YdleGO0eHKsFk1PirU3OEA4G90+HdKJemNN95QaWmpfvOb3+jpp5++0jP9Q88884zq6uoueJsy\n",
              "ZUqPfX0A8AaHj9Vr4Vt7dNPyrfrwa1eQ3jR2uP7y5Ay9Ou86ghSAR+rSq+/nzZunxx57TFFRUaqo\n",
              "qFBra6v7afiSkhJFR0crJCSkU2sXExQUpKCgoAuO+fn5deUUAKDXOFh5SiuzHfp4f4V7Z/Tma0bo\n",
              "SZtF14wkRAF4tg7tlNbW1uro0aPu9zdt2qTw8HBFRERo0qRJWr9+vSRp48aNioqKksVi6fQaAODy\n",
              "fFdxSgvWf6mbl2/TR9+4gvQH40borxkzteaByQQpAK/QoRc6HTlyRHfffbfOnj0rX19fDRs2TC+8\n",
              "8IKSkpJ06NAhpaenq7q6WiEhIVq3bp3Gjx8vSZ1euxxLlizRsmXLOnjaAOD9vj16Siuy7frkQKUk\n",
              "ycdH+uG4SD1ps+iqESEmTwcAHdOlV997AqIUQF+zv7xOK7Lt+vTbY5JcMfqj8ZFaZLMqcfggk6cD\n",
              "gM7hLzoBgJfYX16n5Vl2ZX13Lkb/ZcJILZpjkZUYBeDliFIA8HDflNUpM/uwsr6rkiT5+ki3TByp\n",
              "J+dYZIkgRgH0DkQpAHior0trlZltV87BczF6a9IoLZxjUcKwgSZPBwBXFlEKAB5mb8lJZWbbtfnQ\n",
              "cUmuGL2tPUbjiVEAvRRRCgAeYk/JSWVm2bXlsCtG/Xx93DEaNzTY5OkAoHsRpQBgsi+P1Gh5ll3b\n",
              "7CckuWL0jmtH6YnZFsUSowD6CKIUAEySX1yjzCy78hyuGPX39dEdk1wxGhNOjALoW4hSAOhhu4pq\n",
              "lJl9WNsd1ZJcMXrX5Cg9Mdui0UMGmDwdAJiDKAWAHvJFYbUys+zaUXguRu++brQen5VAjALo84hS\n",
              "AOhmOwqqtTzrsHYW1UiSAvzOxWjUYGIUACSiFAC6hWEYrhjNtmtXe4wG+vnqnuQoLZhl0aiw/iZP\n",
              "CACehSgFgCvIMAx93r4zml98UpIrRv938mgtmJWgkcQoAFwUUQoAV4BhGMpznFBmll27j7THqL+v\n",
              "7k0ercdmJSgylBgFgEshSgGgCwzD0Fb7CWVmHdaeklpJrhi9b0q0FsxK0PCQfuYOCABegigFgE4w\n",
              "DENbDh/X8iy7viqtlSQF+fvqvuuj9VgqMQoAHUWUAkAHGIahzYeOa3m2XV+3x2i/AF/df32MHr0h\n",
              "XhHEKAB0ClEKAJfBMAzlHKxSZrZd+8rqJLli9IGUGM2/IUHDBgWZPCEAeDeiFAAuwTAMZX/nitFv\n",
              "yl0x2j/ATw9MjdEjM+OJUQC4QohSALgIwzD02bfHtCLHrv3lpyRJAwLPxejQgcQoAFxJRCkAnKet\n",
              "zdCn3x7Timy7vq1wxWhwoJ/mTovVwzPiFE6MAkC3IEoBQN/HaKWWZ9l1sLJekitG502L1cMz4zUk\n",
              "ONDkCQGgdyNKAfRpbW2GPjlQqRXZ52J0YJC/0qfF6qEZcRpMjAJAjyBKAfRJbW2GPt5foZXZDh06\n",
              "5orRQUH+enB6rH46I05hA4hRAOhJRCmAPsXZZujjbyq0Itsue9VpSdKgfv56cHqcHpoep9ABASZP\n",
              "CAB9E1EKoE9wthn6y76jWpnjkOO8GH1oRpwenB6n0P7EKACYiSgF0Ks52wx9+PVRrcyxq+D4GUlS\n",
              "SD9/PTQjXunTY4lRAPAQRCmAXqnV2aYP9x3VymyHCk+4YjS0f4AenhGnedNjFdKPGAUAT0KUAuhV\n",
              "Wp1t+vNXR7Uq16Gi9hgNGxCgR2bGa+7UGA0iRgHAIxGlAHqFVmebPthbrhdzHSqubpAkDR4QoIdn\n",
              "xmvetFgNDOLbHQB4Mr5LA/BqLe0xuirHoZIaV4wOCQ5074wGE6MA4BX4bg3AK7U42/T+njKtynWo\n",
              "tOasJCk8OFDzb4jXT1KIUQDwNnzXBuBVmlvbtHFPmV7MdajspCtGhw48F6MDAvm2BgDeiO/eALxC\n",
              "c2ub3vvSFaPltd/HaJAeS43X/dfHqH+gn8kTAgC6gigF4NGaWp16d3eZVm8ucMfosEFBeiw1QfdN\n",
              "iSZGAaCXIEoBeKSmVqc25Jfqpc0FqqhrlCRFfB+j10erXwAxCgC9CVEKwKM0tji1YXepXsotUOUp\n",
              "V4wODwnSgtQE/XgKMQoAvRVRCsAjNLY49V+7SrR6S4GOnWqSJI0I6afHZyfonutGE6MA0MsRpQBM\n",
              "1dji1Fs7S7RmS4Gq6l0xGhnaT4/PStA9yaMV5E+MAkBfQJQCMEVji1Nvtsfo8fYYHRnaT4/Ptuju\n",
              "66KIUQDoY4hSAD3qbLNTb+48ojVbCnXitCtGR4X11xOzLbprcpQC/X1NnhAAYAaiFECPaGhu1fov\n",
              "jmjt1kKdON0sSYoa7IrROycRowDQ13Xop0BjY6Nuu+02JSYmauLEibrxxhvlcDgkSVVVVbr55ptl\n",
              "tVo1btw4bd261X27zq4B8H4Nza16eUuBZj6fq99+fFAnTjdr9JD+ev7O8cr9v7N075RoghQA0PGd\n",
              "0vnz5+sHP/iBfHx8tGrVKj388MPavHmzfv7znyslJUWffPKJ8vPzdfvtt6uoqEgBAQGdXgPgvc40\n",
              "teqNHUf0yrZC1Zxx7YxGDxmghXMsuv3aUQrwI0QBAOd0KEr79eunH/7wh+73U1JS9MILL0iSNmzY\n",
              "4N41TU5O1siRI7VlyxalpaV1eg2A9znd1KrXPy/Wq9sKdbKhRZIUEz5AC2dbdBsxCgD4B7r0O6WZ\n",
              "mZm69dZbVV1drZaWFo0YMcK9Fhsbq5KSkk6vXUxTU5OampouOOZ0OrtyCgCukPrGFvfOaG17jMYN\n",
              "DdbC2RbdmjRS/sQoAOASOh2lv/3tb+VwOJSdna2zZ89eyZn+oaVLl+q555674FhKSkqPfG0AF3eq\n",
              "sUWvby/Wq3lFqjvritH4ocF60mbRLROIUQDA5elUlL7wwgt6//33lZWVpQEDBmjAgAHy9/dXZWWl\n",
              "e9ezuLhY0dHRCg8P79TaxTzzzDNasmTJBceeffbZzpwCgC461diidXnF+kNeoU41tkqS4ocFa9Ec\n",
              "q26ZOFJ+vj4mTwgA8CYd3sJYtmyZ3n77bX322WcKCwtzH7/77ru1Zs0aSVJ+fr7Ky8uVmprapbW/\n",
              "FRQUpJCQkAve/Pz4B7aBnlR3tkXLsw5rxu9y9P+yDutUY6ssEQOV+eMkffZ/UnXbtaMIUgBAh3Vo\n",
              "p7SsrExPPfWU4uPjNXv2bEmuUNy5c6eef/55PfDAA7JarQoMDNT69evdr6Dv7BoAz1HX0KI/bC/S\n",
              "uu1Fqm/fGbVGDNQim1U/HB9JiAIAusTHMAzD7CG6YsmSJVq2bJnZYwC9Vm1Ds/6QV6TXthervskV\n",
              "o4nD22N0XKR8iVEAwBXAX3QCcFEnz7TH6OfFOt0eo1eNGKRFNqtuvmYEMQoAuKKIUgAXqDnTrFe3\n",
              "Fer1z4t1ptn1T65dNWKQFqdZddNYYhQA0D2IUgCSpOrTTXplW5He2FGshvYYHRsZokU2q24aO5wY\n",
              "BQB0K6IU6OOqTzdp7bZC/WnHEXeMXjMyRBk2q24cO1w+PsQoAKD7EaVAH3XidJPWbnXF6NkWV4yO\n",
              "GxWixbZE2a6OIEYBAD2KKAX6mKr6Rq3dUqj1O4+osaVNkjQhKlQZNqvmXEWMAgDMQZQCfURVfaNe\n",
              "3lKoN8+L0Ymjw7TYZtWsMcOIUQCAqYhSoJerOtWo1VsK9NbOEjW1umI0aXSYFqdZlZpIjAIAPANR\n",
              "CvRSlXWNWrOlQG/tKlFze4xOig5TRlqibrAOJUYBAB6FKAV6mcq6Rq3e7NDb+aXuGL0uZrAy0qya\n",
              "YSFGAQCeiSgFeomjtWe1enOB3skvVbPTFaPJsYO1OC1R0xLCiVEAgEcjSgEvV157Vqs3O7Qhv8wd\n",
              "o1PihmixzaqpxCgAwEsQpYCXKjvZoJc2F+jd3aVqcRqSpOvjhmhxWqKmJoSbPB0AAB1DlAJeprSm\n",
              "QS9tdui9L8vcMTo1PlwZaValxBOjAADvRJQCXqK0pkEv5rpitLXNFaPTLeHKsCVqStwQk6cDAKBr\n",
              "iFLAw5VUN2hVrl3v7yl3x+gMy1BlpFmVHEuMAgB6B6IU8FDFJ85oVa5DH+wtl7M9Rmdah2pxmlWT\n",
              "Y4hRAEDvQpQCHqboxBmtynFo01fnYjQ1cZgW2ayaHDPY5OkAAOgeRCngIQqPn3bHaHuLataYYcqw\n",
              "WXVtNDEKAOjdiFLAZI6q01qVY9d/f33UHaNzrorQIptVSaPDTJ0NAICeQpQCJnFU1WtljkP//fVR\n",
              "Ge0xmna1K0YnRIWZOhsAAD2NKAV6mP1YvVbkOPSXfefH6HBl2KwaHxVq7nAAAJiEKAV6yKHKeq3I\n",
              "sevjbyrcMXrT2OFaZLNq3ChiFADQtxGlQDc7WHlKK7Md+uibCvexm68ZoSdtFl0zkhgFAEAiSoFu\n",
              "813FKa3Ituuv+yvdx34wboQW2ay6OjLExMkAAPA8RClwhX171BWjnxxwxaiPj/TDcZF60mbRVSOI\n",
              "UQAALoYoBa6Q/eV1WpFt16ffHpPkitEfjY/UIptVicMHmTwdAACejSgFumh/eZ2WZ9mV9d25GP2X\n",
              "CSO1aI5FVmIUAIDLQpQCnfRNWZ0ysw8r67sqSZKvj3TLxJF6co5FlghiFACAjiBKgQ76urRWmdl2\n",
              "5Rw8F6O3Jo3SwjkWJQwbaPJ0AAB4J6IUuEx7S04qM9uuzYeOS3LF6G3tMRpPjAIA0CVEKfBP7Ck5\n",
              "qcwsu7YcdsWon6+PO0bjhgabPB0AAL0DUQr8A18eqdHyLLu22U9IcsXoHdeO0hOzLYolRgEAuKKI\n",
              "UuBv5BfXKDPLrjzHuRi9c5IrRmPCiVEAALoDUQq021VUo8zsw9ruqJYk+fv66K7JUXpitkWjhwww\n",
              "eToAAHo3ohR93heF1crMsmtH4bkYvfu60Xp8VgIxCgBADyFK0WftKKjW8qzD2llUI0kK8DsXo1GD\n",
              "iVEAAHoSUYo+xTAMV4xm27WrPUYD/Xx1T3KUFsyyaFRYf5MnBACgbyJK0ScYhqHtjmplZh9WfvFJ\n",
              "Sa4Y/d/Jo7VgVoJGEqMAAJiKKEWvZhiG8hwntDzLri+PtMeov6/uTR6tx2YlKDKUGAUAwBMQpeiV\n",
              "DMPQVvsJZWYd1p6SWkmuGL1vSrQeS03QiNB+5g4IAAAu4NuRD160aJFiY2Pl4+Ojr776yn3cbrdr\n",
              "2rRpSkxMVHJysg4cONDlNaAzDMNQ7qEq3f7S55r3x13aU1KrIH9fPTg9Vtt+Nlu/+tdrCFIAADxQ\n",
              "h6L0rrvuUl5enmJiYi44/uijj2r+/Pk6fPiwnn76aaWnp3d5DegIwzCUe7BKt730uR5cl6+vSmvV\n",
              "L8BXD82I07afzdYvb7lGw0OIUQAAPJWPYRhGR28UGxurTZs2KSkpSVVVVbJYLKqpqZG/v78Mw1Bk\n",
              "ZKTy8vIUEhLSqTWLxXLZsyxZskTLli3r6CmglzAMQzkHq5SZbde+sjpJUr8AXz2QEqNHbohXxCBC\n",
              "FAAAb9Dl3yktLS1VZGSk/P1dn8rHx0fR0dEqKSlRaGhop9b+UZQ2NTWpqanpgmNOp7OrpwAvZBiG\n",
              "sr6r0opsu74pd8Vo/wA/PTA1Ro/MjNewQUEmTwgAADrCq17otHTpUj333HMXHEtJSTFpGpjBMAx9\n",
              "9u0xZWbbdeDoKUnSgMBzMTp0IDEKAIA36nKUjh49WhUVFWptbXU/DV9SUqLo6GiFhIR0au0feeaZ\n",
              "Z7RkyZILjj377LNdPQV4gbY2Q59+e0wrsu36tsIVo8GBfpo7LVYPz4hTODEKAIBX63KURkREaNKk\n",
              "SVq/fr3S09O1ceNGRUVFuZ+C7+zaxQQFBSko6ML48PPz6+opwIO1tRn6nwOVysy262BlvSRXjM6b\n",
              "FquHZ8ZrSHCgyRMCAIAroUMvdHr00Uf10UcfqbKyUuHh4Ro0aJAcDocOHTqk9PR0VVdXKyQkROvW\n",
              "rdP48eMlqdNrl4sXOvVObW2GPjlQqRXnxejAIH+lT4vVQzPiNJgYBQCgV+nUq+89CVHau7S1Gfp4\n",
              "f4VWZjt06JgrRgcF+St9uitGwwYQowAA9EZe9UIn9F7ONkMffVOhldl22atOS5IG9fPXg9Pj9ND0\n",
              "OIUOCDB5QgAA0J2IUpjK2WboL/uOamWOQ47zYvShGXF6cHqcQvsTowAA9AVEKUzhbDP04ddHtTLH\n",
              "roLjZyRJIf389dCMeKVPjyVGAQDoY4hS9KhWZ5v+++ujWpXjUOEJV4yG9g/QwzPiNG96rEL6EaMA\n",
              "APRFRCl6RKuzTX/+6qhW5TpU1B6jYQMC9MjMeM2dGqNBxCgAAH0aUYpu1eps0wd7y/VirkPF1Q2S\n",
              "pMEDAvTwzHjNmxargUH8LwgAAIhSdJMWZ5s+2FOuVbkOldS4YnRIcKAemRmvB6bGEKMAAOAClAGu\n",
              "qBZnm97fU6ZVuQ6V1pyVJIUHB2r+DfH6SUqMgolRAABwERQCrojm1jZt3FOmF3MdKjvpitGhA8/F\n",
              "6IBA/lcDAAD/GKWALmlubdO7X5bqpdwCldd+H6NBeiw1XvdfH6P+gX4mTwgAALwBUYpOaWp16t3d\n",
              "ZXop16GjdY2SpGGDgvRYaoLumxJNjAIAgA4hStEhTa1Obcgv1UubC1TRHqMR38fo9dHqF0CMAgCA\n",
              "jiNKcVkaW5x6J79UqzcXqPKUK0aHhwRpQWqCfjyFGAUAAF1DlOKSGluc+q9dJVq9pUDHTjVJkkaE\n",
              "9NPjsxN0z3WjiVEAAHBFEKW4qMYWp97aWaI1WwpUVe+K0cjQfnp8VoLuSR6tIH9iFAAAXDlEKS5w\n",
              "ttmpN3ce0ctbC3W8PUZHhvbT47Mtuvu6KGIUAAB0C6IUks7F6JothTpx2hWjo8L664nZFt01OUqB\n",
              "/r4mTwgAAHozorSPa2hu1fovjmjt1kKdON0sSYoa7IrROycRowAAoGcQpX3UmaZW/emLI3pla6Gq\n",
              "z7hidPSQ/lo426I7JkUpwI8YBQAAPYco7WPONLXqjR1H9Mq2QtW0x2j0kAFaOMei268dRYwCAABT\n",
              "EKV9xOmmVr3+ebFe3Vaokw0tkqSY8AFaONui24hRAABgMqK0l6tvbHHFaF6RattjNG5osBbOtujW\n",
              "pJHyJ0YBAIAHIEp7qVONLXp9uytG6866YjR+aLCetFl0ywRiFAAAeBaitJc51diidXnF+kNeoU41\n",
              "tkqS4ocFa9Ecq26ZOFJ+vj4mTwgAAPD3iNJeou5si/6YV6Q/bi9SfXuMWiIG6sk5Fv3LBGIUAAB4\n",
              "NqLUy9U1tOgP24u07rwYtUYM1CKbVT8cH0mMAgAAr0CUeqnahmb9Ia9Ir20vVn2TK0YTh7fH6LhI\n",
              "+RKjAADAixClXubkmfYY/bxYp9tjdMzwQcpIs+rma0YQowAAwCsRpV6i5kyzXt1WqNc/L9aZZqck\n",
              "6aoRg5Rhs+p/EaMAAMDLEaUervp0k17ZVqQ3dhSroT1Gx0aGaJHNqpvGDidGAQBAr0CUeqjq001a\n",
              "u61Qf9pxxB2j14wMUYbNqhvHDpePDzEKAAB6D6LUw5w43aS1W10xerbFFaPjRoUow5aotKsjiFEA\n",
              "ANArEaUeoqq+UWu3FGr9ziNqbGmTJE2IClWGzao5VxGjAACgdyNKTVZV36iXtxTqzfNidGJUqBan\n",
              "JWrWmGHEKAAA6BOIUpNUnWrU6i0FemtniZpaXTGaNDpMGWlWzUokRgEAQN9ClPawyrpGrdlSoLd2\n",
              "lai5PUYnRYcpIy1RN1iHEqMAAKBPIkp7SEXdWa3ZXKC380vdMTo5ZrAWp1k1w0KMAgCAvo0o7WZH\n",
              "a89q9eYCvZNfqmanK0aTYwcrw5ao6ZZwYhQAAEBEabcprz2r1Zsd2pBf5o7RKXFDtNhm1dQEYhQA\n",
              "AOB8ROkVVnayQS9tLtC7u0vV4jQkSdfHDdHitERNTQg3eToAAADPRJReIaU1DXpps0PvfVnmjtGp\n",
              "8eHKSLMqJZ4YBQAAuBSPiFK73a558+bpxIkTCg0N1WuvvaZrrrnG7LEuS2lNg17MdcVoa5srRqdb\n",
              "wpVhS9SUuCEmTwcAAOAdPCJKH330Uc2fP1/p6el67733lJ6ervz8fLPHuqSS6gatyrXr/T3l7hid\n",
              "YRmqjDSrkmOJUQAAgI4wPUqrqqq0e/duffrpp5KkO++8UwsXLpTD4ZDFYjF5ur9XfOKMVuU69MHe\n",
              "cjnbY3SmdagWp1k1OYYYBQAA6AzTo7S0tFSRkZHy93eN4uPjo+joaJWUlPxdlDY1NampqemCY06n\n",
              "s0fmrDrVqOc/OaRNX52L0dTEYVpks2pyzOAemQEAAKC3Mj1KO2Lp0qV67rnnLjiWkpLSI1/b389X\n",
              "f91fIWeboVljhinDZtW10cQoAADAleBjGIZh5gBVVVWyWCyqqamRv7+/DMNQZGSk8vLyLmun9Nln\n",
              "n1VmZmaPzPr+njLFDxuopNFhPfL1AAAA+gpfsweIiIjQpEmTtH79eknSxo0bFRUVddHfJw0KClJI\n",
              "SMgFb35+fj026x2ToghSAACAbuART9+//PLLSk9P129/+1uFhIRo3bp1Zo8EAACAHuQRUTpmzBjt\n",
              "2LHD7DEAAABgEtOfvgcAAACIUgAAAJiOKAUAAIDpiFIAAACYjigFAACA6YhSAAAAmI4oBQAAgOmI\n",
              "UgAAAJiOKAUAAIDpfAzDMMweoivuuOMOxcbG9sjXcjqd2rVrl6ZMmSI/P78e+Zq4NB4Tz8Nj4pl4\n",
              "XDwPj4nn4THpPjExMcrIyLjkx3h9lPakU6dOKTQ0VHV1dQoJCTF7HIjHxBPxmHgmHhfPw2PieXhM\n",
              "zMXT9wAAADAdUQoAAADTEaUAAAAwHVHaAUFBQfrlL3+poKAgs0dBOx4Tz8Nj4pl4XDwPj4nn4TEx\n",
              "Fy90AgAAgOnYKQUAAIDpiFIAAACYjigFAACA6YjSy2S32zVt2jQlJiYqOTlZBw4cMHukXmnRokWK\n",
              "jY2Vj4+PvvrqK/fxS93/nV3D5WlsbNRtt92mxMRETZw4UTfeeKMcDockqaqqSjfffLOsVqvGjRun\n",
              "rVu3um/X2TVcnptuukkTJkxQUlKSZs6cqb1790riWvEE69atk4+PjzZt2iSJ68RssbGxGjNmjJKS\n",
              "kpSUlKR33nlHEteKRzJwWWbPnm2sW7fOMAzDePfdd43rrrvO3IF6qS1bthilpaVGTEyMsXfvXvfx\n",
              "S93/nV3D5Tl79qzx0UcfGW1tbYZhGMbKlSuN1NRUwzAM48EHHzR++ctfGoZhGLt27TJGjRplNDc3\n",
              "d2kNl+fkyZPu/37//feNCRMmGIbBtWK2oqIiY+rUqUZKSorxwQcfGIbBdWK2v/158j2uFc9DlF6G\n",
              "Y8eOGYMGDTJaWloMwzCMtrY2Y/jw4Ybdbjd5st7r/G8il7r/O7uGzsvPzzdiYmIMwzCM4OBgo6Ki\n",
              "wr2WnJxsfPbZZ11aQ8etW7fOmDhxIteKyZxOp2Gz2Yzdu3cbqamp7ijlOjHXxaKUa8Uz+Zu9U+sN\n",
              "SktLFRkZKX9/193l4+Oj6OholZSUyGKxmDxd73ep+z80NLRTazxunZeZmalbb71V1dXVamlp0YgR\n",
              "I9xrsbGxKikp6fQaOmbu3LnKzc2VJH388cdcKyZbtmyZpk+frsmTJ7uPcZ14hrlz58owDE2ZMkW/\n",
              "+93vuFY8FL9TCuCy/fa3v5XD4dDSpUvNHgWS3njjDZWWluo3v/mNnn76abPH6dP279+vjRs36he/\n",
              "+IXZo+BvbN26Vfv27dOePXs0dOhQzZs3z+yR8A8QpZdh9OjRqqioUGtrqyTJMAyVlJQoOjra5Mn6\n",
              "hkvd/51dQ8e98MILev/99/XXv/5VAwYMUHh4uPz9/VVZWen+mOLiYkVHR3d6DZ0zb9485ebmKioq\n",
              "imvFJNu2bVNxcbGsVqtiY2P1xRdfaP78+dqwYQPXicm+v88CAgK0ePFibdu2jZ8rHooovQwRERGa\n",
              "NGmS1q9fL0nauHGjoqKi2KrvIZe6/zu7ho5ZtmyZ3n77bX322WcKCwtzH7/77ru1Zs0aSVJ+fr7K\n",
              "y8uVmprapTX8c7W1tTp69Kj7/U2bNik8PJxrxUQLFixQRUWFiouLVVxcrJSUFK1du1YLFizgOjHR\n",
              "mTNnVFtb637/7bff1rXXXsu14qlM+l1Wr3Pw4EEjJSXFsFqtxuTJk419+/aZPVKvNH/+fGPUqFGG\n",
              "n5+fERERYSQkJBiGcen7v7NruDylpaWGJCM+Pt6YOHGiMXHiRGPKlCmGYRhGZWWlceONNxoWi8UY\n",
              "O3askZOT475dZ9fwzxUXFxvJycnGuHHjjAkTJhg2m839Qg6uFc9w/guduE7MU1BQYCQlJRnjx483\n",
              "xo0bZ/zrv/6rUVRUZBgG14on8jEMwzA7jAEAANC38fQ9AAAATEeUAgAAwHREKQAAAExHlAIAAMB0\n",
              "RCkAAABMR5QCAADAdEQpAAAATEeUAgAAwHREKQAAAExHlAIAAMB0RCkAAABM9/8DkQidW5y2HLUA\n",
              "AAAASUVORK5CYII=\n",
              "\">\n",
              "      </div>\n",
              "      <script type=\"text/javascript\">\n",
              "        (() => {\n",
              "          const chartElement = document.getElementById(\"chart-de91acf3-fa74-4d02-a2ab-ddbbe7fc24c6\");\n",
              "          async function getCodeForChartHandler(event) {\n",
              "            const chartCodeResponse =  await google.colab.kernel.invokeFunction(\n",
              "                'getCodeForChart', [\"chart-de91acf3-fa74-4d02-a2ab-ddbbe7fc24c6\"], {});\n",
              "            const responseJson = chartCodeResponse.data['application/json'];\n",
              "            await google.colab.notebook.addCell(responseJson.code, 'code');\n",
              "          }\n",
              "          chartElement.onclick = getCodeForChartHandler;\n",
              "        })();\n",
              "      </script>\n",
              "      <style>\n",
              "        .colab-quickchart-chart-with-code  {\n",
              "            display: block;\n",
              "            float: left;\n",
              "            border: 1px solid transparent;\n",
              "        }\n",
              "\n",
              "        .colab-quickchart-chart-with-code:hover {\n",
              "            cursor: pointer;\n",
              "            border: 1px solid #aaa;\n",
              "        }\n",
              "      </style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<google.colab._quickchart_helpers.SectionTitle at 0x7ae7108a4ed0>"
            ],
            "text/html": [
              "<h4 class=\"colab-quickchart-section-title\">Faceted distributions</h4>\n",
              "<style>\n",
              "  .colab-quickchart-section-title {\n",
              "      clear: both;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "from matplotlib import pyplot as plt\n",
              "import seaborn as sns\n",
              "figsize = (12, 1.2 * len(_df_4['Label'].unique()))\n",
              "plt.figure(figsize=figsize)\n",
              "sns.violinplot(_df_4, x='index', y='Label', inner='box', palette='Dark2')\n",
              "sns.despine(top=True, right=True, bottom=True, left=True)"
            ],
            "text/html": [
              "      <div class=\"colab-quickchart-chart-with-code\" id=\"chart-dcab5aff-b2aa-4d02-b611-d43bfb9f392b\">\n",
              "        <img style=\"width: 180px;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+kAAADrCAYAAAAVHdfpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\n",
              "bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\n",
              "YQAAD2EBqD+naQAAU45JREFUeJzt3Xl0HNdhJvqvlu7qDQuxkyBAACRIggu4L9osi5Is27EWD23J\n",
              "nowS+9njE2eUWM+TjMexx3JO/OKZEx+Nt+RMbGesODnHiWXJshXJirWQtijupEgQXCCAWEliI0Bi\n",
              "6bWW+/6o7kJ3owFuALsBfL9zLutW3ermbTS6UV/VrSpJCCFARERERERERFknZ7sDRERERERERGRj\n",
              "SCciIiIiIiLKEQzpRERERERERDmCIZ2IiIiIiIgoRzCkExEREREREeUIhnQiIiIiIiKiHMGQTkRE\n",
              "RERERJQjGNKJiIiIiIiIcgRDOhEREREREVGOYEgnIiIiIiIiyhEM6UREREREREQ5giGdiIiIiIiI\n",
              "KEcwpBMRERERERHlCIZ0IiIiIiIiohzBkE5ERERERESUIxjSiYiIiIiIiHKEmu0OEBEREaUTQjgl\n",
              "MZ8+TW6/UZIkpdQTJX0+eT0iIqLbgSGdiBYsy7JgGAYMw4Cu6zAMA6Zppsyn1zPNm6aZcVnyNLlu\n",
              "WRZM00wpycssy5qyCCGcaaJYluW8nkyB5VohJlMISQ8s6dP0dlmWJ7XdSHt6GMq0Tnpfp1t2M6YL\n",
              "g8nrpIfE9LZMIXK650ifXu/60/Uj0/Ib7X+m1yCEgLAb0pYJCGu6eUAkfm/T6kj6Hb6V0D2bUn5v\n",
              "ZRlyhnlZliHJEhRZgSRLkCXZXiZJUBQFsixPWxRFSVkvua6q6qT1Eu2JemKd5PZrLc/0XMnL0/uV\n",
              "mKb3J/l1JF5v8hSA03ajO0DSv+fSv/MyfT+ml+Tv1eR64vs40/evYRjO82X6XjZNM+X7+Frf05k+\n",
              "x9f6nUtME9+f6T/D9J9/pt+JxDS5uFwuuFwuaJoGt9vtlMR84v8jouyRRC7+NSSiOUMIgVgshkgk\n",
              "glAohEgkgnA4jFgshlgsBsMwEIvFoOu6M00OtJlCbHqAna5kelz68041n9jQmxMkCZCSpohv3Cbq\n",
              "EuzAk9zmPPYazz3pr4BwlkmT1hGT5xN1MU0bZTbpvUwsz/QeSmnzaSskLRMp603zuLT/R6Ssk6lf\n",
              "mZZP8fuX1p7y+PS2pHmR6eeQ0k3pmq9jWpk2e4TzT+rvbHxdKdGe/Ls+6fc+vkwIu3tJ84l2aar5\n",
              "xNQSmftHdBupLhe8Hg98Ph/8fj98Pt+kUlBQgMLCQhQUFDj1xLzH48n2SyCa8xjSicgRiUQwMDCA\n",
              "gYEBXLlyBSMjIxgdHcXo6OikejAYRDgcRiQSyX7YlSRAluIBVoKQEZ9KTptIrOMsk+325HVke3nq\n",
              "fHyZnPx86fNTPF5Kff7kvqX0NxG8k5alhJn5Mtz2WiE+/c+RSJuZ6q/VTP4Zm+pnPV1wzfS4aYPu\n",
              "PHk/afYkB/e0uuSE+eR2AcmaHPYlS0x+Div5OeLFgr1s0vL4uuk7EUTS+hl2RqS0A1PsyLvez23y\n",
              "Tp60HU7xeec7NPH9mdwuxXf8JH+3JuryNG1TPg6p39vO/5f2vZ3c38ROrEw7mK5FANJUO0PTfv4p\n",
              "71Xi/Up+vy0BCMv+vbAEYFiQLAswLUimZS9L1A0Tkm5CMixIhgmY1/93XvN4UF5WhvLy8oyloqKC\n",
              "QZ7oGhjSiRaQaDSK7u5udHZ24uLFi+jv73dCef/AAEZHRq79JLIEobkgVBlCVYDEVLGnQpWBxHxy\n",
              "wFXsacryKcMsIGR5UnAVySFWTttwIiIiotlhWXao1+3wjpgBKaZDihrxokOKxacRHXI4BimiT/l0\n",
              "FRUVqKmpQW1tLWpra516Xl7ebXxRRLmLIZ1oHopEImhra0NnZyc6OjrQ2dmJzs5OXOrthch01Nul\n",
              "wvS5ILwahM8Ny+eG0NwQmgq4VQi3CqHZUygyQzERERFNz7QghWOQQ1FIoRikUBRyKAZpPAJlLAwp\n",
              "FJv0kOLiYixfvhxr167F+vXrsXbtWhQUFGSh80TZxZBONMcJIdDT04PTp0+jubkZzc3NaG1tnTQE\n",
              "XXhcMPO9sPK9EPk+WHkeWD4NwusGXEqWek9EREQLkm5AHg2nlpEQ5GA0ZbWq6mqsX7cOa9euxbp1\n",
              "67B8+XKoKq99TfMbQzrRHGMYBs6cOYOjR4/i9OnTONV8CqMjoxMrKDLMIj/MRQFYBV5Y+T5Y+V7A\n",
              "zT9oRERElONiBpThcchD41CGxqAMjUOKGU6zz+/H9m3bsHPnTuzcuRMVFRVZ7CzR7GBIJ5oDBgYG\n",
              "cPDgQRw6dAiHDh3C+Pi402YFPDCLAzCL82AVB2AV+uzzvYmIiIjmOiHsIfKX46F9YBTyWNhprqmp\n",
              "wc6dO3HHHXdg48aN0DQti50lmhkM6UQ5yDAMvPvuuzh48CAOHDiA9vZ2p80KeGBUFMKsKIBZkgdo\n",
              "riz2lIiIiOj2ksYjUPquQu27CrV/FDBMAICmadi6dSseeOABvO9974Pf789yT4luDkM6UY4wDAPH\n",
              "jx/HG2+8gT1792JsND6EXZVhlBXArCiEUVEAkefNbkeJiIiIcoVp2UfYe6/aZSQEAHC5XLjzzjvx\n",
              "wAMP4O6774bXy+0nmjsY0omyyDRNnDhxwg7me/bg6tWrAADhc0NfWgxzySL7aLnC4etERERE1yKN\n",
              "haH2DEHtHnICu6ZpuPvuu3H//ffjzjvv5H3aKecxpBPdZkIInDt3Dq+88greeustDA8P28u9buhL\n",
              "i2BUl8AqDvA2Z0RERES3QBoNQ+2+DFfPEORR+zz2QCCAhx56CI888ghWrVqV5R4SZcaQTnSbjIyM\n",
              "4LXXXsPLL7+MtrY2APZt0fSlRTCqSmCV5AEygzkRERHRjBIC8kgYas9luDoHnXu0r1y5Eo888gg+\n",
              "8IEPID8/P8udJJrAkE40i0zTxNGjR/GrX/0Kv/3db2HoBiDL0CsXwagtg1lewGBOREREdLtYAkr/\n",
              "VbjaB6BeugJYAm63G+9///vx6KOPYtOmTZB5lxzKMoZ0olkwMDCAX/7yl3j55ZcxMDAAALAKfNDr\n",
              "yqAvK+EV2YmIiIiyLaLD1TUIV/uAMxx+aVUVPv6xj+HDH/4w8vLystxBWqgY0olmiBACR48exc9/\n",
              "/nO8/fbbsCwLcCnQq0ug15XBWuTneeZEREREuUYIyEPjcLX3w9U9BJgWNI+GD33wQ9i9ezfq6+uz\n",
              "3UNaYBjSiW7R2NgYXn31Vbzwwgvo7u4GAJhFfujLK2BUFwOqkuUeEhEREdF1iepwdQzCdb4f8ngE\n",
              "ALBx40bs3r0b9913H1RVzXIHaSFgSCe6SS0tLXjhhRfw2r//O2LRKKDI0KuLoS+vsK/OTkRERERz\n",
              "kxBQeq/C1dYHtfcqAKCoqAj/4T/8B3z0ox9FcXFxdvtH8xpDOtEN0HUde/fuxc9+9jOcOnUKAGAF\n",
              "PNCXl0OvLeW55kRERETzjDQegautD+6OQSBmQFVVPPDAA3j88cexZs2abHeP5iGGdKLrMDg4iJde\n",
              "egm/+MUvnPuaG0sWQV9RDrOikOeaExEREc13hgm16zLcrX2QR0IAgHXr1uHxxx/HfffdB5eLB2to\n",
              "ZjCkE01BCIGmpib8/Oc/x1tvvQXTNAG3ilhdGfTl5RABT7a7SERERES3mxBQBkbhau21b+MmgOLi\n",
              "YuzevRuPPvooh8LTLWNIJ0oTDAbxm9/8Bi+++CJaW1sBAGahD3r9Yl4IjoiIiIgc6UPhFVXFrvvu\n",
              "w+7du7FhwwZIHG1JN4EhnSiutbUVv/jFL/Dr115DOBQCZAl6ZRH0+gpYJXkc0k5EREREmcWHwrva\n",
              "+qBctYfCr1ixArt378ZDDz0En8+X5Q7SXMKQTgtaJBLBW2+9hRdffBHNzc0AAOHXEKsrh1FXCuFx\n",
              "Z7mHRERERDRnJO653toH14UhwBLw+X34vQ//Hnbv3o2ampps95DmAIZ0WpBaW1vxyiuv4JVXX8XY\n",
              "6CggAcbi+IXgygsBmUfNiYiIiOjmSZEY1PYBuM8PQApFAQAbNmzAww8/jF27dvHoOk2JIZ0WjOHh\n",
              "YfzmN7/BK6+84pxrLjxu6HWl0OvKIfxalntIRERERPOOJaD0XoGrrR9q/1VAAB6PBw888AA+8pGP\n",
              "8Nx1moQhneY1Xdexb98+vPrqq9i/f799hXZZhrGkEHptGcyKAkCWs91NIiIiIloApFAUaucgXB2D\n",
              "kMcjAIClVVV4+CMfwYc+9CGUlZVluYeUCxjSad4xDAPHjx/Hnj178OZbb2J0ZBQAYBb5YdSUQa8u\n",
              "BjTex5KIiIiIskQIyINjcHUM2OeuGxYkScLGjRuxa9cu3HfffSgpKcl2LylLGNJpXohGozh8+DD2\n",
              "7t2L3739tn2eOQDhdUNfVgK9phSigOf9EBEREVGO0Q2o3UNwdV2GMmhvw0qShA0bNjiBvbS0NMud\n",
              "pNuJIZ3mrGAwiEOHDmHPnj3Y98479m3TAAifBn1pEYylRbCK83gROCIiIiKaE6RwDMqFYagXhqAO\n",
              "jgLCDuyNjY3YtWsXdu7cierqap7DPs8xpNOcoes6Tp8+jSNHjuDw4cM4ffo0LMsCAFh5HhhLi2As\n",
              "LYa1yM97mhMRERHRnCZF4oG9ZyKwA0B5eTl27NiBHTt2YOvWrSgoKMhuR2nGMaRTzrIsC+fPn8eR\n",
              "I0dw9OhRHD9+HJGIfYENSBLM4gCMigKYlcWwCrwM5kREREQ0L0mRGJTeq1D6rkLtH4UU1e3lkoSG\n",
              "hgYnsDc0NPDWbvMAQzrlBCEEent7cfbsWZw5cwZnz57FuXPnEIoPYQcAs8AHs7zALqX5gEvJYo+J\n",
              "iIiIiLJACMhXglD6R+zQfnkMsOxIJ8ky6mprsXbtWqxZswZr165FXV0dFIXbzXMJQzrddqFQCN3d\n",
              "3eju7kZHRwfOnj2Ls2fPYmRkZGIlCTDzvbCKAnYoLyuA8Lqz12miLPO+dgJS1Mh2N4iIcpLQVIQ/\n",
              "uDHb3SDKDt2EMjgKZXAU8vA41OEgYJhOs8fjQUNDA1atWoWamhosW7YMNTU1KCws5LntOeq2h3RJ\n",
              "knDlyhUUFhbezv+WbiMhBMbGxjA4OIj+/n709PSgq6sL3d3d6OrqwuDg4KTHWAEPzCK/HcqLArAK\n",
              "/TxSTpTE98ujkCN6trtBBAD40Y9+BAD47Gc/m+WeENksjwuhR7dmuxtEucESkEfDkIfHoQyN2dOR\n",
              "kHNOe0Jefj5qk0L70qVLUVZWhrKyMixatAiyLGen/wQ12x2gucE0TYyPj2NkZASjo6MYHR116pcv\n",
              "X8bAwAAGBwcxODiIgcFBRBPnjqex/BqsigJYeV5YeV6IfC/MRX7AzV9FIiIiIqJbJkuwCn2wCn0w\n",
              "6srsZYZpB/dEGQtjZDSMplOn0NTUNOkpVFVFaWkpysvLUVZWhtLSUhQVFaGgoAD5+fkoKChw6vn5\n",
              "+VBVbsvPpKz8NP/u7/4OL730EgYHB/G1r30Nn/70pwEAf/Znf4bf/va30HUd+fn5+OEPf4hVq1YB\n",
              "sI/Af+Mb38CvfvUr9Pf349vf/jbOnj2LF154ASMjI/jhD3+I97///Rn/v2g0img0mrJM0zRomjar\n",
              "r3OuM00TT/+/T+PsmbMYHx+/rscIrxuW1wVRvAiW1w3h1WDleSDyPLACHkCdu0fHtQOtkMfC2e4G\n",
              "LVAc6k5ENDUpasD7m8lBg2g2WXleRO+oz3Y3ro+qwCoKwCoKpC63LEjBqB3cg1FIoSikcAxmKIaL\n",
              "I8Po7esDrmPgdX5BPp752jO46667ZukFLCxZCemapuHw4cM4d+4ctm3bhieffBKqquJLX/oSvvWt\n",
              "bwEA/uVf/gVf+MIX8NprrzmPCwQCOHToEN588008+uij+P73v4+jR4/i+eefx5//+Z/jyJEjGf+/\n",
              "b37zm/jLv/zLlGXPPPMMvv71r8/aa5wPxsfHceSw/TO1vC6IgB20hccN4VbjRbHnfW4Ij3te35Nc\n",
              "HgtDuRLMdjeIiIgojSQE/0YT3QxZhsjzwszzwszULgSkiA4pFIMU1SHFDEhRA1JMt5ePRyCPhjE6\n",
              "MoqTJ08ypM+QrIT03//93wcArF69Gqqqoq+vD0uXLsXrr7+O733vexgbG4NlWRgeHk553BNPPAEA\n",
              "2Lp1K4LBID7xiU8AALZv347W1tYp/78vf/nL+OIXv5iyjEfRr01VVUiSBCEE5LAOhHUog2P2nji3\n",
              "MhHUEyHd644fPZ+fod3K82a7C7SAyVdDkHidTyKijIRkD+8lup3m5bahEEDMgByKOUfVnXoinEcN\n",
              "yDET0FNH+blcrix1ev7JSkj3eDxOXVEUGIaB7u5uPPXUUzhy5AiWL1+OpqYmvO9978v4uMQtBJLn\n",
              "DWPqoaAc2n5z/H4//uf//J9oaWlxzkNPPh99ZGQE41dHp34CCRAeN6yA5pyDbuV77eHvfs+cC/Bz\n",
              "ZjgTzUu+Xx6FxAvHERFlJDQV4Q80ZrsbRHND/Oh44vx0KX6OuhyMQg7HANOa8qEejwcFBYUp56QX\n",
              "FBSgqKgIjz322O17DfNczpzhPzIyApfLhcWLF0MIge9///vZ7hIBuPfee3HvvfdO2W4YBoaHh1Mu\n",
              "HDc4OOjM9/f3o7e3F9bgWOoDZQmW3wMr3wNzUQBWkR9mUQDQuAeOKBOhqZj6TybR7fX/PPV5u+Lh\n",
              "dzblBqHlzCYtUW4xTPue6kPjkEdCkEfDUMbCgJ46uF2SJJSUlKC8pty5wntZWZlz4bjEFd/dbt4S\n",
              "+XbImW+09evX4xOf+ATWrl2L4uJi7omZI1RVdT64U9F1HRcuXHBuwZaYdnV3Y/TiFagXrzjrWn7N\n",
              "vgVb4nZsiwK8FRsRwPv/EhER0fQsYR8RH0q+9Vo45cJvLpcLy5bVptwvvaamBlVVVSmjnSm7bvt9\n",
              "0omSDQ8P49y5czhz5gzOnj2LM2fO4MqVidAOCTCLAjDLC2CUF8AqzgMU3rORiIiIiBY4Yd8PXem7\n",
              "CqVvBOrQWMoRcs3jwZqGBqxZswZr167FqlWrUFFR4Zw6TLmLIZ1yihACAwMDTmhvampCc3PzxDUH\n",
              "FBlGaR7M8kKY5QX2RWKkuXVuOxERERHRTYnoUPtHoPRdhdo/Aikcc5pq62qxbu06rF27FmvXrkVt\n",
              "bS3vXz5HMaRTzguHwzhx4gSOHDmCI0eOpFzJX3hcMJYsgrG0GGZ5PiDzKDsRERERzR/ySAhqzxCU\n",
              "S1dSbjW4qKgIO3fswPbt27F9+3YUFxdnsZc0kxjSac4ZHh7GsWPHcPjwYezfvx9DQ0N2g1uFvmQR\n",
              "jKVFMMsLAJVDeYiIiIhojhEC8kgY6oUhqD1DkEfDAOzzyTdt2oQd8WC+YsUKSBxROi8xpNOcZlkW\n",
              "mpubsWfPHuzZswd9fX12g6pAX1wIo6oY5pJFPI+diIiIiHKXEM4Rc7VnGPKYHcw1j4a777ob9913\n",
              "H+666y54vfPw3uw0CUM6zRtCCLS0tDiBvbu7225wq9CriqHXlsIqCvAcdiIiIiLKDVEdrq7LUNsH\n",
              "oIyEAEwE8/vvvx933HEHg/kCxJBO81ZHRwdee+01vPrrVzE4MAgAsPK80GtLYSwrgfBpWe4hERER\n",
              "ES04loDSfxWu9gGol64AloDqUnHP3ffgwQcfxJ133snboS1wDOk075mmiWPHjuGVV17Bnr17EYtG\n",
              "AQBGRQGM2jIYlUUcDk9EREREs0oaC8PVMQhX56BzVfb6+no8/PDDeOihh1BQUJDlHlKuYEinBSUY\n",
              "DOLNN9/Eq6++ihMnTgAAhOaCXlcKva4cIsC9lkREREQ0QywB5dIwXG39UPtHAAB5eXl46KGH8PDD\n",
              "D2PVqlVZ7iDlIoZ0WrB6enrwq1/9Cr/61a8wMmJ/aRqLC6EvL4e5eBEg89x1IiIiIrpxUjgGtX0A\n",
              "7vP9zlHzbdu24dFHH8U999wDTeNplzQ1hnRa8GKxGPbu3YsXX3xx4ui6z41YXTmMujIIrzu7HSQi\n",
              "IiKi3CcE5MtjcLX2wXVhGBACfr8fDz/8MD760Y9i2bJl2e4hzREM6URJ2tvb8Ytf/AKvvvoqgsEg\n",
              "IEnQlxZBr6+AVZLHK8MTERERUSrDhNp1Ge7WPsjxK7TX19dj9+7deOihh3h1drphDOlEGYTDYbz+\n",
              "+ut4/vnn0draCgAwC33Q6ytgVJcAqpLlHhIRERFRNknBKFxtfXC3DwAxA4qq4v5du/Cxj30M69ev\n",
              "h8SDO3STGNKJpiGEwKlTp/D888/jrbfegmmagFtFrLYU+ooKXmiOiIiIaCERAsrgKFzv9UG9NAwI\n",
              "oKioCLt378Zjjz2G4uLibPeQ5gGGdKLrdPnyZbz00kt48cUXMTw8DCB+obkVFTAXF3IoPBEREdF8\n",
              "lWFI+9q1a/H4449j165dcLlcWe4gzScM6UQ3SNd17N27F88//zyampoAAJZfg76iHHptGaDxS5qI\n",
              "iIhoPpDGwnC19cPdOegMaX/g/vvx8Y9/HOvWrct292ieYkgnugWtra148cUX8etf/xqRSARQZOhV\n",
              "xdBXlMMqCvDoOhEREdFcYwkofVfhau2D2ncVAFBcXIyPfvSjeOyxx1BSUpLd/tG8x5BONAPGx8fx\n",
              "61//Gi+88AI6OzsBAOYiP/S6chjVxYBbzW4HiYiIiGh6UR2ujgG42vohB6MAgI0bN+LjH/847r33\n",
              "Xqgqt+fo9mBIJ5pBQggcP34cL7zwAvbu3QvLsiaOrteWwSrlbdyIiIiIcoYQUAZGobb3w3XxCmBa\n",
              "8Hg8+NCHPoTdu3djxYoV2e4hLUAM6USz5PLly3j11Vfx8ssvo6enBwBgBTzQa8tg1JZCeN1Z7iER\n",
              "ERHRwiSFolA7BuHqGHCOmtfW1uKxxx7D7/3e7yEQCGS5h7SQMaQTzTIhBE6ePImXX34Zb7z5BqKR\n",
              "KCABxuJFMKpLYCxZBLh433UiIiKiWWVaUHqvwNU+YJ9rLgCv14sHH3wQjzzyCNauXct7m1NOYEgn\n",
              "uo2CwSDeeOMNvPzyy2hubrYXKrJ9K7fqEvtWbioDOxEREdGMsOz7mqvdl6FeHIYUNQAA69evx6OP\n",
              "Popdu3bB5/NluZNEqRjSibKkq6sLb775Jl5//XV0dHTYC1UZ+uJFMKqLYS5eBChydjtJRERENNcI\n",
              "AXlwDGrPZbguDEOK6ACAktJSPPSBD+AjH/kIamtrs9xJoqkxpBPlgPb2diewd3d32wtVBUZ5PoyK\n",
              "QpiLCyH8nux2koiIiChXWRbkoXGoPUN2MA/HAACLiopw/65deOCBB9DY2AhZ5gEQyn0M6UQ5RAiB\n",
              "trY2vPnmm9i7d69zOzcAsPK8MCoKYC4uhFmaz2HxREREtKBJwSiUvqtQ+65C7R8BdBMAUFBQgF3x\n",
              "YL5x40YoCreZaG5hSCfKYb29vTh06BAOHDiAI0ePIhQM2g2KDKMkD1ZJHsziAMziPN6LnYiIiOY3\n",
              "w4RyeQxKrx3M5dGw01RVXYWdO3bi7rvvxpYtW3hPc5rTGNKJ5gjDMNDc3IwDBw7g4MGDaGlpSWm3\n",
              "8rxOYLeKA7AKfIDMK5QSERHRHCSEfaT88hjkoTEoQ+NQroaAeHTxeDzYtm0bdu7ciZ07d6KysjLL\n",
              "HSaaOQzpRHPU6Ogozpw5g+bmZqeMj49PrKDIMPM8sPK9sPJ98akXIuDhBemIiIgodwgBKRSFPBKG\n",
              "fDVoB/KhcUhR3VnF7XajoaEBjY2N2LlzJxobG+FyubLYaaLZw5BONE9YloXu7m40Nzfj9OnTaGlp\n",
              "QUdHB8LhcOqKkgQroMHK88LyuSG8GoTPDeFzw/K6IXwaQzwRERHNPNOCFIxCHg3HSwjyaBjKWBgw\n",
              "rJRVKysrsW7dOqfU19dzCDstGAzpRPOYEAIDAwPo7OxMKe3t7RgZGZn6cZoLlkcF3CqE2wXhViE0\n",
              "1Z7GC1wKhKoAqmxPFdmZh8Rh9kRERAuGEIBhQooakKI6pFAMciiaNI1CDsWcW6El0zwe1NbUoLa2\n",
              "FrW1tairq8OaNWtQVFSUhRdClBuuO6SPjo5O256fnz8jHSKi2yMYDGJgYMAp/f39KfXh4WGMjY3B\n",
              "sqxrP1k6RbZDuyxByDIgSxCKBMgyIMvxumSH+fhUTDUvpa4rnGVw2jOtm/J8UywTcrxPUvJ8Yh2Z\n",
              "5/QTEWUiBCAS06R6vE1KbgPsdqSuc0MSO34l5x974iyXIBLziXWceSl1XZogBGAJ++i2aQGWBZjC\n",
              "rhsmJN2EZJhAYuoss+xh6DE7kMsx0563pn5fNU1DeXk5ysvLUVFRgZqkUF5eXs7bohGlue6QLssy\n",
              "JElC8uqJeUmSYJrmrHWSiLLDsiyEQiGMjIxgdHQ0ZRoKhRAKhRCJRBAOhxGJRFLmY7EYYrEYDMNw\n",
              "6rquO2XOkCcCu0jsJEiE/OSdALJ87R0DU+18kDDxXCkblBN1kbyRmb7Bmtj2TJ9PI5I2UqXpvvqF\n",
              "88/ExvW0bSJpIzy1XUpvv57nSFlvmr6kLb+ZTfBJTylNqmSYzfAzTn/cda0v2f//tI+dWHfKvkz5\n",
              "mCn+b6T+LkxaP/35pEz/t5R5HSnxM526ffJzpv+f0sTzTGrL8PhM7VOZ6tc++fOQ9jspJbcnh00x\n",
              "sc7EsnhATV4nOZjGl0kpITe5LS3gZmqzJubteuL5kpclLU9b316GSes7z2GlPt+k/9N57XOQ8z2L\n",
              "iZ28Sd+5Imm5872c/J08VTswaaeBsyztsyAyfp4ySHyvpfzupf++AdP+3lgCkiUAYcXfe8SXWU44\n",
              "vxWSJCEvPw+FBYUoLLRLQUEBCgsLUVZWlhLK8/PzIXFHCdF143B3IrrthBAwTROmacIwDGeaXLcs\n",
              "y1kneb1M7cmPm+45k5dNV3Rdn3L5VG2JQkSUy2RZhqIoUBQFsqJAVRUoigo1vkxV1Yl2WYYsy1BV\n",
              "1amntyXXk4skSU498f9KkjSpXIsQAkIIZ1RXop68PDGfqKcX0zQn1dOn6ctM04RpWbBME5YQ9jSx\n",
              "Xnx5og+5IP3nn3gvE8XlcqUsc7vd0DQNbrfbKZqmQdM0uFwu+Hy+jMXv98Pn86GgoACBQID3Hyea\n",
              "JTcV0o8dO4YzZ87gySefxNWrVxEOh7F48eLZ6B8R0ZyR2PlwrZ0F6Tsg0jcMExucyRuPySWxYZhe\n",
              "Em2Z+pVcT98wzrShnLwBnb4xndjYTm6bauP7ZpZdTx+S+53+mJuV+DmlT5PbkzfKM03T6+kb8Tfy\n",
              "HNdaP1M/M/Uh02u4nv9rqteRaT75d2+q383ktvTAda3/a7qf1bU2YzL9zgOTf2+m+x1ODpiZQmem\n",
              "YJppPlOQSqyTCLuZQnCmwJxYlh6qlaSwnb5+4v+jmZP+/WvGw3umnQrJ60/1e5nsWjs4kn8v+L4S\n",
              "zS83HNL/7u/+Dn//93+P8fFxnD9/HufPn8dnP/tZ7NmzZ7b6SERERERERLQg3PBVGn7wgx/g4MGD\n",
              "zoXili9fjsHBwRnvGBEREREREdFCc8MhXdM0eL3elGW8ZyERERERERHRrbvhkF5aWor33nvPOffl\n",
              "ueeeQ3V19Yx3jIiIiIiIiGihueFz0tva2vDJT34Sp0+fRnFxMfLz8/Fv//ZvqK2tna0+EhERERER\n",
              "ES0IN3V1d8uy0NLSAiEEVq1axdsvEBEREREREc2AmzqZ/PDhw3jjjTcgSRIeeOAB7NixY6b7RURE\n",
              "RERERLTg3PA56d/61rfwxBNPYGhoCJcvX8YTTzyBZ599djb6RkRERERERLSg3PBw95UrV+LAgQMo\n",
              "Li4GAAwPD2Pnzp147733ZqWDRERERERERAvFDR9Jz8/PdwI6ABQVFTn3TCciIiIiIiKim3fd56Q3\n",
              "NTUBAHbt2oVPfepT+MxnPgPAvgXbAw88MDu9IyIiIiIiIlpArnu4+3S3WJMkCe3t7TPWKSIiIiIi\n",
              "IqKF6KZuwUZEREREREREM++mbsEGANFoFNFo1JnneelEREREREREt+aGLxx38OBBNDQ0wOfzYdGi\n",
              "RU4hIiIiIiIioltzw0fSv/CFL+C5557DH/3RH+F3v/sdvvvd78Lj8cxG34iIiIiIiIgWlBs+J33z\n",
              "5s04fvw41q9fj1OnTgEAtm3bhiNHjsxKB4lo/hBCIBKJIBgMIhgMYnx83KkHg0GEw2HEYjHouu6U\n",
              "9HnLsq75/6iqCpfLBVVVU0pimdvthqZp0DQNHo8nZZqoe71e+Hw+eDweKIpyG346RETzmxACpmnC\n",
              "NE1YluXUDcOAZVkQQiCxWZqop2+mSpIEWZZTpsl1VVWhKIozlSQpGy+ViOiW3PCRdJfLBQAoLi7G\n",
              "8ePHUVVVhcHBwRnvGBHNDaZpYmhoCAMDAxgeHk4pV65cSaoPY3w8eF0hO9domhterw8+nw9er9cJ\n",
              "8MnF7/fD7/dPWpbe7vV6Ics3fKYREdGMSuw0DYVCCIfDCIfDiEQiKdNEPRKJIBqNOtNMJXnHqmEY\n",
              "EztYYzHohuEE8dtNlmWoigIlXlRVhcvthsvlmrJomga32+2UxA7c5GUej8cpiZ27yTt7E38rNE3j\n",
              "jgIiumE3HNI/8YlPYGhoCH/xF3+Be++9F7qu46tf/eps9I2IcoBlWejr60Nvby96e3udemLa398P\n",
              "0zSnfLwEwK9aCCgmij0WPIqAJlvQFAGPnDQvC2iKgCIJqJKAKsGpKzLsqSRwrU0dAcASEkwBmEKC\n",
              "JQATqfO6JcEQEmLxqW7FS7weSykyolYMsXAQ4aCEESEjakkwrJvf6PJ6PHZ4Twv1yeE/Ufd6vc7G\n",
              "31T1xEahqt70tUCJaA6IxWIIhUIIhULOCKTk+UR9qmXhcDi+LIhwODLpKPXNkiUBV/w7O1FUCfBI\n",
              "An5JQFUBWRWQJXtdOf4YWYJTlwBIEpzv+ImpAOLLBex/BCRYAISwlwkAQkjx73/7O98S9t8CSwBW\n",
              "/G+AZQKmIcEMSwjF/yYkihGfn2mSJMGjafD6vPB6fc73d+I7PrHzNtMOXr/fj0AggLy8PPj9fuTl\n",
              "5cHtds94H4ko99zSLdh0XUc4HMa6devQ3d09k/0iotssGo2iu7sbXV1d6OzsTJnGYrFJ60sA8l0m\n",
              "Cl0GFrlMFLhMBFQrXibqPsWCPA8PIpgCiFkSoqYd2iPxesyS4vMyYqZdj1r2OlEzqR5fHrNkRE17\n",
              "4/JWybLsBHZNc0PT7ACffpTI7XY7w/6TTwtIHiKaPlUUBbIsp5TEUNLkZYl+JIagphcAKUeVMi2b\n",
              "zvWsN9VzJi9P70/6fKZhtIl64jUmSvrPIHlZ4meU/PNLrvMI2/xlGAZCoVDKUen0kh6eE8smwnQ8\n",
              "YAeDCIZCMAzjpvoiAdAUAbdkQZMtuOM7Rd2ygDu+k9Qlx+elxHK7zR1vc8kCLklAlQGXNDHvksW8\n",
              "+Y4Xwv5uN4S9A9ewJOiJ+fiOXCNph64eb9ctOWlHLxCzZOgifYfvxI7fmLj5Hb1ulwuBvAACgTwE\n",
              "AgHk5+ejoKDAmSbX8/PzUVhYiKKiIl4/imiOmZH7pFdVVaGnp2cm+kNEs0wIgYGBAbS0tOC9995D\n",
              "S0sLzp8/j97e3klHVTRZoETTUeo2UOw2Uei2A/kit4l81YTKUdszQgjAEIiH9niAj4f/xJH95A0+\n",
              "PWljz95oxKSNR0NMbFDO5lEiujWJobhOeFdkKIoKRZahJO0guVZRr7Fupp0uN/M8iR0M6fPJOx+S\n",
              "d94k76S41rnEyTtKEjLtxEg+dzm9WJbllORzny3LcoZbm6YJXddhxIdgJ5fE8sRQ7cQw7lgsNqme\n",
              "KClDwRNDw+NDvm+FIgl7hFF85JEz4ihl2TXq8TDukgS4Pyi3TOzondh5G0vs1E3awRs2JURMGRFL\n",
              "RsSp29NwfOfA9fB6vSgqKspYSktLUVZWhtLSUixatIinZBHlgBkJ6dXV1TySTpSDhBDo6elBS0uL\n",
              "E8rfa2nB1ZGRlPXyVBNlmoFSzUCppjv1fNXiht08Yg//tI8KJQd3IzEkNHlYaOJUAWEPK7XiQ0yF\n",
              "QHxeig8xRXzY6cRogMTyxDBUxB8HZ35yPdP8JNfx1yr9hIhJ/4dIbUvuM9JfQ9L6AtKk1yUSw27T\n",
              "htwmhuEm/1yspHWtSeul/vwTjzVF6s/bgjRRj69vipkZhUE3R4aAS4kfWZaslKPLzpFpefKR6cTR\n",
              "6kT4djvhe2Id7gSl66FbQNiUEUoUQ06ZDxoyxgx7Om4qGDfkaXfYqqrqhPZEcC8vL0dlZSUqKyux\n",
              "ePFiHpUnug2u+wTGpqamKdt0XZ+RzhDRrQmFQjhz5gxOnTqFU6dOobn5FEZHx1LWKXYbaCzQscSj\n",
              "Y7FHxxKvjoA69y7mRjfOPh8UUFPiKc11E0E+EeaTd7Ik7wSY2OFipq2XvqPAWSd5J0HaDprMy1J3\n",
              "XKTPJ/rr7PQA0nboJEyEiPRDCfZ5y8JZK7EjMZFpE+c6S0g+/9kO1FL8nGg1PlUkQEF8Gn+cc12M\n",
              "+LUw7PrEtTLUpCCucCcmZZlLBlyyhXzX9f0dFwKIWBLGDRnjhoIxQ8aormBEVzBqKBjRZYxcjuJU\n",
              "3yVYU4T54uJiJ7QvWbIElZWVqK6uxrJly5CXlzeTL49owbruI+m1tbVTP4kkob29fcY6RUTX59Kl\n",
              "Szh58qQTys+fb4NlTXyki90Gqn0xLPVOhHJNYTgjIiKiqVkCCBoyRgwFV2MKhnUFwzEVwzF7elVX\n",
              "Mh6RLy4qwrKaGtTU1GDZsmWoidfLysp4DQ6iGzAjw92J6Pbo7e3F8ePHcezYMRw/fhx9fX1Om0sW\n",
              "qPLGUO2NodoXQ5WPR8iJiIho5lkCGNXt8D4UVXE5pmIwqmIgqmI4pk4aq+Xz+bBixQrU19c7Zfny\n",
              "5Rw6TzQFhnSiHDYwMIBjx47ZofzYMVzq7XXa/KqFOl8UNf4YlvliqPDoHHpJREREWWVYcEJ7Irj3\n",
              "R10YiKopQ+hlWcLSpVWor6/HypUrsXr1ajQ0NCA/Pz+LvSfKDQzpRDkkHA7j3XffxcGDB3Ho0CF0\n",
              "dXU5bT7FQq0/ijp/FMv9MZRpBi/qRkRERHOCYQEDURW9ERd6Iy70xachM/UqiVVVVVizZg3WrFmD\n",
              "tWvXor6+HpqmZanXRNnBkE6URUIItLW1OaH85IkT0OO37dFkgTp/BMsDMdT5oyjXjHlzL1oiIiIi\n",
              "IYBRQ8alsAsXwm5ciE+Tg7uiKKivr8eaNWuwYcMGbNiwARUVFVnsNdHsY0gnus3GxsZw8OBBHDhw\n",
              "AAcPHsDw8BUA9pWIK70x1AeiqA9EUe2Lcfg6ERERLShCAFd0BT0hF3riwf1SxJ1yT/jysjJs2LgR\n",
              "jY2N2LBhA+rq6qAoShZ7TTSzGNKJZpkQAu3t7XjnnXewf/9+NDU1wbLsC7rlu0zU+6NYmRfBcn8M\n",
              "fl7ojYiIiCiFKYC+iAudITe6gm50hjSMGRNH2/1+H9avb8SmTZuwZcsWrF69Gqp63XeaJso5DOlE\n",
              "syASieDIkSPYv38/9u/fj/7+fgD20fJlvihW5UWxOi+Ccp5XTkRERHRDEkfbO4NudIXc6Ay5MRB1\n",
              "Oe1erxcbNmzAli1bsGXLFqxcuZKhneYUhnSiGTIwMIB33nkH+/btw5EjRxCLxQDYF3xbGYhgdV4E\n",
              "9YEofCo/ckREREQzKWhI6AxpOD/uRntQQ39SaPf7fNi4aRM2b96M7du3Y/ny5ZBleZpnI8ouhnSi\n",
              "mySEQEtLC/bt24e3334bLS0tTttij47VeXYwX+rVecE3IiIiotto3JDREbQDe3sw9Uh7YWEhtm3b\n",
              "5pTFixdnsadEkzGkE92ASCSCY8eOYd++fdi3720MDl4GACiSQJ0/ioa8CFbnRbHIbWa5p0RERESU\n",
              "MGbIOD9uH2lvDXowok9caG7p0qVOYN+yZQsKCgqy2FMihnSiaxoaGnKGsR8+dAiRaBQA4FctrE4a\n",
              "xq4p/CgRERER5TohgKGYgrZxDW1BDe1BD8KmPexRkiQ0NDRg+/bt2LFjB9atWweXy3WNZySaWQzp\n",
              "RGkS9y63j5bvw+nTp522ck23j5bnR1DFYexEREREc54lgIthlxPau0IazHhC8nq92Lx5M3bs2IEd\n",
              "O3aguroaEq/6S7OMIZ0I9jD248ePY9++fXjnnXecq7HLElDni2J1fgQNeREUcRg7ERER0bwWNSV0\n",
              "hNxoG9fQOq6lnM9eXlaG7Tt2YPv27di2bRsKCwuz11GatxjSacFKvhr70aNHEI2mXo29IT+ClYEo\n",
              "PBzGTkRERLRgjeiyE9jbgh4E4/dolyQJq1atwvbt27F9+3Y0NjbC7XZnubc0HzCk04JhGAaam5tx\n",
              "4MAB7N+/H62trU5bhUe3zy/nMHYiIiIimoIlgL6IitZxD9rGNXSG3DCEveHo0TRs3LTJOcrOW73R\n",
              "zWJIp3mtr68PBw8exMGDB3Hk8GEEQyEAgCoLLI9fjX1VIIpCDmMnIiIiohukW0BH0D6XvXVcQ18k\n",
              "6VZvBQXYsnWrc+X4ysrKLPaU5hKGdJpXIpEITp48iQMHDuDgwYPo7Ox02krcBlbm2UPYa/0xuGX+\n",
              "6hMRERHRzHFu9RZ0o23cg6tJt3pbvLgCW7fagX3z5s0oKSnJYk8plzGk05xmGAbOnDmDo0eP4ujR\n",
              "ozjV1ATdMAAAmiyw3B/Byrwo6gNRXvSNiIiIiG4bIYDhmILzQQ1t4xraQ5pzPjsAVFUtxaZNm7Fp\n",
              "0yZs3rwZ5eXlWewt5RKGdJpTLMtCW1ubE8rfffddhMNhAIAEoNIbw3J/FCsDUVT7YlB5GhARERER\n",
              "5QBLAP0RFW1BDR1BNzpDE/dnB4AlS5Zg82Y7tG/atAmLFy/m7d4WKIZ0ymm6ruPcuXM4efIkTp48\n",
              "iaaTJzEyOuq0l2k6lvujWBGIodYfhZdXYiciIiKiOSAR2tuDGjpCbnQENYTMiSNMxUVFWN/YiMZ4\n",
              "WblyJa8ev0AwpFNOGRsbw6lTp+xA3tSE06dPIxaLOe1FbgN1viiWB+wj5nkuK4u9JSIiIiKaGZYA\n",
              "BqIq2oNudIXc6A5pKee0u10urG5owPr167F+/XqsWbMGpaWlPNo+DzGkU9ZEo1G0trbi7NmzTuns\n",
              "7ETiV1ICsMQTwzJ/DDW+GJb5YshnKCciIiKiBWJEl9EdskN7V8iNSxE3rKT0VlxUhNUNDVi9ejUa\n",
              "GhrQ0NCA4uLi7HWYZgRDOt0WsVgMHR0dOHv2LM6dO4czZ87g/PnzMM2Ji7l5FIFKjx3Ia/xRVHl1\n",
              "aBy+TkREREQEwL7l24WwG90hNy6GXbgYcWE4pqasU1JSgoaGBqxatQrLly/H8uXLUVlZCUVRpnhW\n",
              "yjUM6TSjLMvCpUuXcP78+ZTS3d0Ny5o4Cu6S7UBe6dWx1Kuj0htDsduEzNE6RERERETXLWhIuBSx\n",
              "Q/uFsAsXw+6UYfIAoGlu1NbWOaE9UYqLizlcPgcxpNNNCYVC6OnpSSmdnZ1obz+PSCSasq5XsVCh\n",
              "6Sj3GKj0xrDUq6NUM6Dw+4CIiIiIaMaNGzL6Iir6Ii67RFUMRF3QrdQNcL/fh+rqZaiqqkJ1dbVT\n",
              "qqqq4Pf7s9R7YkinjEzTxNDQEPr6+tDf34/e3l709PTgwoUL6O7uxtDQ0KTHqLJAmdsO4xUeHRWa\n",
              "Pc1TLXAHHRERERFR9ljx+7YnQnt/xIXLMRVDMXVSeAfs892XVlWhoqICFRUVWLx4MRYvXoyKigqU\n",
              "l5fD4/Fk4VUsDAzpC4wQAqFQCMPDwxgaGsLw8DCGh4cxODjoBPK+vj4MDAykDE9PkAEUug2UuA2U\n",
              "aAaK3QZK3CZKNAOFLg5XJwKAb7eWIph0CxUiIppZfsXC0/WD2e4G0bxgCWBUl3E5puJyVE2ZXtEV\n",
              "WCLzBv6iRYuwePFilJaWori4GCUlJSnT4uJiLFq0CKqqZnw8TY0/sTnMNE2Ew2GMjY1hdHTUmSbK\n",
              "yMiIUx8eHsbw0BCGhoYQiUanfE4ZQL7LRLXHDt2FLhOFbhMFLhPFbgOLXCZUZg+iaQVNGeMGL85C\n",
              "c9OPfvQjAMBnP/vZLPeEiIhuB1kCCt0WCt0xrAjEUtoSAf6qbgf2qzHFnuoKrgYH8N7ZYZw5M/VR\n",
              "OlmWUFBQiMLCQhQUFEwqhYWFyM/PR15eHgKBAPx+v1MWcrhfuK98Drh48SL+7//9vxgZGUEoFEIw\n",
              "GEQoFEIoGEQwGJw2bKdTJIE81UKJaiIvz0JANRFQLeTFp/nxQJ6nWjwaTkREREREKQG+JkO7EEDE\n",
              "kjCqKxgzZIwZ8WnS/HhoAINjQ+jqkGDh+oOGR9Pg9/sRyMuD3++Hx+OBx+OB1+tNmSbq73//+1FZ\n",
              "WTljrz2bZi2kh8NhfOpTn8KpU6fgcrlQXl6Ov/iLv8BTTz2FzZs34/jx49A0Df/wD/+AjRs3oq+v\n",
              "D5/85CcxOjqKSCSC++67D9/97nchyzKee+45/PM//zNKS0tx8uRJFBYW4kc/+hG+8pWv4Ny5c6iq\n",
              "qsKLL76IQCCQsS/RaBTRtECraRo0TZutlz8jXn/9dbzyyisA7HuGa4qAW7agyRZKZAHNL6DJFryK\n",
              "gFex4FMseOJTryLgUxN1Cx5Z8LzwGfAvPYUYjHLfFk0vZHC4CRHRbAoZMr7XVpLtbtACV6oZ+ETV\n",
              "1Wx3I6skCfEsYqD8GusmAn3IkBEy7RKM1yOmjIglIWpKiFgyIqaEiBVDNDiO4dFB9FoydEvCdOdp\n",
              "Nzc345vf/OZMvrysmbW08dprr+Hq1as4c+YMAGB4eBhNTU04ffo0vvOd7+AnP/kJfvazn+ETn/gE\n",
              "zp49i8LCQrz88ssIBAIwTROPPvqo0w4AR44cwalTp1BdXY0nn3wSDz/8MPbv34/y8nJ85CMfwT/+\n",
              "4z/iv/yX/5KxL9/85jfxl3/5lynLnnnmGXz961+frZc/IxLnhFd5YyjVDGiyBU0R8MiJsC7gUURS\n",
              "MLfDuUtiIJ8tg1EVlyLubHeDiIhoQbMg8e8x0RwzEehNFMMEYA+nj1oSwqacFtDtaTRpGouvN27Y\n",
              "4X7clBGzJg6MpB+UnctmLaRv2LABZ8+exR//8R/j3nvvxYc//GEAQE1NDe6//34AwOOPP47Pfe5z\n",
              "6OnpQUlJCb70pS9h3759EEJgYGAA69atc0L6HXfcgerqagDA1q1boes6ysvt/TXbtm1Da2vrlH35\n",
              "8pe/jC9+8Yspy3L9KDoA1NfXQ1VV9ISBnvD1/yFSpYkj64lpQE0Ue0h7cl1TeO3A61WqGdnuAs0B\n",
              "fRHXDQ3nIiKiGyNDoMKjZ7sbtMBxu3AyIYCQKWPMkJ0h8OOGgpCZdgTdlBEyFYQNGZMvVX1tkiTB\n",
              "o2lY5PXCGy8PPvjgjL+ebJm1kF5XV4czZ87grbfewhtvvIH/9t/+G7797W9PWk+SJEiShGeffRYD\n",
              "AwM4dOgQPB4PvvjFLyISiTjrJV/iX1GUSfOGMfWHZC4Mbc/knnvuwd69e1PPR89Qz3ThuMRF4wZH\n",
              "RzNepT2ZSxbIV82JC8W5TBS67QvHFcTnXRy9CwALfkgTXZ//71w5LxxHRDSLfKqFP1lxOdvdIFpQ\n",
              "LAGMGTKu6gquxFT74nG6glE9cS66gnFDhjnF1eATFEVBQUE+yuIXlMt04bhAIDDpQnLJ56BrmgZp\n",
              "Hg8dnrWQfuHCBSxatAiPPPIIPvjBD+Kll15CT08POjs7sWfPHtx33334+c9/jvLycixduhRXrlxB\n",
              "RUUFPB4P+vr68Pzzz2P37t2z1b05Q1VV5OfnIz8//6YeL4RAMBh0brWWuO1a+nRwcBDtQ0OY6o58\n",
              "ftVCkcu+7drE7ddMlLgNHoknSuNXbmafMFFuePqPPg0ACPDyG5TD+D1LNDtiloShqOLchm0oHsav\n",
              "6ApGdGXKAK5pbpSUlmBZSUnKLdhKSkpQVFSUcnV3v98/rwP2TJi1P8GnTp3Cl7/8ZQghYBgGnnzy\n",
              "STQ2NmLt2rV47rnn8Kd/+qdwu9346U9/CkmS8IUvfAEf+9jHsHbtWixZsgQPPPDAbHVtQZEkydkT\n",
              "lThdYCq6rk+6X3qifunSJfReuoSe8OQRCwHVQolbR6lmoFwzUOHRUe4xEFD5B5QWJt67l4iIiHKV\n",
              "EMBVXUF/dPJ90Uf0ySMBJUlCSUkJ1lRUYPHixaioqHBK4j7pDN4zSxJTHTqdBXv37sXTTz+NEydO\n",
              "3K7/kmaQaZro7+9HT0/PpHLx4sVJw+oDqoUKTUe5R0eFR0eFx0C5pnPoPBERERHRbRAyJPRFXeiL\n",
              "qOiPuNAftUvETA3UkiRh8eIKVFcvQ1VVFaqrq1FdXY3KykqUl5fD5XJl6RUsTBzMRtdNURQsWbIE\n",
              "S5YswY4dO1LaDMNAT08Pzp8/j/Pnz6O9vR1tbW04f+kS2oIT1wOQJaBCi2GpV4+XGMo8BhTueCMi\n",
              "IiIiummjuowLYRcuht24GHahN+LCaNo1clRVRU1tDerq6rBixQosW7YM1dXVWLJkyZy8htd8dVuP\n",
              "pNPCEw6H0d7ejvPnz6OtrQ1nz57Fe++1IBqNOeuoksASj45KbwxVPh01vhgKXSZvI0dERERElMGY\n",
              "IeNi2IULYRcuhd24EHZhLC2QV1RUYMWKFVi+fLkzra6uhqryOG2uY0in284wDHR0dODcuXM4c+YM\n",
              "zp49i7a2tpQr9Oe7TNT4Yljmi6LGF0OFx4DM0E5EREREC4wpgP6Iiq6QG90hN7rDbgzHUoN2RUUF\n",
              "Ghoa0NDQgFWrVmH16tUoKCjIUo/pVjGkU06IxWJoa2tDc3MzTp48iZMnT+Ly5Ylbq2iyQHU8sNf6\n",
              "Y6jyxqDy3HYiIiIimmcipuQE8q6QGxfCbkStiaNVhYWFWL9+PdasWYOGhgasXr0ahYWF2eswzTiG\n",
              "dMpJQgj09vbi5MmTaGpqwskTJ9De0eG0u2WBGl8Uy/1RLA/EsNij80g7EREREc05IUNCZ0hDe9CN\n",
              "jqAbvRE3EgFNkiTU1taisbERjY2NWL9+PZYuXcorqc9zDOk0Z4yMjKCpqQnHjh3D0aNH0dbW5rR5\n",
              "FQt1/onQXuo2eE47EREREeWcYEoo19AXcTmh3O12Y926ddi4caNz++q8vLys9pduP4Z0mrOGh4dx\n",
              "/PhxHD16FEePHsWFCxectkKXiZWBCFbm2cHdo/DXnIiIiIhuv6gpoSPkxvlxDeeDGnojE7cz0zQ3\n",
              "1q9vxObNm7F582asWbMGbrc7i72lXMCQTvNGb28vjh07hsOHD+PQwYMYGR0FYN/2bZk3ipV5UawM\n",
              "RHgROiIiIiKaNYYF9ITdaBvXcD7oRk9YgxVPXJrmxoYNG7FlyxZs2rQJDQ0NvAc5TcKQTvOSaZpo\n",
              "aWnBwYMHceDAAZw+3Qwr/u0YUC2sDESwOi+C+gCPshMRERHRzRMC6I+qaBvX0DquoSOkQY9f6E2W\n",
              "ZaxZswbbtm3Dtm3bsG7dOh4pp2tiSKcFYXR0FEeOHHFCe+LK8bIE1PqiWJ0Xwaq8CEo1M8s9JSIi\n",
              "IqJcN6bLaAvaobxt3IMxY+K2Q3V1ddi+fTu2bt2KTZs2we/3Z7GnNBcxpNOCI4RAa2sr9u3bh/37\n",
              "9+P06dNIfAxK3AZW5dlH2Wt8vM0bEREREQG6BXQENSeY9yWdV15cVITtO3Zg+/bt2L59O4qLi7PY\n",
              "U5oPGNJpwbty5QoOHDiAd955BwcPHEAwFAIAeBSBen8EDfkRrApE4FP5USEiIiJaCCwB9EdUtI5r\n",
              "aB33oDPkhiHsIeya5samTZuxfft27NixA3V1dbwlGs0ohnSiJIZh4OTJk9i3bx/27XsbPT32FeMT\n",
              "F59bnR9BA4fFExEREc07o7ocH76uoS3owXjSEPZVq1ZhR/xoeWNjI88rp1nFkE40ja6uLrz99tvY\n",
              "t28fmppOOhefK3EbaMiLYHV+BMt8MSjceUpEREQ0p0RMCR1BN9qCdjAfiE4MYS8rK8WOHTudc8sX\n",
              "LVqUxZ7SQsOQTnSdRkZGsH//fuzbtw8HDuxHKBQGAHgVgZWBMBry7Puye3m1eCIiIqKck3prNA09\n",
              "YbdzazSv14stW7Zg27Zt2LFjB5YtW8Yh7JQ1DOlEN0HXdbz77rvYt28f3n77d+jt7QNgD4uv8UXt\n",
              "o+x5EZRwWDwRERFRVpgCuBR2oT2ooT3oRldIQzR+azRFUbBu3Trn1mhr166FqqpZ7jGRjSGd6BYJ\n",
              "IdDe3h4P7G/zavFEREREWWAJoDfiQnvQjfNBDV0hDRFz4mh44tZo27Ztw8aNG3lrNMpZDOlEM2x4\n",
              "eBgHDhzAvn37cOjQQWdYvCYLrAhEsCoQxaq8CPJdVpZ7SkRERDR3GRZwMeJCZ1BDV8iNjrRQXlNT\n",
              "gy1btmDz5s3YtGkTioqKsthbouvHkE40i3RdR1NTE9555x2888476OrqctqWeGJYlRdFfSCKal58\n",
              "joiIiGhaYVNCV8iNrqAbnSE3LoQnbosGANVVVdiydSs2b96MzZs3837lNGcxpBPdRhcvXsT+/fvx\n",
              "zjvv4PixY4jpOgD7KHudP4L6gB3ai90meK0SIiIiWqhMAQxEVVwIudETdqE75EZ/0tXXZVnGqlWr\n",
              "sGHDBjQ2NmLDhg0M5TRvMKQTZUkkEsHx48dx+PBhHDx4EJ2dnU5bkdtwAnudn1eMJyIiovlLCOCK\n",
              "ruBC2IWekBsXwi5cjLihWxNHLLxeL9avX48NGzZgw4YNWLNmDXw+XxZ7TTR7GNKJckR/fz8OHTqE\n",
              "Q4cO4fDhwxgbGwMASAAqPDrq/FEs90dR64/Bw9BOREREc5BhAYNRFb0RV0oJmRNX15VlGStWrMDa\n",
              "tWuxZs0arFmzBjU1NVAUJYs9J7p9GNKJcpBpmjh37hwOHz6MY8eOoampCbFYDIAd2pd4YqgLxFDn\n",
              "j6LGx9BOREREuUUIYESXMRB1oT8eyvsiLgxEVZhJ55FLkoSlS5eioaHBCeQrV66Ex+PJYu+Jsosh\n",
              "nWgOiMViOHPmDI4dO4bjx4/jVFOTcz67BKBc01HtizmlhOe0ExER0W1gWMBQTMVgVMVA1J4ORlUM\n",
              "xlyIWakbI16vFytWrEB9fb1Tli9fDq/Xm6XeE+UmhnSiOSgajaK5uRnHjx/HyZMncfr0aYTDYafd\n",
              "p1h2YPfaob3Sq/NoOxEREd0wIYCgKWM4pmA4puJKTLHruorhmIoRXUH6FobHo2HZshosW7YMNTU1\n",
              "qKmpQX19PSorKyHLcsb/h4gmMKQTzQOmaaK9vR2nTp1yyoULF1LWKXIbWOLR7eK1S57Ke7UT0fSE\n",
              "ACwAlgAsIU3UIdltScsE7HnhPE5yltvLpKR6/PmTHnO9JACSBEgQSByns+ftIksCsgTIEJAkQI4v\n",
              "kwAoEqDE29X4VJEE5PhzEC0kQti3NRsxFIzqCkbiZVSXnWVXdHXSEXEAkGUJZWXlWLJkiRPGE9Oy\n",
              "sjKGcaJbwJBONE8NDw+jubkZp0+fRktLC1paWnDlypWUdfJUE0s8OhZ7dJRqBko1A2WaAY1H3ekG\n",
              "JEIYYG/wOfV4iLPrqdPEuqnLpk9IN/JbKdIqIkOb/f9Lk/omkkMlJCBlPtEuJdWTgmnaMitp/YkQ\n",
              "mxRwE+sl1UWGZZNDclp7UiC2BGA69Yk2U6Q+h5n+OEhpz3vj4XmuUyQBVQIUWUCFgCoJqLI9VSTA\n",
              "JQsokoBLEnDJSVNZwBVvTyx3yxbcsoA7vkxLqrvj63CnAM0GwwLCpoyQKSNoyBg3ZYwbCsYNOV6S\n",
              "6qaScgX1dAX5+SivqEBlZSWWLFmCyspKp15RUQGXyzXlY4no5jGkEy0QQghcvnwZLS0teO+995xp\n",
              "b2/vpHXzXSZK3QbKNN0J7kVuE/kuEwo3Km87IQBDALolIWZJiAnZqeuWBF3Y08Q6hphYbsTnTYH4\n",
              "NKluTdSTw1oivJmJ0Ibk8DgRNBNHSim3ybIMVVWhKAoURYEanypJyxRFSVknuaQ/XpblSe2JZcl1\n",
              "SZJSliWKJEkpJX1ZgjRFghVCpBTLspDYlLEsC5ZlwTRNmKaZsW4YxpRF13UYhoFYLAZd1xGNRqHH\n",
              "YojGYs6ymdpskgBoioBbsqDJFtyKHeTtMG9N1BULnnhdU+zgr8kCHtmyHy8LaLIFVeJIgPlCCEAX\n",
              "EiKmhIgpI2JJCJsyopY9H44vi8SDeMiQETIlhEwZYVNBdJrQneB2u1FUVISioiKUlpairKzMmSZK\n",
              "SUkJL95GlCUM6UQL3MjICDo6OtDZ2YnOzk50dXWhq6sTvb19kzZGJdgBfpHLQKHLxCK3iUUuE4vc\n",
              "BgpcJgKqvTG50DcUrXhYjlgSopaMqCkhmqmeCN1m6nzUku3lznT2jmbKsgyXS4WqqFDURFBTnVCW\n",
              "Hs6SSyKIJS9LPGd6EEsOYJmC2FSBLH35VOtdz2Omm6b3L/k1JL+u9HpivUw/i0w/r/R6prCrquqk\n",
              "+lQBerpwnSjX8zOj6yOEgGEYiEajTolEIpOmiRIOhxEOh1PqiflQKIRwOIxQKBQvQYTDkZveCaBI\n",
              "qQHfo6SF/Xion7QTwClWUl3ERw3M8A9wnjEFYFgSYvEdorGknaaJnajRpLrznS4kRM2J7/uoNfF3\n",
              "IRb/O3GjvwV+nw8FhYUoKChAfn5+yjQRxpOLz+fjdwNRDmNIJ6KMIpEIenp6nOB+6dIl9PX1obe3\n",
              "F/39/bCszOezK5JAQLUQUOzQbhe77lUSG4/xDUTFPhrkUbIz9DNxhNoQExtRiXoiJDtB2tnYsjey\n",
              "0sN21JSd9us5ijEVWZbh8/ng9/ng8Xrh8/ng8Xjg8Xjg9Xoz1jVNg9vthqZp0DQNHo/HmXe73XC7\n",
              "3XC5XHC73VBV1Zm6XC7ec5YohwghnACfXILB4KR6MBjMuDwUCiEUryfuAnKzVGkisKvpQ/yl1OWJ\n",
              "UwKcafzUAOcUgvj5//Z1ARL1xLUDJq4ZkCDF/5GS55F6Skn69Qys+KklzqkdTl1KOQ3EjIfqiRFG\n",
              "EyONjHh78qgkI77csCToQo4vR8ptxG6F1+OBz+eDz++3p/ESCARSSl5eHvx+P/Ly8hAIBOD3+50w\n",
              "rqrqjPSFiHIDQzoR3TDDMHD58mUntPf29mJwcBDDw8MpJfmK89eSGPppb9AlT5E0D0jS9F9ZImnD\n",
              "zIxvdFlO3d5IM5KGgs/EF6DX64Xf74c/bQMrMZ+8PNMybzyM+3w+uFwuHt0gohmh63pK2A+Hw06Y\n",
              "Tz6Kn37EP/3I/8SogUQ9lu2XdttomhtutwbN7YY7acdnYidpYkdpYpqoJ3aker3elJK8zO/3w+Px\n",
              "cGcpEU3CkE5EsyYSiTiB/cqVKxgfH3eO/gSDwUnzoVBo4nzQ+PmfMT0GPaZDNwyYpnld/68kSVBV\n",
              "BarqSpraR44TR5KTN6bSN7A0TUsJz8nT5OL3++H1enkFWyJaUIQQiMViKcP+dV23v7NjMed7PPn8\n",
              "fiP+HZ7pGgGJZcmbpMnXHUhelnyaSfppKYlTTxKngaSftpNY5nK5piyqqjqjkVRV5U5TIsoKhnQi\n",
              "mjPSN+IySWykERERERHNRQzpRERERERERDmCYzSJiIiIiIiIcgRDOhEREREREVGOYEgnIiIiIiIi\n",
              "yhEM6UREREREREQ5giGdiIiIiIiIKEcwpBMRERERERHlCIb0WRaNRvH1r38d0Wg0212hW8T3cn7h\n",
              "+zm/8P2cX/h+zh98L+cXvp/zC9/P3MX7pM+y0dFRFBQUYGRkBPn5+dnuDt0CvpfzC9/P+YXv5/zC\n",
              "93P+4Hs5v/D9nF/4fuYuHkknIiIiIiIiyhEM6UREREREREQ5giGdiIiIiIiIKEcwpM8yTdPwzDPP\n",
              "QNO0bHeFbhHfy/mF7+f8wvdzfuH7OX/wvZxf+H7OL3w/cxcvHEdERERERESUI3gknYiIiIiIiChH\n",
              "MKQTERERERER5QiGdCIiIiIiIqIcwZBORERERERElCMY0m/BK6+8gi1btkDTNDz99NMpbZZl4U/+\n",
              "5E+wfPlyrFixAt///vdvuY2yq7W1FXfeeSdWrlyJbdu24fTp09nuEiX50z/9U9TU1ECSJJw4ccJZ\n",
              "Pt37drNtNPsikQgee+wxrFy5Ehs2bMCDDz6ItrY2AMDAwAA++MEPor6+HuvWrcPvfvc753E320az\n",
              "6wMf+AAaGxuxceNG3HPPPXj33XcB8PM51/34xz+GJEl46aWXAPCzOVfV1NRg1apV2LhxIzZu3Ih/\n",
              "/dd/BcDP51wUjUbx1FNPob6+HuvXr8d/+k//CQDfyzlJ0E1raWkRJ06cEF/5ylfEF77whZS2f/zH\n",
              "fxS7du0ShmGIoaEhUV1dLZqbm2+pjbLrvvvuEz/+8Y+FEEI8//zzYuvWrdntEKX47W9/K3p6esSy\n",
              "ZcvEu+++6yyf7n272TaafeFwWLzyyivCsiwhhBDf+973xL333iuEEOLTn/60eOaZZ4QQQhw+fFhU\n",
              "VlaKWCx2S200u65cueLUX3zxRdHY2CiE4OdzLuvo6BB33HGH2Llzp/jFL34hhOBnc65K/7uZwM/n\n",
              "3PP000+Lp556yvnb2dvbK4TgezkXMaTPgGeeeWZSSP/whz8sfvrTnzrzf/7nfy6+8pWv3FIbZU9/\n",
              "f7/Iy8sTuq4LIYSwLEuUl5eL1tbWLPeM0iVvbEz3vt1sG2XHkSNHxLJly4QQQvj9fmfDQwghtm3b\n",
              "Jl5//fVbaqPb58c//rHYsGEDP59zmGma4v777xdHjx4V9957rxPS+dmcmzKFdH4+557x8XGRl5cn\n",
              "RkZGUpbzvZybONx9lnR3d2PZsmXOfE1NDbq7u2+pjbKnp6cHixcvhqqqAABJklBdXc33JsdN977d\n",
              "bBtlx3e+8x08+uijGBoagq7rqKiocNoS35M320a3xx/8wR+gqqoK/+N//A/80z/9Ez+fc9izzz6L\n",
              "u+66C1u2bHGW8bM5t/3BH/wB1q9fj8985jMYHBzk53MOOn/+PIqKivDXf/3X2Lp1K+655x68+eab\n",
              "fC/nKIb0adxxxx0oKSnJWHp6erLdPSKiBeGv//qv0dbWhm9+85vZ7grdgp/85Cfo6enBN77xDXzp\n",
              "S1/KdnfoJjU3N+OFF17AV7/61Wx3hWbI7373OzQ1NeH48eMoKSnBH/7hH2a7S3QTDMNAV1cX1qxZ\n",
              "g6NHj+K73/0unnjiCRiGke2u0U1gSJ/GgQMHcPny5Yylqqpq2sdWV1ejq6vLme/s7ER1dfUttVH2\n",
              "VFVVobe31/miE0Kgu7ub702Om+59u9k2ur2+9a1v4cUXX8Svf/1r+Hw+FBcXQ1VV9PX1Oeskvidv\n",
              "to1urz/8wz/Enj17sHTpUn4+56C3334bnZ2dqK+vR01NDQ4ePIjPfe5z+NnPfsbP5hyV+Fm7XC48\n",
              "/fTTePvtt/n3cw6qrq6GLMv4/d//fQDApk2bUFtbi66uLr6XcxBD+iz5+Mc/jh/+8IcwTRPDw8P4\n",
              "13/9VzzxxBO31EbZU1ZWhs2bN+Of//mfAQAvvPACli5dihUrVmS5ZzSd6d63m22j2+fZZ5/FT3/6\n",
              "U7z++usoLCx0ln/84x/H//k//wcAcOTIEVy8eBH33nvvLbXR7Ll69SouXbrkzL/00ksoLi7m53OO\n",
              "+vznP4/e3l50dnais7MTO3fuxA9+8AN8/vOf52dzDgoGg7h69aoz/9Of/hSbNm3i53MOKikpwf33\n",
              "349///d/BwB0dHSgo6MDd911F9/LuSgrZ8LPE2+88YaorKwUeXl5IhAIiMrKSvHLX/5SCCGEYRji\n",
              "j//4j0Vtba2oq6sT3/72t53H3WwbZde5c+fEzp07RX19vdiyZYtoamrKdpcoyec+9zlRWVkpFEUR\n",
              "ZWVlYvny5UKI6d+3m22j2dfT0yMAiLq6OrFhwwaxYcMGsX37diGEEH19feLBBx8UK1asEGvWrBFv\n",
              "vfWW87ibbaPZ09nZKbZt2ybWrVsnGhsbxf333+9cpIqfz7kv+cJx/GzOPefPnxcbN24U69evF+vW\n",
              "rROPPPKI6OjoEELw8zkXnT9/Xrz//e93vm9//vOfCyH4Xs5FkhBCZHtHARERERERERFxuDsRERER\n",
              "ERFRzmBIJyIiIiIiIsoRDOlEREQL0MaNGzE2NnbDj/vYxz6G5557buY7RERERAAANdsdICIiotvv\n",
              "xIkT2e4CERERZcAj6URERAuQJEnOrZdqamrwta99DXfccQdqa2vxjW98w1nv3LlzuPPOO7F27Vo8\n",
              "9thjGB0dddrGxsbwn//zf8b27dvR2NiIz33uc4jFYmhpacHSpUvR3t4OwL7f/Qc/+EFYlnVbXyMR\n",
              "EdFcxJBOREREuHr1Kg4cOIAjR47gb/7mb3Dx4kUAwJNPPonPfOYzOH36NP7qr/4Kv/3tb53H/Nf/\n",
              "+l9xzz334PDhwzh58iQsy8J3vvMdrFq1Cn/zN3+Dxx9/HHv37sXf/u3f4p/+6Z8gy9zsICIiuhYO\n",
              "dyciIiL8x//4HwEAJSUlqKurQ0dHB/Ly8nDixAl86lOfAgCsX78ed999t/OYl156CQcOHMCzzz4L\n",
              "AAiHw1AUBQDwyU9+Env27MFDDz2EN998E6Wlpbf3BREREc1RDOlEREQEj8fj1BVFgWEYGdeTJMmp\n",
              "CyHwwgsvYOXKlZPWMwwDzc3NKCoqco7KExER0bVx3BkRERFllJ+fj02bNuEnP/kJAOD06dPYt2+f\n",
              "0/7YY4/hf/2v/+UE+itXrqCtrQ0A8N//+3/HqlWr8Pbbb+PP/uzPnOVEREQ0PYZ0IiIimtJPfvIT\n",
              "/OAHP8C6devw1a9+Fe973/uctv/9v/83vF4vNm7ciMbGRtx///3o7OzEv/3bv+G1117D3/7t32LF\n",
              "ihV49tln8fjjjyMSiWTxlRAREc0NkhBCZLsTRERERERERMQj6UREREREREQ5gyGdiIiIiIiIKEcw\n",
              "pBMRERERERHlCIZ0IiIiIiIiohzBkE5ERERERESUIxjSiYiIiIiIiHIEQzoRERERERFRjmBIJyIi\n",
              "IiIiIsoRDOlEREREREREOYIhnYiIiIiIiChH/P8JRHfr2Sg+OwAAAABJRU5ErkJggg==\n",
              "\">\n",
              "      </div>\n",
              "      <script type=\"text/javascript\">\n",
              "        (() => {\n",
              "          const chartElement = document.getElementById(\"chart-dcab5aff-b2aa-4d02-b611-d43bfb9f392b\");\n",
              "          async function getCodeForChartHandler(event) {\n",
              "            const chartCodeResponse =  await google.colab.kernel.invokeFunction(\n",
              "                'getCodeForChart', [\"chart-dcab5aff-b2aa-4d02-b611-d43bfb9f392b\"], {});\n",
              "            const responseJson = chartCodeResponse.data['application/json'];\n",
              "            await google.colab.notebook.addCell(responseJson.code, 'code');\n",
              "          }\n",
              "          chartElement.onclick = getCodeForChartHandler;\n",
              "        })();\n",
              "      </script>\n",
              "      <style>\n",
              "        .colab-quickchart-chart-with-code  {\n",
              "            display: block;\n",
              "            float: left;\n",
              "            border: 1px solid transparent;\n",
              "        }\n",
              "\n",
              "        .colab-quickchart-chart-with-code:hover {\n",
              "            cursor: pointer;\n",
              "            border: 1px solid #aaa;\n",
              "        }\n",
              "      </style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
      "metadata": {
        "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
      },
      "source": [
        "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
        "outputId": "d396186e-995b-4a69-d1ea-51f8dc16b42a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
      "metadata": {
        "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
      },
      "source": [
        "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
        "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7be4a0a2-9704-4a96-b38f-240339818688",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7be4a0a2-9704-4a96-b38f-240339818688",
        "outputId": "3b3da70c-f738-4d96-ee60-78f023c9ef7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    # 垃圾邮件的个数\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
      "metadata": {
        "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
      },
      "source": [
        "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
      "metadata": {
        "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
      },
      "outputs": [],
      "source": [
        "# 列名称替换\n",
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
        "outputId": "c7b2e36a-e471-4c87-e18c-71d20a386d88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               Text\n",
              "4307      0  Awww dat is sweet! We can think of something t...\n",
              "4138      0                             Just got to  &lt;#&gt;\n",
              "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
              "4461      0  This is wishing you a great day. Moji told me ...\n",
              "5440      0      Thank you. do you generally date the brothas?\n",
              "...     ...                                                ...\n",
              "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
              "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
              "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
              "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
              "5567      1  This is the 2nd time we have tried 2 contact u...\n",
              "\n",
              "[1494 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f11dd69-2fb3-426b-9989-757b2cb52048\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4307</th>\n",
              "      <td>0</td>\n",
              "      <td>Awww dat is sweet! We can think of something t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4138</th>\n",
              "      <td>0</td>\n",
              "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4831</th>\n",
              "      <td>0</td>\n",
              "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4461</th>\n",
              "      <td>0</td>\n",
              "      <td>This is wishing you a great day. Moji told me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5440</th>\n",
              "      <td>0</td>\n",
              "      <td>Thank you. do you generally date the brothas?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5537</th>\n",
              "      <td>1</td>\n",
              "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5540</th>\n",
              "      <td>1</td>\n",
              "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5547</th>\n",
              "      <td>1</td>\n",
              "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5566</th>\n",
              "      <td>1</td>\n",
              "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1494 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f11dd69-2fb3-426b-9989-757b2cb52048')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f11dd69-2fb3-426b-9989-757b2cb52048 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f11dd69-2fb3-426b-9989-757b2cb52048');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7d546505-7d1b-4881-ba5c-be0487880d02\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d546505-7d1b-4881-ba5c-be0487880d02')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7d546505-7d1b-4881-ba5c-be0487880d02 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1bd7b6da-3a5e-42b9-88e0-04ad332f9a21\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('balanced_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1bd7b6da-3a5e-42b9-88e0-04ad332f9a21 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('balanced_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df",
              "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 1494,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1388,\n        \"samples\": [\n          \"chile, please! It's only a  &lt;DECIMAL&gt;  hour drive for me. I come down all the time and will be subletting feb-april for audition season.\",\n          \"I only haf msn. It's yijue@hotmail.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "balanced_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
      "metadata": {
        "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
      },
      "source": [
        "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "uQl0Psdmx15D",
      "metadata": {
        "id": "uQl0Psdmx15D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1405e35b-a484-4cd4-ffe2-870c8f032f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1045\n",
            "0.7\n",
            "0.1\n",
            "1194\n"
          ]
        }
      ],
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    # sample取样，frac=1为抽取的数据比例，drop=True丢弃原始索引\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    print(train_end)\n",
        "    print(train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "    print(validation_frac)\n",
        "    print(validation_end)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "# 数据集拆分\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n",
        "# 转为csv格式的数据集\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
      "metadata": {
        "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094"
      },
      "source": [
        "## 6.3 Creating data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
      "metadata": {
        "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
      },
      "source": [
        "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
        "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
        "  2. pad all messages to the length of the longest message in the dataset or batch\n",
        "\n",
        "- We choose option 2 and pad all messages to the longest message in the dataset\n",
        "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0829f33f-1428-4f22-9886-7fee633b3666",
      "metadata": {
        "id": "0829f33f-1428-4f22-9886-7fee633b3666"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
        "outputId": "81a57b16-154e-46ae-d46d-80e329d1afbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
      "metadata": {
        "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
      },
      "source": [
        "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
      "metadata": {
        "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "  # 初始化的，对象\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                # 截断过长的内容\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        # 填充特定次数的必要的词语\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "    # []调用\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "    # len()方法调用\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    # 单下划线，私有方法\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n",
        "        # Note: A more pythonic version to implement this method\n",
        "        # is the following, which is also used in the next chapter:\n",
        "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "uzj85f8ou82h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzj85f8ou82h",
        "outputId": "11a661e5-3722-4a91-8a97-8e5df729ebc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
      "metadata": {
        "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60"
      },
      "source": [
        "- We also pad the validation and test set to the longest training sequence\n",
        "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
        "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
      "metadata": {
        "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
      },
      "outputs": [],
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20170d89-85a0-4844-9887-832f5d23432a",
      "metadata": {
        "id": "20170d89-85a0-4844-9887-832f5d23432a"
      },
      "source": [
        "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
      "metadata": {
        "id": "64bcc349-205f-48f8-9655-95ff21f5e72f"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
      "metadata": {
        "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
      "metadata": {
        "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
      },
      "source": [
        "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
        "outputId": "68f32bfa-9223-4000-bce8-2e3029aaeb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
      "metadata": {
        "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
      },
      "source": [
        "- Lastly, let's print the total number of batches in each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "IZfw-TYD2zTj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZfw-TYD2zTj",
        "outputId": "5aec8b45-d439-4022-a0f4-2025d7715f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
      "metadata": {
        "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
      },
      "source": [
        "## 6.4 Initializing a model with pretrained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
      "metadata": {
        "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208"
      },
      "source": [
        "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
      "metadata": {
        "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        # 确保输出维度可以被头数整除\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        # 计算每个注意力头的维度\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        # 基于输入输出维度定义权重矩阵\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        # 定义投影矩阵\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        # 定义dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # 注册因果掩码\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        # 通过线性层计算 Keys, Queries, Values矩阵\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # 拆分权重并为每个头添加一个维度\n",
        "        # 最后一个维度 (d_out) 拆分成 num_heads 个独立的子空间，每个子空间的维度是 head_dim，\n",
        "        # 为后续的多头注意力计算做准备。\n",
        "        # view() 方法: view() 是 PyTorch 中用来改变张量形状的方法。它返回一个新的张量，\n",
        "        # 该张量与原张量共享底层数据，但具有不同的形状。你可以把它理解为“从不同的角度看待”同一个数据。\n",
        "        # (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # 调整维度顺序，将头数维度放在前面，方便后续矩阵乘法\n",
        "        # (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # 计算缩放点积注意力分数 (Scaled Dot-Product Attention)\n",
        "        # queries @ keys.transpose(2, 3) 在这里是关键步骤\n",
        "        # 它在 (b, num_heads) 维度上进行广播，对每个头独立执行矩阵乘法\n",
        "        # (b, num_heads, num_tokens, head_dim) @ (b, num_heads, head_dim, num_tokens)\n",
        "        # 得到 (b, num_heads, num_tokens, num_tokens) 的注意力分数\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        # 应用因果掩码\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        # 计算注意力权重 (Softmax)\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # 计算上下文向量\n",
        "        # (b, num_heads, num_tokens, num_tokens) @ (b, num_heads, num_tokens, head_dim)\n",
        "        # 得到 (b, num_heads, num_tokens, head_dim) 的上下文向量\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2) # 调整维度顺序回来\n",
        "        # 组合所有头的上下文向量\n",
        "        # (b, num_tokens, num_heads, head_dim) -> (b, num_tokens, d_out)\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "\n",
        "        # 应用输出投影层 (可选)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        # 可学习的缩放和偏移参数\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 归一化，转为均值为0，方差为1的向量\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 初始化注意力机制模块\n",
        "        self.att = MultiHeadAttention(\n",
        "            # 输入输出维度\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            # 窗口宽度\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        # 前馈网络\n",
        "        self.ff = FeedForward(cfg)\n",
        "        # 归一化\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        # 残差连接\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        # 对注意力层的输出应用 dropout。\n",
        "        x = self.drop_shortcut(x)\n",
        "        # 残差连接\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        # 前馈网络模块，由两个线性模块和一个非线性模块构成\n",
        "        # 作用是为模型引入非线性性，并允许模型在每个位置（token）上独立地处理信息。\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        # transform块\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Ezo8dyybD-_Z"
      },
      "id": "Ezo8dyybD-_Z",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "0WIk2St9FKFq"
      },
      "id": "0WIk2St9FKFq",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "redinNmhE-gj"
      },
      "id": "redinNmhE-gj",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "022a649a-44f5-466c-8a8e-326c063384f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "022a649a-44f5-466c-8a8e-326c063384f5",
        "outputId": "a556f084-a412-4ad0-9442-47e5c31f3e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        with urllib.request.urlopen(download_url) as response:\n",
        "            # Get the total file size from headers, defaulting to 0 if not present\n",
        "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "            # Check if file exists and has the same size\n",
        "            if os.path.exists(destination):\n",
        "                file_size_local = os.path.getsize(destination)\n",
        "                if file_size == file_size_local:\n",
        "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                    return True  # Indicate success without re-downloading\n",
        "\n",
        "            block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "            # Initialize the progress bar with total file size\n",
        "            progress_bar_description = os.path.basename(download_url)\n",
        "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "                with open(destination, \"wb\") as file:\n",
        "                    while True:\n",
        "                        chunk = response.read(block_size)\n",
        "                        if not chunk:\n",
        "                            break\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "            return True\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except (urllib.error.HTTPError, urllib.error.URLError):\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except urllib.error.HTTPError:\n",
        "                pass\n",
        "\n",
        "        # If we reach here, both attempts have failed\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "# from previous_chapters import GPTModel, load_weights_into_gpt\n",
        "# If the `previous_chapters.py` file is not available locally,\n",
        "# you can import it from the `llms-from-scratch` PyPI package.\n",
        "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
        "# E.g.,\n",
        "# from llms_from_scratch.ch04 import GPTModel\n",
        "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8e056c-abe0-415f-b34d-df686204259e",
      "metadata": {
        "id": "ab8e056c-abe0-415f-b34d-df686204259e"
      },
      "source": [
        "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "HcOSRqEEFiuf"
      },
      "id": "HcOSRqEEFiuf",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ],
      "metadata": {
        "id": "m3I1MvSjFt9H"
      },
      "id": "m3I1MvSjFt9H",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
        "outputId": "1e577162-1cd7-41e4-b55e-a859eb7d0708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "# from previous_chapters import (\n",
        "#     generate_text_simple,\n",
        "#     text_to_token_ids,\n",
        "#     token_ids_to_text\n",
        "# )\n",
        "\n",
        "# Alternatively:\n",
        "# from llms_from_scratch.ch05 import (\n",
        "#    generate_text_simple,\n",
        "#    text_to_token_ids,\n",
        "#    token_ids_to_text\n",
        "# )\n",
        "\n",
        "\n",
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69162550-6a02-4ece-8db1-06c71d61946f",
      "metadata": {
        "id": "69162550-6a02-4ece-8db1-06c71d61946f"
      },
      "source": [
        "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
        "outputId": "f63a5daa-fac8-4d31-d8a0-21b5596b957e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
      "metadata": {
        "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016"
      },
      "source": [
        "- As we can see, the model is not very good at following instructions\n",
        "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
      "metadata": {
        "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
      },
      "source": [
        "## 6.5 Adding a classification head"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
      "metadata": {
        "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217bac05-78df-4412-bd80-612f8061c01d",
      "metadata": {
        "id": "217bac05-78df-4412-bd80-612f8061c01d"
      },
      "source": [
        "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
        "- Let's take a look at the model architecture first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
        "outputId": "312f4d60-48b8-4d81-bb1e-85834d2270ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
      "metadata": {
        "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d"
      },
      "source": [
        "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
        "- The goal is to replace and finetune the output layer\n",
        "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "fkMWFl-0etea",
      "metadata": {
        "id": "fkMWFl-0etea"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72155f83-87d9-476a-a978-a15aa2d44147",
      "metadata": {
        "id": "72155f83-87d9-476a-a978-a15aa2d44147"
      },
      "source": [
        "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
        "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
        "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
      "metadata": {
        "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
      "metadata": {
        "id": "30be5475-ae77-4f97-8f3e-dec462b1339f"
      },
      "source": [
        "- Technically, it's sufficient to only train the output layer\n",
        "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
        "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
      "metadata": {
        "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
      "metadata": {
        "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
      },
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
      "metadata": {
        "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e"
      },
      "source": [
        "- We can still use this model similar to before in previous chapters\n",
        "- For example, let's feed it some text input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
        "outputId": "4b2e2a59-dddc-47a8-b8fc-497dbde4ee05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
      "metadata": {
        "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b"
      },
      "source": [
        "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
        "outputId": "2969df13-835c-4bdd-cb07-05d5b43ae059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "# 禁用梯度更新\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75430a01-ef9c-426a-aca0-664689c4f461",
      "metadata": {
        "id": "75430a01-ef9c-426a-aca0-664689c4f461"
      },
      "source": [
        "- As discussed in previous chapters, for each input token, there's one output vector\n",
        "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
      "metadata": {
        "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
      "metadata": {
        "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a"
      },
      "source": [
        "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
        "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
        "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
        "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
        "outputId": "b6236a3b-0fef-4628-ec89-237fe76dc855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
      "metadata": {
        "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=200px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
      "metadata": {
        "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c"
      },
      "source": [
        "## 6.6 Calculating the classification loss and accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
      "metadata": {
        "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
      "metadata": {
        "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3"
      },
      "source": [
        "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
      "metadata": {
        "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=600px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
      "metadata": {
        "id": "c77faab1-3461-4118-866a-6171f2b89aa0"
      },
      "outputs": [],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
      "metadata": {
        "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d"
      },
      "source": [
        "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
      "metadata": {
        "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01"
      },
      "outputs": [],
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414a6f02-307e-4147-a416-14d115bf8179",
      "metadata": {
        "id": "414a6f02-307e-4147-a416-14d115bf8179"
      },
      "source": [
        "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
      "metadata": {
        "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2"
      },
      "outputs": [],
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
      "metadata": {
        "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505"
      },
      "source": [
        "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
        "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
      "metadata": {
        "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7165fe46-a284-410b-957f-7524877d1a1a",
      "metadata": {
        "id": "7165fe46-a284-410b-957f-7524877d1a1a"
      },
      "source": [
        "- Let's apply the function to calculate the classification accuracies for the different datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
      "metadata": {
        "id": "390e5255-8427-488c-adef-e1c10ab4fb26"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
        "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#print(f\"Running on {device} device.\")\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30345e2a-afed-4d22-9486-f4010f90a871",
      "metadata": {
        "id": "30345e2a-afed-4d22-9486-f4010f90a871"
      },
      "source": [
        "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
      "metadata": {
        "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328"
      },
      "source": [
        "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
        "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
        "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
        "\n",
        "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
      "metadata": {
        "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
      "metadata": {
        "id": "a013aab9-f854-4866-ad55-5b8350adb50a"
      },
      "source": [
        "The `calc_loss_loader` is exactly the same as in chapter 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
      "metadata": {
        "id": "b7b83e10-5720-45e7-ac5e-369417ca846b"
      },
      "outputs": [],
      "source": [
        "# Same as in chapter 5\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56826ecd-6e74-40e6-b772-d3541e585067",
      "metadata": {
        "id": "56826ecd-6e74-40e6-b772-d3541e585067"
      },
      "source": [
        "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
      "metadata": {
        "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
      "metadata": {
        "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d"
      },
      "source": [
        "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
      "metadata": {
        "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
      },
      "source": [
        "## 6.7 Finetuning the model on supervised data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
      "metadata": {
        "id": "6a9b099b-0829-4f72-8a2b-4363e3497026"
      },
      "source": [
        "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
        "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
        "- The only two differences are that we now\n",
        "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
        "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
      "metadata": {
        "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Csbr60to50FL",
      "metadata": {
        "id": "Csbr60to50FL"
      },
      "outputs": [],
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
      "metadata": {
        "id": "9624cb30-3e3a-45be-b006-c00475b58ae8"
      },
      "source": [
        "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
      "metadata": {
        "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab"
      },
      "outputs": [],
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
      "metadata": {
        "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9"
      },
      "source": [
        "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X7kU3aAj7vTJ",
      "metadata": {
        "id": "X7kU3aAj7vTJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1261bf90-3ce7-4591-895a-044a05538f30",
      "metadata": {
        "id": "1261bf90-3ce7-4591-895a-044a05538f30"
      },
      "source": [
        "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cURgnDqdCeka",
      "metadata": {
        "id": "cURgnDqdCeka"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OIqRt466DiGk",
      "metadata": {
        "id": "OIqRt466DiGk"
      },
      "outputs": [],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
      "metadata": {
        "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc"
      },
      "source": [
        "- Above, based on the downward slope, we see that the model learns well\n",
        "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
        "- Similarly, we can plot the accuracy below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yz8BIsaF0TUo",
      "metadata": {
        "id": "yz8BIsaF0TUo"
      },
      "outputs": [],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90aba699-21bc-42de-a69c-99f370bb0363",
      "metadata": {
        "id": "90aba699-21bc-42de-a69c-99f370bb0363"
      },
      "source": [
        "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
        "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
        "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UHWaJFrjY0zW",
      "metadata": {
        "id": "UHWaJFrjY0zW"
      },
      "outputs": [],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
      "metadata": {
        "id": "6882649f-dc7b-401f-84d2-024ff79c74a1"
      },
      "source": [
        "- We can see that the training and validation set performances are practically identical\n",
        "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
        "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
      "metadata": {
        "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0"
      },
      "source": [
        "## 6.8 Using the LLM as a spam classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
      "metadata": {
        "id": "72ebcfa2-479e-408b-9cf0-7421f6144855"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
      "metadata": {
        "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31"
      },
      "source": [
        "- Finally, let's use the finetuned GPT model in action\n",
        "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
        "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aHdn6xvL-IW5",
      "metadata": {
        "id": "aHdn6xvL-IW5"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
        "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "    assert max_length is not None, (\n",
        "        \"max_length must be specified. If you want to use the full model context, \"\n",
        "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
        "    )\n",
        "    assert max_length <= supported_context_length, (\n",
        "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
        "    )\n",
        "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
        "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
        "    # input_ids = input_ids[:max_len]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
      "metadata": {
        "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c"
      },
      "source": [
        "- Let's try it out on a few examples below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apU_pf51AWSV",
      "metadata": {
        "id": "apU_pf51AWSV"
      },
      "outputs": [],
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1g5VTOo_Ajs5",
      "metadata": {
        "id": "1g5VTOo_Ajs5"
      },
      "outputs": [],
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
      "metadata": {
        "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e"
      },
      "source": [
        "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mYnX-gI1CfQY",
      "metadata": {
        "id": "mYnX-gI1CfQY"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
      "metadata": {
        "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6"
      },
      "source": [
        "- Then, in a new session, we could load the model as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
      "metadata": {
        "id": "cc4e68a5-d492-493b-87ef-45c475f353f5"
      },
      "outputs": [],
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
      "metadata": {
        "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
      },
      "source": [
        "## Summary and takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
      "metadata": {
        "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e"
      },
      "source": [
        "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
        "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
        "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}